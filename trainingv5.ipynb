{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a15e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "개선된 통합 NLU 모델 훈련 시작 (Intent + NER)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "데이터 전처리 및 통합 시작\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인텐트 데이터 로드 중...\n",
      "인텐트 레이블 목록: ['search_book_title', 'search_book_author', 'search_book_location', 'check_book_availability', 'get_bestseller', 'get_new_releases', 'request_recommendation_genre', 'request_recommendation_mood', 'request_recommendation_topic', 'request_recommendation_similar', 'request_recommendation_reader', 'search_space_availability', 'reserve_space', 'get_space_info', 'check_space_reservation', 'cancel_space_reservation', 'search_program', 'apply_program', 'get_program_info', 'check_program_application', 'cancel_program_application', 'get_library_hours', 'inquire_service', 'manage_membership', 'check_loan_status', 'extend_loan', 'reserve_book', 'check_reservation_status', 'cancel_book_reservation', 'check_overdue_status', 'report_lost_item', 'greeting', 'gratitude', 'closing', 'affirmative', 'negative', 'abuse', 'clarification', 'out_of_scope', 'repeat']\n",
      "레이블 매핑 정보:\n",
      "  'search_book_title' -> 0\n",
      "  'search_book_author' -> 1\n",
      "  'search_book_location' -> 2\n",
      "  'check_book_availability' -> 3\n",
      "  'get_bestseller' -> 4\n",
      "  'get_new_releases' -> 5\n",
      "  'request_recommendation_genre' -> 6\n",
      "  'request_recommendation_mood' -> 7\n",
      "  'request_recommendation_topic' -> 8\n",
      "  'request_recommendation_similar' -> 9\n",
      "  'request_recommendation_reader' -> 10\n",
      "  'search_space_availability' -> 11\n",
      "  'reserve_space' -> 12\n",
      "  'get_space_info' -> 13\n",
      "  'check_space_reservation' -> 14\n",
      "  'cancel_space_reservation' -> 15\n",
      "  'search_program' -> 16\n",
      "  'apply_program' -> 17\n",
      "  'get_program_info' -> 18\n",
      "  'check_program_application' -> 19\n",
      "  'cancel_program_application' -> 20\n",
      "  'get_library_hours' -> 21\n",
      "  'inquire_service' -> 22\n",
      "  'manage_membership' -> 23\n",
      "  'check_loan_status' -> 24\n",
      "  'extend_loan' -> 25\n",
      "  'reserve_book' -> 26\n",
      "  'check_reservation_status' -> 27\n",
      "  'cancel_book_reservation' -> 28\n",
      "  'check_overdue_status' -> 29\n",
      "  'report_lost_item' -> 30\n",
      "  'greeting' -> 31\n",
      "  'gratitude' -> 32\n",
      "  'closing' -> 33\n",
      "  'affirmative' -> 34\n",
      "  'negative' -> 35\n",
      "  'abuse' -> 36\n",
      "  'clarification' -> 37\n",
      "  'out_of_scope' -> 38\n",
      "  'repeat' -> 39\n",
      "\n",
      "변환 전 원본 레이블 분포:\n",
      "  '0': 194개\n",
      "  '1': 116개\n",
      "  '2': 213개\n",
      "  '3': 183개\n",
      "  '4': 75개\n",
      "  '5': 89개\n",
      "  '6': 295개\n",
      "  '7': 45개\n",
      "  '8': 5개\n",
      "  '9': 5개\n",
      "  '10': 5개\n",
      "  '11': 5개\n",
      "  '12': 5개\n",
      "  '13': 5개\n",
      "  '14': 5개\n",
      "  '15': 5개\n",
      "  '16': 5개\n",
      "  '17': 5개\n",
      "  '18': 5개\n",
      "  '19': 5개\n",
      "  '20': 5개\n",
      "  '21': 5개\n",
      "  '22': 5개\n",
      "  '23': 5개\n",
      "  '24': 5개\n",
      "  '25': 5개\n",
      "  '26': 5개\n",
      "  '27': 5개\n",
      "  '28': 5개\n",
      "  '29': 5개\n",
      "  '30': 5개\n",
      "  '31': 5개\n",
      "  '32': 5개\n",
      "  '33': 5개\n",
      "  '34': 5개\n",
      "  '35': 5개\n",
      "  '36': 6개\n",
      "  '37': 5개\n",
      "  '38': 5개\n",
      "  '39': 5개\n",
      "변환: '0' -> 0 (텍스트: '나루토 책 있어?...')\n",
      "변환: '0' -> 0 (텍스트: '식물학자의 숲속 일기라는 책 있나요?...')\n",
      "변환: '0' -> 0 (텍스트: '사랑의 기술 책 찾아주세요....')\n",
      "변환: '0' -> 0 (텍스트: '거북의 시간 소장하고 있는지 궁금합니다....')\n",
      "변환: '0' -> 0 (텍스트: '미신은 어떻게 사회를 위협하는가 검색해줘....')\n",
      "변환: '0' -> 0 (텍스트: '지나고 보니 마흔이 기회였다 구비되어 있는지 확인할 수...')\n",
      "변환: '0' -> 0 (텍스트: '회사생활에도 예절이 필요합니다 도서관에 있어요?...')\n",
      "변환: '0' -> 0 (텍스트: 'AI 2025 책 지금 볼 수 있나요?...')\n",
      "변환: '0' -> 0 (텍스트: '오더 ORDER 찾고 싶은데 어디 있나요?...')\n",
      "변환: '0' -> 0 (텍스트: '듀얼 브레인 책 제목으로 검색해주세요....')\n",
      "\n",
      "레이블 변환 결과: 성공=1371개, 기본값 사용=0개\n",
      "\n",
      "변환 후 인텐트 레이블 분포:\n",
      "  - 레이블 0 (search_book_title): 194개\n",
      "  - 레이블 1 (search_book_author): 116개\n",
      "  - 레이블 2 (search_book_location): 213개\n",
      "  - 레이블 3 (check_book_availability): 183개\n",
      "  - 레이블 4 (get_bestseller): 75개\n",
      "  - 레이블 5 (get_new_releases): 89개\n",
      "  - 레이블 6 (request_recommendation_genre): 295개\n",
      "  - 레이블 7 (request_recommendation_mood): 45개\n",
      "  - 레이블 8 (request_recommendation_topic): 5개\n",
      "  - 레이블 9 (request_recommendation_similar): 5개\n",
      "  - 레이블 10 (request_recommendation_reader): 5개\n",
      "  - 레이블 11 (search_space_availability): 5개\n",
      "  - 레이블 12 (reserve_space): 5개\n",
      "  - 레이블 13 (get_space_info): 5개\n",
      "  - 레이블 14 (check_space_reservation): 5개\n",
      "  - 레이블 15 (cancel_space_reservation): 5개\n",
      "  - 레이블 16 (search_program): 5개\n",
      "  - 레이블 17 (apply_program): 5개\n",
      "  - 레이블 18 (get_program_info): 5개\n",
      "  - 레이블 19 (check_program_application): 5개\n",
      "  - 레이블 20 (cancel_program_application): 5개\n",
      "  - 레이블 21 (get_library_hours): 5개\n",
      "  - 레이블 22 (inquire_service): 5개\n",
      "  - 레이블 23 (manage_membership): 5개\n",
      "  - 레이블 24 (check_loan_status): 5개\n",
      "  - 레이블 25 (extend_loan): 5개\n",
      "  - 레이블 26 (reserve_book): 5개\n",
      "  - 레이블 27 (check_reservation_status): 5개\n",
      "  - 레이블 28 (cancel_book_reservation): 5개\n",
      "  - 레이블 29 (check_overdue_status): 5개\n",
      "  - 레이블 30 (report_lost_item): 5개\n",
      "  - 레이블 31 (greeting): 5개\n",
      "  - 레이블 32 (gratitude): 5개\n",
      "  - 레이블 33 (closing): 5개\n",
      "  - 레이블 34 (affirmative): 5개\n",
      "  - 레이블 35 (negative): 5개\n",
      "  - 레이블 36 (abuse): 6개\n",
      "  - 레이블 37 (clarification): 5개\n",
      "  - 레이블 38 (out_of_scope): 5개\n",
      "  - 레이블 39 (repeat): 5개\n",
      "Intent 레이블 (40개): ['search_book_title', 'search_book_author', 'search_book_location', 'check_book_availability', 'get_bestseller', 'get_new_releases', 'request_recommendation_genre', 'request_recommendation_mood', 'request_recommendation_topic', 'request_recommendation_similar', 'request_recommendation_reader', 'search_space_availability', 'reserve_space', 'get_space_info', 'check_space_reservation', 'cancel_space_reservation', 'search_program', 'apply_program', 'get_program_info', 'check_program_application', 'cancel_program_application', 'get_library_hours', 'inquire_service', 'manage_membership', 'check_loan_status', 'extend_loan', 'reserve_book', 'check_reservation_status', 'cancel_book_reservation', 'check_overdue_status', 'report_lost_item', 'greeting', 'gratitude', 'closing', 'affirmative', 'negative', 'abuse', 'clarification', 'out_of_scope', 'repeat']\n",
      "NER 데이터 로드 중...\n",
      "NER 레이블 (1개): ['O']\n",
      "\n",
      "--- Intent 데이터 전처리 ---\n",
      "인텐트 클래스별 데이터 수:\n",
      "  - 0 (search_book_title): 194개\n",
      "  - 1 (search_book_author): 116개\n",
      "  - 2 (search_book_location): 213개\n",
      "  - 3 (check_book_availability): 183개\n",
      "  - 4 (get_bestseller): 75개\n",
      "  - 5 (get_new_releases): 89개\n",
      "  - 6 (request_recommendation_genre): 295개\n",
      "  - 7 (request_recommendation_mood): 45개\n",
      "  - 8 (request_recommendation_topic): 5개\n",
      "  - 9 (request_recommendation_similar): 5개\n",
      "  - 10 (request_recommendation_reader): 5개\n",
      "  - 11 (search_space_availability): 5개\n",
      "  - 12 (reserve_space): 5개\n",
      "  - 13 (get_space_info): 5개\n",
      "  - 14 (check_space_reservation): 5개\n",
      "  - 15 (cancel_space_reservation): 5개\n",
      "  - 16 (search_program): 5개\n",
      "  - 17 (apply_program): 5개\n",
      "  - 18 (get_program_info): 5개\n",
      "  - 19 (check_program_application): 5개\n",
      "  - 20 (cancel_program_application): 5개\n",
      "  - 21 (get_library_hours): 5개\n",
      "  - 22 (inquire_service): 5개\n",
      "  - 23 (manage_membership): 5개\n",
      "  - 24 (check_loan_status): 5개\n",
      "  - 25 (extend_loan): 5개\n",
      "  - 26 (reserve_book): 5개\n",
      "  - 27 (check_reservation_status): 5개\n",
      "  - 28 (cancel_book_reservation): 5개\n",
      "  - 29 (check_overdue_status): 5개\n",
      "  - 30 (report_lost_item): 5개\n",
      "  - 31 (greeting): 5개\n",
      "  - 32 (gratitude): 5개\n",
      "  - 33 (closing): 5개\n",
      "  - 34 (affirmative): 5개\n",
      "  - 35 (negative): 5개\n",
      "  - 36 (abuse): 6개\n",
      "  - 37 (clarification): 5개\n",
      "  - 38 (out_of_scope): 5개\n",
      "  - 39 (repeat): 5개\n",
      "클래스별 오버샘플링 비율:\n",
      "  - 0 (search_book_title): 3배\n",
      "  - 1 (search_book_author): 5배\n",
      "  - 2 (search_book_location): 2배\n",
      "  - 3 (check_book_availability): 3배\n",
      "  - 4 (get_bestseller): 5배\n",
      "  - 5 (get_new_releases): 5배\n",
      "  - 6 (request_recommendation_genre): 2배\n",
      "  - 7 (request_recommendation_mood): 5배\n",
      "  - 8 (request_recommendation_topic): 5배\n",
      "  - 9 (request_recommendation_similar): 5배\n",
      "  - 10 (request_recommendation_reader): 5배\n",
      "  - 11 (search_space_availability): 5배\n",
      "  - 12 (reserve_space): 5배\n",
      "  - 13 (get_space_info): 5배\n",
      "  - 14 (check_space_reservation): 5배\n",
      "  - 15 (cancel_space_reservation): 5배\n",
      "  - 16 (search_program): 5배\n",
      "  - 17 (apply_program): 5배\n",
      "  - 18 (get_program_info): 5배\n",
      "  - 19 (check_program_application): 5배\n",
      "  - 20 (cancel_program_application): 5배\n",
      "  - 21 (get_library_hours): 5배\n",
      "  - 22 (inquire_service): 5배\n",
      "  - 23 (manage_membership): 5배\n",
      "  - 24 (check_loan_status): 5배\n",
      "  - 25 (extend_loan): 5배\n",
      "  - 26 (reserve_book): 5배\n",
      "  - 27 (check_reservation_status): 5배\n",
      "  - 28 (cancel_book_reservation): 5배\n",
      "  - 29 (check_overdue_status): 5배\n",
      "  - 30 (report_lost_item): 5배\n",
      "  - 31 (greeting): 5배\n",
      "  - 32 (gratitude): 5배\n",
      "  - 33 (closing): 5배\n",
      "  - 34 (affirmative): 5배\n",
      "  - 35 (negative): 5배\n",
      "  - 36 (abuse): 5배\n",
      "  - 37 (clarification): 5배\n",
      "  - 38 (out_of_scope): 5배\n",
      "  - 39 (repeat): 5배\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "인텐트 데이터 처리:  18%|█▊        | 241/1371 [00:00<00:00, 2404.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Intent 데이터 0] '나루토 책 있어?' -> 의도: search_book_title (0)\n",
      "\n",
      "[Intent 데이터 1] '식물학자의 숲속 일기라는 책 있나요?' -> 의도: search_book_title (0)\n",
      "\n",
      "[Intent 데이터 2] '사랑의 기술 책 찾아주세요.' -> 의도: search_book_title (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "인텐트 데이터 처리: 100%|██████████| 1371/1371 [00:00<00:00, 2511.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NER 데이터 전처리 ---\n",
      "엔티티 유형별 개수:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NER 데이터 처리: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: 3203\n",
      "검증 데이터 크기: 687\n",
      "테스트 데이터 크기: 687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "훈련 데이터 인텐트 레이블 분포:\n",
      "  - 레이블 0 (search_book_title): 409개 (12.8%)\n",
      "  - 레이블 1 (search_book_author): 398개 (12.4%)\n",
      "  - 레이블 2 (search_book_location): 325개 (10.1%)\n",
      "  - 레이블 3 (check_book_availability): 390개 (12.2%)\n",
      "  - 레이블 4 (get_bestseller): 252개 (7.9%)\n",
      "  - 레이블 5 (get_new_releases): 298개 (9.3%)\n",
      "  - 레이블 6 (request_recommendation_genre): 414개 (12.9%)\n",
      "  - 레이블 7 (request_recommendation_mood): 153개 (4.8%)\n",
      "  - 레이블 8 (request_recommendation_topic): 18개 (0.6%)\n",
      "  - 레이블 9 (request_recommendation_similar): 16개 (0.5%)\n",
      "  - 레이블 10 (request_recommendation_reader): 15개 (0.5%)\n",
      "  - 레이블 11 (search_space_availability): 16개 (0.5%)\n",
      "  - 레이블 12 (reserve_space): 18개 (0.6%)\n",
      "  - 레이블 13 (get_space_info): 17개 (0.5%)\n",
      "  - 레이블 14 (check_space_reservation): 16개 (0.5%)\n",
      "  - 레이블 15 (cancel_space_reservation): 19개 (0.6%)\n",
      "  - 레이블 16 (search_program): 17개 (0.5%)\n",
      "  - 레이블 17 (apply_program): 20개 (0.6%)\n",
      "  - 레이블 18 (get_program_info): 17개 (0.5%)\n",
      "  - 레이블 19 (check_program_application): 16개 (0.5%)\n",
      "  - 레이블 20 (cancel_program_application): 17개 (0.5%)\n",
      "  - 레이블 21 (get_library_hours): 21개 (0.7%)\n",
      "  - 레이블 22 (inquire_service): 15개 (0.5%)\n",
      "  - 레이블 23 (manage_membership): 20개 (0.6%)\n",
      "  - 레이블 24 (check_loan_status): 19개 (0.6%)\n",
      "  - 레이블 25 (extend_loan): 12개 (0.4%)\n",
      "  - 레이블 26 (reserve_book): 17개 (0.5%)\n",
      "  - 레이블 27 (check_reservation_status): 19개 (0.6%)\n",
      "  - 레이블 28 (cancel_book_reservation): 16개 (0.5%)\n",
      "  - 레이블 29 (check_overdue_status): 16개 (0.5%)\n",
      "  - 레이블 30 (report_lost_item): 18개 (0.6%)\n",
      "  - 레이블 31 (greeting): 16개 (0.5%)\n",
      "  - 레이블 32 (gratitude): 19개 (0.6%)\n",
      "  - 레이블 33 (closing): 20개 (0.6%)\n",
      "  - 레이블 34 (affirmative): 18개 (0.6%)\n",
      "  - 레이블 35 (negative): 19개 (0.6%)\n",
      "  - 레이블 36 (abuse): 23개 (0.7%)\n",
      "  - 레이블 37 (clarification): 17개 (0.5%)\n",
      "  - 레이블 38 (out_of_scope): 19개 (0.6%)\n",
      "  - 레이블 39 (repeat): 18개 (0.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.json from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\model.safetensors\n",
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인텐트 데이터 로드 중...\n",
      "인텐트 레이블 목록: ['search_book_title', 'search_book_author', 'search_book_location', 'check_book_availability', 'get_bestseller', 'get_new_releases', 'request_recommendation_genre', 'request_recommendation_mood', 'request_recommendation_topic', 'request_recommendation_similar', 'request_recommendation_reader', 'search_space_availability', 'reserve_space', 'get_space_info', 'check_space_reservation', 'cancel_space_reservation', 'search_program', 'apply_program', 'get_program_info', 'check_program_application', 'cancel_program_application', 'get_library_hours', 'inquire_service', 'manage_membership', 'check_loan_status', 'extend_loan', 'reserve_book', 'check_reservation_status', 'cancel_book_reservation', 'check_overdue_status', 'report_lost_item', 'greeting', 'gratitude', 'closing', 'affirmative', 'negative', 'abuse', 'clarification', 'out_of_scope', 'repeat']\n",
      "레이블 매핑 정보:\n",
      "  'search_book_title' -> 0\n",
      "  'search_book_author' -> 1\n",
      "  'search_book_location' -> 2\n",
      "  'check_book_availability' -> 3\n",
      "  'get_bestseller' -> 4\n",
      "  'get_new_releases' -> 5\n",
      "  'request_recommendation_genre' -> 6\n",
      "  'request_recommendation_mood' -> 7\n",
      "  'request_recommendation_topic' -> 8\n",
      "  'request_recommendation_similar' -> 9\n",
      "  'request_recommendation_reader' -> 10\n",
      "  'search_space_availability' -> 11\n",
      "  'reserve_space' -> 12\n",
      "  'get_space_info' -> 13\n",
      "  'check_space_reservation' -> 14\n",
      "  'cancel_space_reservation' -> 15\n",
      "  'search_program' -> 16\n",
      "  'apply_program' -> 17\n",
      "  'get_program_info' -> 18\n",
      "  'check_program_application' -> 19\n",
      "  'cancel_program_application' -> 20\n",
      "  'get_library_hours' -> 21\n",
      "  'inquire_service' -> 22\n",
      "  'manage_membership' -> 23\n",
      "  'check_loan_status' -> 24\n",
      "  'extend_loan' -> 25\n",
      "  'reserve_book' -> 26\n",
      "  'check_reservation_status' -> 27\n",
      "  'cancel_book_reservation' -> 28\n",
      "  'check_overdue_status' -> 29\n",
      "  'report_lost_item' -> 30\n",
      "  'greeting' -> 31\n",
      "  'gratitude' -> 32\n",
      "  'closing' -> 33\n",
      "  'affirmative' -> 34\n",
      "  'negative' -> 35\n",
      "  'abuse' -> 36\n",
      "  'clarification' -> 37\n",
      "  'out_of_scope' -> 38\n",
      "  'repeat' -> 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file model.safetensors from cache at C:\\Users\\daehy\\.cache\\huggingface\\hub\\models--klue--roberta-base\\snapshots\\02f94ba5e3fcb7e2a58a390b8639b0fac974a8da\\model.safetensors\n",
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "변환 전 원본 레이블 분포:\n",
      "  '0': 194개\n",
      "  '1': 116개\n",
      "  '2': 213개\n",
      "  '3': 183개\n",
      "  '4': 75개\n",
      "  '5': 89개\n",
      "  '6': 295개\n",
      "  '7': 45개\n",
      "  '8': 5개\n",
      "  '9': 5개\n",
      "  '10': 5개\n",
      "  '11': 5개\n",
      "  '12': 5개\n",
      "  '13': 5개\n",
      "  '14': 5개\n",
      "  '15': 5개\n",
      "  '16': 5개\n",
      "  '17': 5개\n",
      "  '18': 5개\n",
      "  '19': 5개\n",
      "  '20': 5개\n",
      "  '21': 5개\n",
      "  '22': 5개\n",
      "  '23': 5개\n",
      "  '24': 5개\n",
      "  '25': 5개\n",
      "  '26': 5개\n",
      "  '27': 5개\n",
      "  '28': 5개\n",
      "  '29': 5개\n",
      "  '30': 5개\n",
      "  '31': 5개\n",
      "  '32': 5개\n",
      "  '33': 5개\n",
      "  '34': 5개\n",
      "  '35': 5개\n",
      "  '36': 6개\n",
      "  '37': 5개\n",
      "  '38': 5개\n",
      "  '39': 5개\n",
      "변환: '0' -> 0 (텍스트: '나루토 책 있어?...')\n",
      "변환: '0' -> 0 (텍스트: '식물학자의 숲속 일기라는 책 있나요?...')\n",
      "변환: '0' -> 0 (텍스트: '사랑의 기술 책 찾아주세요....')\n",
      "변환: '0' -> 0 (텍스트: '거북의 시간 소장하고 있는지 궁금합니다....')\n",
      "변환: '0' -> 0 (텍스트: '미신은 어떻게 사회를 위협하는가 검색해줘....')\n",
      "변환: '0' -> 0 (텍스트: '지나고 보니 마흔이 기회였다 구비되어 있는지 확인할 수...')\n",
      "변환: '0' -> 0 (텍스트: '회사생활에도 예절이 필요합니다 도서관에 있어요?...')\n",
      "변환: '0' -> 0 (텍스트: 'AI 2025 책 지금 볼 수 있나요?...')\n",
      "변환: '0' -> 0 (텍스트: '오더 ORDER 찾고 싶은데 어디 있나요?...')\n",
      "변환: '0' -> 0 (텍스트: '듀얼 브레인 책 제목으로 검색해주세요....')\n",
      "\n",
      "레이블 변환 결과: 성공=1371개, 기본값 사용=0개\n",
      "\n",
      "변환 후 인텐트 레이블 분포:\n",
      "  - 레이블 0 (search_book_title): 194개\n",
      "  - 레이블 1 (search_book_author): 116개\n",
      "  - 레이블 2 (search_book_location): 213개\n",
      "  - 레이블 3 (check_book_availability): 183개\n",
      "  - 레이블 4 (get_bestseller): 75개\n",
      "  - 레이블 5 (get_new_releases): 89개\n",
      "  - 레이블 6 (request_recommendation_genre): 295개\n",
      "  - 레이블 7 (request_recommendation_mood): 45개\n",
      "  - 레이블 8 (request_recommendation_topic): 5개\n",
      "  - 레이블 9 (request_recommendation_similar): 5개\n",
      "  - 레이블 10 (request_recommendation_reader): 5개\n",
      "  - 레이블 11 (search_space_availability): 5개\n",
      "  - 레이블 12 (reserve_space): 5개\n",
      "  - 레이블 13 (get_space_info): 5개\n",
      "  - 레이블 14 (check_space_reservation): 5개\n",
      "  - 레이블 15 (cancel_space_reservation): 5개\n",
      "  - 레이블 16 (search_program): 5개\n",
      "  - 레이블 17 (apply_program): 5개\n",
      "  - 레이블 18 (get_program_info): 5개\n",
      "  - 레이블 19 (check_program_application): 5개\n",
      "  - 레이블 20 (cancel_program_application): 5개\n",
      "  - 레이블 21 (get_library_hours): 5개\n",
      "  - 레이블 22 (inquire_service): 5개\n",
      "  - 레이블 23 (manage_membership): 5개\n",
      "  - 레이블 24 (check_loan_status): 5개\n",
      "  - 레이블 25 (extend_loan): 5개\n",
      "  - 레이블 26 (reserve_book): 5개\n",
      "  - 레이블 27 (check_reservation_status): 5개\n",
      "  - 레이블 28 (cancel_book_reservation): 5개\n",
      "  - 레이블 29 (check_overdue_status): 5개\n",
      "  - 레이블 30 (report_lost_item): 5개\n",
      "  - 레이블 31 (greeting): 5개\n",
      "  - 레이블 32 (gratitude): 5개\n",
      "  - 레이블 33 (closing): 5개\n",
      "  - 레이블 34 (affirmative): 5개\n",
      "  - 레이블 35 (negative): 5개\n",
      "  - 레이블 36 (abuse): 6개\n",
      "  - 레이블 37 (clarification): 5개\n",
      "  - 레이블 38 (out_of_scope): 5개\n",
      "  - 레이블 39 (repeat): 5개\n",
      "\n",
      "인텐트 클래스 분포:\n",
      "  - 클래스 0: 194개\n",
      "  - 클래스 1: 116개\n",
      "  - 클래스 2: 213개\n",
      "  - 클래스 3: 183개\n",
      "  - 클래스 4: 75개\n",
      "  - 클래스 5: 89개\n",
      "  - 클래스 6: 295개\n",
      "  - 클래스 7: 45개\n",
      "  - 클래스 8: 5개\n",
      "  - 클래스 9: 5개\n",
      "  - 클래스 10: 5개\n",
      "  - 클래스 11: 5개\n",
      "  - 클래스 12: 5개\n",
      "  - 클래스 13: 5개\n",
      "  - 클래스 14: 5개\n",
      "  - 클래스 15: 5개\n",
      "  - 클래스 16: 5개\n",
      "  - 클래스 17: 5개\n",
      "  - 클래스 18: 5개\n",
      "  - 클래스 19: 5개\n",
      "  - 클래스 20: 5개\n",
      "  - 클래스 21: 5개\n",
      "  - 클래스 22: 5개\n",
      "  - 클래스 23: 5개\n",
      "  - 클래스 24: 5개\n",
      "  - 클래스 25: 5개\n",
      "  - 클래스 26: 5개\n",
      "  - 클래스 27: 5개\n",
      "  - 클래스 28: 5개\n",
      "  - 클래스 29: 5개\n",
      "  - 클래스 30: 5개\n",
      "  - 클래스 31: 5개\n",
      "  - 클래스 32: 5개\n",
      "  - 클래스 33: 5개\n",
      "  - 클래스 34: 5개\n",
      "  - 클래스 35: 5개\n",
      "  - 클래스 36: 6개\n",
      "  - 클래스 37: 5개\n",
      "  - 클래스 38: 5개\n",
      "  - 클래스 39: 5개\n",
      "클래스별 가중치: [1.5128205128205128, 2.5213675213675213, 1.3785046728971964, 1.6032608695652173, 3.8815789473684212, 3.2777777777777777, 0.9966216216216216, 6.413043478260869, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 49.166666666666664, 42.142857142857146, 49.166666666666664, 49.166666666666664, 49.166666666666664]\n",
      "인텐트 분류기 가중치 균형있게 초기화 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `ImprovedRobertaForJointIntentAndNER.forward` and have been ignored: text, intent_label. If text, intent_label are not expected by `ImprovedRobertaForJointIntentAndNER.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 3,203\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1,000\n",
      "  Number of trainable parameters = 118,330,412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 훈련 시작...\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0292), 최소: 클래스 22 (0.0221)\n",
      "샘플 0: 예측=24, 실제=0, 상위확률=[클래스 24(0.0270), 클래스 30(0.0270), 클래스 0(0.0269)]\n",
      "샘플 1: 예측=1, 실제=0, 상위확률=[클래스 1(0.0312), 클래스 16(0.0311), 클래스 4(0.0297)]\n",
      "샘플 2: 예측=36, 실제=0, 상위확률=[클래스 36(0.0274), 클래스 25(0.0269), 클래스 16(0.0264)]\n",
      "샘플 3: 예측=10, 실제=0, 상위확률=[클래스 10(0.0317), 클래스 7(0.0310), 클래스 16(0.0308)]\n",
      "샘플 4: 예측=24, 실제=0, 상위확률=[클래스 24(0.0270), 클래스 30(0.0270), 클래스 0(0.0269)]\n",
      "Step 0 - Total: 2.8896, Intent: 3.6119, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0300), 최소: 클래스 18 (0.0217)\n",
      "샘플 0: 예측=24, 실제=0, 상위확률=[클래스 24(0.0269), 클래스 30(0.0267), 클래스 9(0.0265)]\n",
      "샘플 1: 예측=11, 실제=0, 상위확률=[클래스 11(0.0266), 클래스 13(0.0265), 클래스 19(0.0262)]\n",
      "샘플 2: 예측=16, 실제=0, 상위확률=[클래스 16(0.0340), 클래스 1(0.0301), 클래스 10(0.0285)]\n",
      "샘플 3: 예측=1, 실제=0, 상위확률=[클래스 1(0.0321), 클래스 16(0.0308), 클래스 23(0.0298)]\n",
      "샘플 4: 예측=11, 실제=0, 상위확률=[클래스 11(0.0266), 클래스 13(0.0265), 클래스 19(0.0262)]\n",
      "Step 0 - Total: 2.9081, Intent: 3.6351, NER: -0.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  27/1000 04:18 < 2:47:56, 0.10 it/s, Epoch 0.26/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Intent Accuracy</th>\n",
       "      <th>Intent F1 Macro</th>\n",
       "      <th>Intent F1 Weighted</th>\n",
       "      <th>Ner F1</th>\n",
       "      <th>Joint Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.019700</td>\n",
       "      <td>1.869557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 확률 - 최대: 클래스 16 (0.0297), 최소: 클래스 22 (0.0219)\n",
      "샘플 0: 예측=16, 실제=0, 상위확률=[클래스 16(0.0314), 클래스 1(0.0309), 클래스 4(0.0299)]\n",
      "샘플 1: 예측=16, 실제=0, 상위확률=[클래스 16(0.0314), 클래스 1(0.0309), 클래스 4(0.0299)]\n",
      "샘플 2: 예측=16, 실제=0, 상위확률=[클래스 16(0.0326), 클래스 7(0.0314), 클래스 1(0.0303)]\n",
      "샘플 3: 예측=16, 실제=0, 상위확률=[클래스 16(0.0324), 클래스 1(0.0312), 클래스 10(0.0311)]\n",
      "샘플 4: 예측=1, 실제=0, 상위확률=[클래스 1(0.0314), 클래스 16(0.0313), 클래스 4(0.0300)]\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0289), 최소: 클래스 18 (0.0221)\n",
      "샘플 0: 예측=7, 실제=0, 상위확률=[클래스 7(0.0311), 클래스 1(0.0309), 클래스 16(0.0304)]\n",
      "샘플 1: 예측=7, 실제=0, 상위확률=[클래스 7(0.0311), 클래스 1(0.0309), 클래스 16(0.0304)]\n",
      "샘플 2: 예측=11, 실제=0, 상위확률=[클래스 11(0.0270), 클래스 16(0.0265), 클래스 3(0.0261)]\n",
      "샘플 3: 예측=1, 실제=0, 상위확률=[클래스 1(0.0315), 클래스 16(0.0308), 클래스 26(0.0294)]\n",
      "샘플 4: 예측=13, 실제=0, 상위확률=[클래스 13(0.0268), 클래스 0(0.0268), 클래스 14(0.0265)]\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0293), 최소: 클래스 22 (0.0219)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0279), 클래스 30(0.0271), 클래스 13(0.0270)]\n",
      "샘플 1: 예측=1, 실제=0, 상위확률=[클래스 1(0.0317), 클래스 16(0.0316), 클래스 0(0.0292)]\n",
      "샘플 2: 예측=9, 실제=0, 상위확률=[클래스 9(0.0269), 클래스 36(0.0267), 클래스 18(0.0267)]\n",
      "샘플 3: 예측=1, 실제=0, 상위확률=[클래스 1(0.0316), 클래스 16(0.0304), 클래스 4(0.0296)]\n",
      "샘플 4: 예측=16, 실제=0, 상위확률=[클래스 16(0.0273), 클래스 19(0.0272), 클래스 36(0.0267)]\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0298), 최소: 클래스 18 (0.0217)\n",
      "샘플 0: 예측=16, 실제=0, 상위확률=[클래스 16(0.0303), 클래스 1(0.0302), 클래스 7(0.0301)]\n",
      "샘플 1: 예측=16, 실제=0, 상위확률=[클래스 16(0.0306), 클래스 10(0.0297), 클래스 4(0.0295)]\n",
      "샘플 2: 예측=16, 실제=0, 상위확률=[클래스 16(0.0317), 클래스 1(0.0312), 클래스 10(0.0303)]\n",
      "샘플 3: 예측=16, 실제=0, 상위확률=[클래스 16(0.0320), 클래스 1(0.0312), 클래스 26(0.0291)]\n",
      "샘플 4: 예측=30, 실제=0, 상위확률=[클래스 30(0.0274), 클래스 25(0.0274), 클래스 24(0.0266)]\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0305), 최소: 클래스 18 (0.0214)\n",
      "샘플 0: 예측=16, 실제=0, 상위확률=[클래스 16(0.0322), 클래스 7(0.0302), 클래스 1(0.0299)]\n",
      "샘플 1: 예측=1, 실제=0, 상위확률=[클래스 1(0.0310), 클래스 10(0.0307), 클래스 16(0.0297)]\n",
      "샘플 2: 예측=16, 실제=0, 상위확률=[클래스 16(0.0321), 클래스 1(0.0311), 클래스 7(0.0296)]\n",
      "샘플 3: 예측=16, 실제=0, 상위확률=[클래스 16(0.0320), 클래스 7(0.0308), 클래스 1(0.0286)]\n",
      "샘플 4: 예측=16, 실제=0, 상위확률=[클래스 16(0.0322), 클래스 7(0.0302), 클래스 1(0.0299)]\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0290), 최소: 클래스 18 (0.0221)\n",
      "샘플 0: 예측=16, 실제=0, 상위확률=[클래스 16(0.0320), 클래스 1(0.0317), 클래스 26(0.0298)]\n",
      "샘플 1: 예측=36, 실제=0, 상위확률=[클래스 36(0.0285), 클래스 9(0.0272), 클래스 30(0.0270)]\n",
      "샘플 2: 예측=1, 실제=0, 상위확률=[클래스 1(0.0327), 클래스 16(0.0321), 클래스 7(0.0321)]\n",
      "샘플 3: 예측=1, 실제=0, 상위확률=[클래스 1(0.0327), 클래스 16(0.0321), 클래스 7(0.0321)]\n",
      "샘플 4: 예측=16, 실제=0, 상위확률=[클래스 16(0.0309), 클래스 26(0.0304), 클래스 1(0.0300)]\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0295), 최소: 클래스 18 (0.0217)\n",
      "샘플 0: 예측=16, 실제=0, 상위확률=[클래스 16(0.0309), 클래스 7(0.0296), 클래스 1(0.0292)]\n",
      "샘플 1: 예측=16, 실제=0, 상위확률=[클래스 16(0.0322), 클래스 1(0.0320), 클래스 39(0.0295)]\n",
      "샘플 2: 예측=25, 실제=0, 상위확률=[클래스 25(0.0273), 클래스 24(0.0267), 클래스 16(0.0261)]\n",
      "샘플 3: 예측=25, 실제=0, 상위확률=[클래스 25(0.0273), 클래스 24(0.0267), 클래스 16(0.0261)]\n",
      "샘플 4: 예측=16, 실제=0, 상위확률=[클래스 16(0.0322), 클래스 1(0.0320), 클래스 39(0.0295)]\n",
      "클래스별 확률 - 최대: 클래스 1 (0.0310), 최소: 클래스 3 (0.0208)\n",
      "샘플 0: 예측=1, 실제=0, 상위확률=[클래스 1(0.0320), 클래스 7(0.0309), 클래스 16(0.0309)]\n",
      "샘플 1: 예측=1, 실제=0, 상위확률=[클래스 1(0.0322), 클래스 16(0.0313), 클래스 7(0.0302)]\n",
      "샘플 2: 예측=1, 실제=0, 상위확률=[클래스 1(0.0322), 클래스 16(0.0313), 클래스 7(0.0302)]\n",
      "샘플 3: 예측=1, 실제=0, 상위확률=[클래스 1(0.0320), 클래스 7(0.0309), 클래스 16(0.0309)]\n",
      "샘플 4: 예측=1, 실제=0, 상위확률=[클래스 1(0.0322), 클래스 16(0.0313), 클래스 7(0.0302)]\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0297), 최소: 클래스 22 (0.0222)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0272), 클래스 30(0.0271), 클래스 25(0.0267)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0277), 클래스 18(0.0267), 클래스 6(0.0266)]\n",
      "샘플 2: 예측=35, 실제=0, 상위확률=[클래스 35(0.0277), 클래스 19(0.0277), 클래스 16(0.0275)]\n",
      "샘플 3: 예측=16, 실제=0, 상위확률=[클래스 16(0.0321), 클래스 10(0.0309), 클래스 4(0.0307)]\n",
      "샘플 4: 예측=16, 실제=0, 상위확률=[클래스 16(0.0312), 클래스 1(0.0302), 클래스 10(0.0299)]\n",
      "Step 5 - Total: 2.8750, Intent: 3.5937, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0289), 최소: 클래스 18 (0.0223)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0279), 클래스 6(0.0270), 클래스 16(0.0269)]\n",
      "샘플 1: 예측=16, 실제=0, 상위확률=[클래스 16(0.0309), 클래스 10(0.0308), 클래스 4(0.0307)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0272), 클래스 17(0.0267), 클래스 32(0.0266)]\n",
      "샘플 3: 예측=16, 실제=0, 상위확률=[클래스 16(0.0309), 클래스 10(0.0308), 클래스 4(0.0307)]\n",
      "샘플 4: 예측=1, 실제=0, 상위확률=[클래스 1(0.0327), 클래스 16(0.0302), 클래스 4(0.0292)]\n",
      "Step 5 - Total: 2.8935, Intent: 3.6168, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0295), 최소: 클래스 3 (0.0223)\n",
      "샘플 0: 예측=7, 실제=0, 상위확률=[클래스 7(0.0273), 클래스 0(0.0270), 클래스 4(0.0264)]\n",
      "샘플 1: 예측=1, 실제=0, 상위확률=[클래스 1(0.0317), 클래스 16(0.0314), 클래스 7(0.0307)]\n",
      "샘플 2: 예측=7, 실제=0, 상위확률=[클래스 7(0.0314), 클래스 1(0.0307), 클래스 16(0.0307)]\n",
      "샘플 3: 예측=16, 실제=0, 상위확률=[클래스 16(0.0317), 클래스 7(0.0313), 클래스 1(0.0297)]\n",
      "샘플 4: 예측=16, 실제=0, 상위확률=[클래스 16(0.0282), 클래스 30(0.0268), 클래스 9(0.0267)]\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0299), 최소: 클래스 18 (0.0219)\n",
      "샘플 0: 예측=16, 실제=0, 상위확률=[클래스 16(0.0306), 클래스 4(0.0300), 클래스 1(0.0297)]\n",
      "샘플 1: 예측=16, 실제=0, 상위확률=[클래스 16(0.0321), 클래스 1(0.0308), 클래스 10(0.0308)]\n",
      "샘플 2: 예측=16, 실제=0, 상위확률=[클래스 16(0.0320), 클래스 7(0.0304), 클래스 1(0.0299)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0286), 클래스 9(0.0265), 클래스 1(0.0265)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0276), 클래스 9(0.0271), 클래스 19(0.0268)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0288), 최소: 클래스 18 (0.0225)\n",
      "샘플 0: 예측=1, 실제=0, 상위확률=[클래스 1(0.0316), 클래스 4(0.0305), 클래스 26(0.0299)]\n",
      "샘플 1: 예측=1, 실제=0, 상위확률=[클래스 1(0.0321), 클래스 16(0.0308), 클래스 4(0.0304)]\n",
      "샘플 2: 예측=24, 실제=0, 상위확률=[클래스 24(0.0275), 클래스 25(0.0273), 클래스 0(0.0269)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0272), 클래스 19(0.0272), 클래스 25(0.0265)]\n",
      "샘플 4: 예측=1, 실제=0, 상위확률=[클래스 1(0.0326), 클래스 0(0.0322), 클래스 16(0.0311)]\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0301), 최소: 클래스 18 (0.0212)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0271), 클래스 32(0.0263), 클래스 4(0.0260)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0283), 클래스 11(0.0271), 클래스 4(0.0263)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0271), 클래스 32(0.0263), 클래스 4(0.0260)]\n",
      "샘플 3: 예측=16, 실제=0, 상위확률=[클래스 16(0.0320), 클래스 0(0.0319), 클래스 7(0.0313)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0271), 클래스 32(0.0263), 클래스 4(0.0260)]\n",
      "클래스별 확률 - 최대: 클래스 16 (0.0297), 최소: 클래스 18 (0.0219)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0317), 클래스 30(0.0272), 클래스 36(0.0266)]\n",
      "샘플 1: 예측=1, 실제=0, 상위확률=[클래스 1(0.0325), 클래스 16(0.0308), 클래스 7(0.0303)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0276), 클래스 30(0.0273), 클래스 16(0.0267)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0317), 클래스 1(0.0311), 클래스 7(0.0306)]\n",
      "샘플 4: 예측=16, 실제=0, 상위확률=[클래스 16(0.0313), 클래스 1(0.0308), 클래스 10(0.0299)]\n",
      "클래스별 확률 - 최대: 클래스 1 (0.0298), 최소: 클래스 18 (0.0219)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0283), 클래스 30(0.0265), 클래스 36(0.0262)]\n",
      "샘플 1: 예측=1, 실제=0, 상위확률=[클래스 1(0.0329), 클래스 16(0.0310), 클래스 4(0.0297)]\n",
      "샘플 2: 예측=1, 실제=0, 상위확률=[클래스 1(0.0316), 클래스 16(0.0306), 클래스 10(0.0301)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0312), 클래스 27(0.0270), 클래스 30(0.0270)]\n",
      "샘플 4: 예측=1, 실제=0, 상위확률=[클래스 1(0.0329), 클래스 16(0.0310), 클래스 4(0.0297)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0308), 최소: 클래스 28 (0.0220)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0319), 클래스 16(0.0309), 클래스 1(0.0302)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0302), 클래스 37(0.0271), 클래스 30(0.0270)]\n",
      "샘플 2: 예측=16, 실제=0, 상위확률=[클래스 16(0.0328), 클래스 1(0.0316), 클래스 0(0.0302)]\n",
      "샘플 3: 예측=16, 실제=0, 상위확률=[클래스 16(0.0328), 클래스 1(0.0316), 클래스 0(0.0302)]\n",
      "샘플 4: 예측=1, 실제=0, 상위확률=[클래스 1(0.0323), 클래스 16(0.0319), 클래스 0(0.0308)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0304), 최소: 클래스 18 (0.0214)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0288), 클래스 25(0.0271), 클래스 36(0.0264)]\n",
      "샘플 1: 예측=16, 실제=0, 상위확률=[클래스 16(0.0310), 클래스 0(0.0308), 클래스 7(0.0295)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0309), 클래스 10(0.0308), 클래스 1(0.0306)]\n",
      "샘플 3: 예측=10, 실제=0, 상위확률=[클래스 10(0.0313), 클래스 16(0.0310), 클래스 0(0.0307)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0318), 클래스 16(0.0300), 클래스 1(0.0299)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0317), 최소: 클래스 3 (0.0219)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0325), 클래스 11(0.0275), 클래스 16(0.0273)]\n",
      "샘플 1: 예측=1, 실제=0, 상위확률=[클래스 1(0.0324), 클래스 16(0.0318), 클래스 7(0.0307)]\n",
      "샘플 2: 예측=1, 실제=0, 상위확률=[클래스 1(0.0315), 클래스 0(0.0307), 클래스 16(0.0304)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0325), 클래스 11(0.0275), 클래스 16(0.0273)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0287), 클래스 25(0.0264), 클래스 19(0.0261)]\n",
      "Step 10 - Total: 2.7627, Intent: 3.4534, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0321), 최소: 클래스 18 (0.0218)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0316), 클래스 16(0.0311), 클래스 1(0.0303)]\n",
      "샘플 1: 예측=16, 실제=0, 상위확률=[클래스 16(0.0319), 클래스 1(0.0313), 클래스 4(0.0300)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0333), 클래스 1(0.0317), 클래스 16(0.0312)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0317), 클래스 30(0.0272), 클래스 36(0.0271)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0333), 클래스 1(0.0317), 클래스 16(0.0312)]\n",
      "Step 10 - Total: 2.7535, Intent: 3.4419, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0324), 최소: 클래스 3 (0.0221)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0338), 클래스 16(0.0321), 클래스 1(0.0298)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0322), 클래스 16(0.0310), 클래스 1(0.0304)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0301), 클래스 30(0.0275), 클래스 36(0.0273)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0342), 클래스 1(0.0307), 클래스 16(0.0305)]\n",
      "샘플 4: 예측=16, 실제=0, 상위확률=[클래스 16(0.0313), 클래스 0(0.0311), 클래스 7(0.0308)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0334), 최소: 클래스 3 (0.0216)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0333), 클래스 16(0.0274), 클래스 7(0.0270)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0343), 클래스 1(0.0326), 클래스 16(0.0312)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0324), 클래스 1(0.0317), 클래스 10(0.0308)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0338), 클래스 16(0.0312), 클래스 1(0.0300)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0347), 클래스 16(0.0307), 클래스 1(0.0304)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0340), 최소: 클래스 28 (0.0225)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0351), 클래스 1(0.0322), 클래스 7(0.0314)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0345), 클래스 25(0.0275), 클래스 9(0.0265)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0312), 클래스 19(0.0267), 클래스 16(0.0258)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0317), 클래스 17(0.0266), 클래스 26(0.0266)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0380), 클래스 10(0.0306), 클래스 1(0.0305)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0342), 최소: 클래스 18 (0.0218)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0350), 클래스 1(0.0323), 클래스 16(0.0300)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0374), 클래스 1(0.0322), 클래스 16(0.0311)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0374), 클래스 1(0.0322), 클래스 16(0.0311)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0374), 클래스 1(0.0322), 클래스 16(0.0311)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0372), 클래스 1(0.0305), 클래스 16(0.0302)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0360), 최소: 클래스 28 (0.0218)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0390), 클래스 1(0.0319), 클래스 7(0.0316)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0354), 클래스 1(0.0321), 클래스 7(0.0303)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0379), 클래스 30(0.0276), 클래스 9(0.0268)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0354), 클래스 1(0.0321), 클래스 7(0.0303)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0377), 클래스 16(0.0326), 클래스 7(0.0310)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0357), 최소: 클래스 3 (0.0213)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0356), 클래스 1(0.0306), 클래스 4(0.0302)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0352), 클래스 7(0.0279), 클래스 16(0.0274)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0356), 클래스 1(0.0306), 클래스 4(0.0302)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0360), 클래스 1(0.0330), 클래스 4(0.0315)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0345), 클래스 4(0.0314), 클래스 10(0.0308)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0381), 최소: 클래스 28 (0.0216)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0396), 클래스 7(0.0309), 클래스 16(0.0295)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0374), 클래스 1(0.0329), 클래스 16(0.0299)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0374), 클래스 1(0.0329), 클래스 16(0.0299)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0354), 클래스 1(0.0311), 클래스 7(0.0305)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0400), 클래스 1(0.0314), 클래스 10(0.0300)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0387), 최소: 클래스 3 (0.0213)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0367), 클래스 1(0.0315), 클래스 10(0.0309)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0400), 클래스 1(0.0312), 클래스 26(0.0297)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0360), 클래스 1(0.0329), 클래스 16(0.0290)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0367), 클래스 1(0.0315), 클래스 10(0.0309)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0367), 클래스 1(0.0315), 클래스 10(0.0309)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0416), 최소: 클래스 28 (0.0217)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0425), 클래스 1(0.0333), 클래스 16(0.0304)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0420), 클래스 1(0.0333), 클래스 7(0.0319)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0399), 클래스 7(0.0305), 클래스 1(0.0303)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0468), 클래스 1(0.0313), 클래스 16(0.0304)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0407), 클래스 1(0.0307), 클래스 7(0.0306)]\n",
      "Step 15 - Total: 2.5455, Intent: 3.1819, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0408), 최소: 클래스 28 (0.0220)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0390), 클래스 30(0.0274), 클래스 7(0.0269)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0443), 클래스 1(0.0317), 클래스 7(0.0303)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0418), 클래스 7(0.0263), 클래스 21(0.0261)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0406), 클래스 1(0.0321), 클래스 4(0.0304)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0443), 클래스 1(0.0317), 클래스 7(0.0303)]\n",
      "Step 15 - Total: 2.5604, Intent: 3.2006, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0435), 최소: 클래스 28 (0.0219)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0391), 클래스 30(0.0269), 클래스 21(0.0266)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0410), 클래스 21(0.0308), 클래스 7(0.0302)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0402), 클래스 10(0.0317), 클래스 1(0.0316)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0431), 클래스 1(0.0316), 클래스 16(0.0303)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0477), 클래스 1(0.0315), 클래스 10(0.0302)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0438), 최소: 클래스 28 (0.0214)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0463), 클래스 7(0.0331), 클래스 1(0.0328)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0463), 클래스 7(0.0331), 클래스 1(0.0328)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0395), 클래스 15(0.0280), 클래스 37(0.0277)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0372), 클래스 21(0.0267), 클래스 30(0.0265)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0452), 클래스 7(0.0283), 클래스 30(0.0276)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0446), 최소: 클래스 18 (0.0215)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0422), 클래스 30(0.0273), 클래스 19(0.0264)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0382), 클래스 24(0.0267), 클래스 30(0.0264)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0377), 클래스 1(0.0320), 클래스 16(0.0316)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0477), 클래스 1(0.0337), 클래스 16(0.0319)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0394), 클래스 4(0.0314), 클래스 16(0.0314)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0462), 최소: 클래스 28 (0.0213)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0495), 클래스 7(0.0305), 클래스 1(0.0301)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0469), 클래스 1(0.0313), 클래스 7(0.0301)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0495), 클래스 7(0.0305), 클래스 1(0.0301)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0515), 클래스 1(0.0313), 클래스 21(0.0293)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0467), 클래스 1(0.0328), 클래스 4(0.0297)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0475), 최소: 클래스 28 (0.0219)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0467), 클래스 30(0.0275), 클래스 13(0.0270)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0518), 클래스 7(0.0320), 클래스 10(0.0307)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0472), 클래스 7(0.0311), 클래스 1(0.0304)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0518), 클래스 21(0.0287), 클래스 24(0.0274)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0463), 클래스 13(0.0277), 클래스 20(0.0273)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0487), 최소: 클래스 28 (0.0211)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0490), 클래스 21(0.0279), 클래스 1(0.0264)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0519), 클래스 1(0.0300), 클래스 7(0.0298)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0492), 클래스 1(0.0313), 클래스 7(0.0307)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0490), 클래스 21(0.0279), 클래스 1(0.0264)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0478), 클래스 1(0.0307), 클래스 10(0.0302)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0524), 최소: 클래스 28 (0.0214)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0437), 클래스 1(0.0321), 클래스 10(0.0296)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0483), 클래스 30(0.0280), 클래스 21(0.0268)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0483), 클래스 30(0.0280), 클래스 21(0.0268)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0620), 클래스 1(0.0309), 클래스 7(0.0305)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0620), 클래스 1(0.0309), 클래스 7(0.0305)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0524), 최소: 클래스 28 (0.0213)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0536), 클래스 1(0.0310), 클래스 16(0.0306)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0495), 클래스 21(0.0286), 클래스 30(0.0268)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0481), 클래스 21(0.0281), 클래스 30(0.0278)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0501), 클래스 30(0.0265), 클래스 21(0.0264)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0526), 클래스 7(0.0309), 클래스 1(0.0304)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0582), 최소: 클래스 9 (0.0210)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0570), 클래스 7(0.0317), 클래스 1(0.0308)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0625), 클래스 7(0.0314), 클래스 16(0.0300)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0538), 클래스 30(0.0277), 클래스 24(0.0267)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0576), 클래스 4(0.0296), 클래스 10(0.0294)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0604), 클래스 1(0.0312), 클래스 16(0.0306)]\n",
      "Step 20 - Total: 2.2765, Intent: 2.8456, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0564), 최소: 클래스 31 (0.0214)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0530), 클래스 30(0.0284), 클래스 21(0.0268)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0567), 클래스 1(0.0327), 클래스 7(0.0304)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0627), 클래스 1(0.0323), 클래스 10(0.0293)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0665), 클래스 7(0.0310), 클래스 16(0.0301)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0665), 클래스 7(0.0310), 클래스 16(0.0301)]\n",
      "Step 20 - Total: 2.3038, Intent: 2.8798, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0635), 최소: 클래스 31 (0.0209)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0575), 클래스 21(0.0284), 클래스 24(0.0273)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0621), 클래스 30(0.0280), 클래스 21(0.0278)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0511), 클래스 21(0.0270), 클래스 4(0.0268)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0575), 클래스 21(0.0284), 클래스 24(0.0273)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0591), 클래스 7(0.0315), 클래스 10(0.0313)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0647), 최소: 클래스 9 (0.0206)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0608), 클래스 7(0.0311), 클래스 21(0.0305)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0689), 클래스 30(0.0295), 클래스 24(0.0277)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0716), 클래스 1(0.0303), 클래스 7(0.0302)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0617), 클래스 6(0.0282), 클래스 21(0.0279)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0636), 클래스 7(0.0315), 클래스 1(0.0313)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0682), 최소: 클래스 28 (0.0205)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0683), 클래스 24(0.0278), 클래스 21(0.0276)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0550), 클래스 7(0.0275), 클래스 30(0.0268)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0666), 클래스 15(0.0276), 클래스 7(0.0276)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0691), 클래스 21(0.0292), 클래스 24(0.0274)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0756), 클래스 10(0.0296), 클래스 30(0.0289)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0673), 최소: 클래스 31 (0.0205)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0742), 클래스 30(0.0275), 클래스 1(0.0268)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0661), 클래스 7(0.0319), 클래스 1(0.0311)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0500), 클래스 30(0.0298), 클래스 21(0.0268)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0662), 클래스 1(0.0302), 클래스 10(0.0295)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0714), 클래스 24(0.0296), 클래스 10(0.0293)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0750), 최소: 클래스 9 (0.0201)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0608), 클래스 21(0.0291), 클래스 24(0.0278)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0608), 클래스 21(0.0291), 클래스 24(0.0278)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0608), 클래스 21(0.0291), 클래스 24(0.0278)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0827), 클래스 30(0.0280), 클래스 24(0.0277)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0670), 클래스 1(0.0311), 클래스 7(0.0308)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0731), 최소: 클래스 31 (0.0206)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0729), 클래스 21(0.0276), 클래스 15(0.0270)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0787), 클래스 7(0.0304), 클래스 21(0.0303)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0761), 클래스 30(0.0283), 클래스 7(0.0279)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0706), 클래스 21(0.0276), 클래스 1(0.0273)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0830), 클래스 39(0.0296), 클래스 1(0.0290)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0766), 최소: 클래스 28 (0.0203)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0711), 클래스 21(0.0293), 클래스 30(0.0286)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0852), 클래스 21(0.0309), 클래스 7(0.0304)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0590), 클래스 21(0.0284), 클래스 30(0.0283)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0785), 클래스 19(0.0301), 클래스 1(0.0295)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0879), 클래스 30(0.0302), 클래스 21(0.0295)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0851), 최소: 클래스 31 (0.0198)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0838), 클래스 1(0.0307), 클래스 21(0.0300)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0912), 클래스 1(0.0300), 클래스 16(0.0279)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0911), 클래스 21(0.0298), 클래스 1(0.0294)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0781), 클래스 4(0.0308), 클래스 1(0.0303)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0912), 클래스 1(0.0300), 클래스 16(0.0279)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `ImprovedRobertaForJointIntentAndNER.forward` and have been ignored: text, intent_label. If text, intent_label are not expected by `ImprovedRobertaForJointIntentAndNER.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 687\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 확률 - 최대: 클래스 0 (0.0972), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0970), 클래스 21(0.0291), 클래스 7(0.0281)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0974), 클래스 21(0.0293), 클래스 1(0.0280)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0949), 클래스 21(0.0293), 클래스 7(0.0288)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0975), 클래스 21(0.0293), 클래스 1(0.0283)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0974), 클래스 21(0.0284), 클래스 7(0.0279)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0972), 최소: 클래스 9 (0.0193)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0989), 클래스 21(0.0300), 클래스 1(0.0284)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0953), 클래스 21(0.0298), 클래스 1(0.0287)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0928), 클래스 21(0.0289), 클래스 1(0.0285)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0982), 클래스 21(0.0288), 클래스 1(0.0281)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0995), 클래스 21(0.0292), 클래스 7(0.0280)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0967), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0969), 클래스 21(0.0293), 클래스 1(0.0283)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0972), 클래스 21(0.0293), 클래스 7(0.0285)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.1007), 클래스 21(0.0292), 클래스 1(0.0279)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0954), 클래스 21(0.0293), 클래스 1(0.0281)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0969), 클래스 21(0.0297), 클래스 1(0.0288)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0969), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0905), 클래스 21(0.0288), 클래스 1(0.0286)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.1002), 클래스 21(0.0294), 클래스 1(0.0281)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0970), 클래스 21(0.0296), 클래스 7(0.0279)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0970), 클래스 21(0.0296), 클래스 7(0.0279)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0961), 클래스 21(0.0293), 클래스 1(0.0281)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0965), 최소: 클래스 9 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.1003), 클래스 21(0.0298), 클래스 1(0.0284)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0963), 클래스 21(0.0298), 클래스 1(0.0285)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0912), 클래스 21(0.0289), 클래스 1(0.0284)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0890), 클래스 7(0.0287), 클래스 1(0.0286)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0912), 클래스 21(0.0289), 클래스 1(0.0284)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0958), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0953), 클래스 21(0.0290), 클래스 1(0.0285)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0985), 클래스 21(0.0296), 클래스 7(0.0279)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0992), 클래스 21(0.0294), 클래스 1(0.0280)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0868), 클래스 1(0.0288), 클래스 21(0.0286)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0975), 클래스 21(0.0295), 클래스 7(0.0278)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0983), 최소: 클래스 9 (0.0193)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0997), 클래스 21(0.0293), 클래스 1(0.0282)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0973), 클래스 21(0.0297), 클래스 1(0.0282)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0982), 클래스 21(0.0294), 클래스 1(0.0280)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0985), 클래스 21(0.0290), 클래스 1(0.0278)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0982), 클래스 21(0.0294), 클래스 1(0.0280)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0963), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0890), 클래스 21(0.0289), 클래스 1(0.0284)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0965), 클래스 21(0.0289), 클래스 1(0.0284)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0938), 클래스 21(0.0289), 클래스 1(0.0285)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0965), 클래스 21(0.0289), 클래스 1(0.0284)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0947), 클래스 21(0.0295), 클래스 1(0.0285)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0968), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0991), 클래스 21(0.0294), 클래스 1(0.0282)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0988), 클래스 21(0.0295), 클래스 1(0.0279)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0983), 클래스 21(0.0292), 클래스 1(0.0282)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0979), 클래스 21(0.0294), 클래스 7(0.0279)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0980), 클래스 21(0.0292), 클래스 1(0.0285)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0968), 최소: 클래스 9 (0.0193)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0964), 클래스 21(0.0295), 클래스 1(0.0283)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0977), 클래스 21(0.0302), 클래스 1(0.0282)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0977), 클래스 21(0.0302), 클래스 1(0.0282)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0957), 클래스 21(0.0298), 클래스 1(0.0291)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0984), 클래스 21(0.0293), 클래스 1(0.0280)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0967), 최소: 클래스 9 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0980), 클래스 21(0.0290), 클래스 1(0.0283)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0962), 클래스 21(0.0289), 클래스 1(0.0285)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0952), 클래스 21(0.0289), 클래스 7(0.0284)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0936), 클래스 21(0.0288), 클래스 1(0.0280)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0918), 클래스 21(0.0290), 클래스 1(0.0286)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0975), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0988), 클래스 21(0.0295), 클래스 1(0.0283)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0966), 클래스 21(0.0295), 클래스 1(0.0276)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0975), 클래스 21(0.0298), 클래스 1(0.0284)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0946), 클래스 21(0.0292), 클래스 1(0.0286)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0975), 클래스 21(0.0298), 클래스 1(0.0284)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0967), 최소: 클래스 35 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0956), 클래스 21(0.0296), 클래스 1(0.0286)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0965), 클래스 21(0.0294), 클래스 1(0.0284)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0956), 클래스 21(0.0296), 클래스 1(0.0286)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0948), 클래스 21(0.0293), 클래스 1(0.0289)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0987), 클래스 21(0.0303), 클래스 1(0.0280)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0966), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0992), 클래스 21(0.0293), 클래스 1(0.0278)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0973), 클래스 21(0.0289), 클래스 7(0.0280)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0968), 클래스 21(0.0292), 클래스 1(0.0283)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0996), 클래스 21(0.0298), 클래스 1(0.0279)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0945), 클래스 21(0.0289), 클래스 1(0.0283)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0972), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0983), 클래스 21(0.0294), 클래스 7(0.0279)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0983), 클래스 21(0.0294), 클래스 7(0.0279)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0963), 클래스 21(0.0290), 클래스 1(0.0285)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0990), 클래스 21(0.0293), 클래스 1(0.0280)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0975), 클래스 21(0.0292), 클래스 1(0.0282)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0974), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0976), 클래스 21(0.0299), 클래스 1(0.0283)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0983), 클래스 21(0.0290), 클래스 1(0.0283)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0983), 클래스 21(0.0295), 클래스 1(0.0287)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0952), 클래스 21(0.0293), 클래스 1(0.0279)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0976), 클래스 21(0.0289), 클래스 7(0.0282)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0963), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0951), 클래스 21(0.0296), 클래스 1(0.0280)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0949), 클래스 21(0.0300), 클래스 1(0.0286)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0964), 클래스 21(0.0290), 클래스 1(0.0284)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0983), 클래스 21(0.0301), 클래스 1(0.0281)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0957), 클래스 21(0.0290), 클래스 1(0.0282)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0967), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0955), 클래스 21(0.0294), 클래스 1(0.0286)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0946), 클래스 21(0.0295), 클래스 1(0.0282)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0944), 클래스 21(0.0295), 클래스 1(0.0285)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0965), 클래스 21(0.0297), 클래스 1(0.0282)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0963), 클래스 21(0.0293), 클래스 1(0.0281)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0959), 최소: 클래스 8 (0.0196)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0962), 클래스 21(0.0297), 클래스 1(0.0281)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0986), 클래스 21(0.0297), 클래스 7(0.0283)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0962), 클래스 21(0.0297), 클래스 1(0.0281)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0928), 클래스 21(0.0289), 클래스 1(0.0285)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0980), 클래스 21(0.0296), 클래스 7(0.0282)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0967), 최소: 클래스 9 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0958), 클래스 21(0.0288), 클래스 1(0.0284)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0930), 클래스 21(0.0288), 클래스 1(0.0284)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0976), 클래스 21(0.0294), 클래스 1(0.0280)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0973), 클래스 21(0.0289), 클래스 1(0.0285)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0964), 클래스 21(0.0288), 클래스 1(0.0285)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0952), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0916), 클래스 21(0.0288), 클래스 7(0.0284)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0986), 클래스 21(0.0294), 클래스 7(0.0283)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0975), 클래스 21(0.0296), 클래스 1(0.0285)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0975), 클래스 21(0.0296), 클래스 1(0.0291)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0993), 클래스 21(0.0292), 클래스 1(0.0279)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0956), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0960), 클래스 21(0.0294), 클래스 1(0.0289)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0966), 클래스 21(0.0294), 클래스 7(0.0279)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0953), 클래스 21(0.0287), 클래스 1(0.0282)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0953), 클래스 21(0.0287), 클래스 1(0.0282)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0981), 클래스 21(0.0296), 클래스 1(0.0281)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0968), 최소: 클래스 35 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0969), 클래스 21(0.0296), 클래스 7(0.0282)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0972), 클래스 21(0.0298), 클래스 7(0.0281)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0970), 클래스 21(0.0295), 클래스 1(0.0284)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0975), 클래스 21(0.0296), 클래스 1(0.0281)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0963), 클래스 21(0.0293), 클래스 1(0.0285)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0968), 최소: 클래스 9 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0951), 클래스 21(0.0299), 클래스 1(0.0287)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0981), 클래스 21(0.0292), 클래스 1(0.0287)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0984), 클래스 21(0.0288), 클래스 1(0.0281)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0994), 클래스 21(0.0291), 클래스 7(0.0280)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0984), 클래스 21(0.0288), 클래스 1(0.0281)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0971), 최소: 클래스 9 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0962), 클래스 21(0.0291), 클래스 7(0.0284)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0971), 클래스 21(0.0289), 클래스 7(0.0281)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0965), 클래스 21(0.0290), 클래스 1(0.0284)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0986), 클래스 21(0.0295), 클래스 1(0.0283)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0966), 클래스 21(0.0299), 클래스 7(0.0282)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0970), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0979), 클래스 21(0.0288), 클래스 1(0.0280)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0973), 클래스 21(0.0296), 클래스 1(0.0277)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0985), 클래스 21(0.0292), 클래스 1(0.0280)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0966), 클래스 21(0.0295), 클래스 1(0.0276)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0947), 클래스 21(0.0296), 클래스 7(0.0286)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0967), 최소: 클래스 9 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0979), 클래스 21(0.0291), 클래스 1(0.0281)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0995), 클래스 21(0.0287), 클래스 1(0.0283)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0915), 클래스 21(0.0291), 클래스 1(0.0287)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0977), 클래스 21(0.0299), 클래스 1(0.0278)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0920), 클래스 21(0.0287), 클래스 1(0.0283)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0966), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0957), 클래스 21(0.0289), 클래스 1(0.0287)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0992), 클래스 21(0.0294), 클래스 7(0.0283)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0992), 클래스 21(0.0294), 클래스 7(0.0283)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0936), 클래스 21(0.0299), 클래스 1(0.0284)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0936), 클래스 21(0.0299), 클래스 1(0.0284)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0973), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0990), 클래스 21(0.0295), 클래스 1(0.0288)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0950), 클래스 21(0.0289), 클래스 1(0.0286)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0982), 클래스 21(0.0290), 클래스 1(0.0280)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0930), 클래스 21(0.0292), 클래스 1(0.0281)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0982), 클래스 21(0.0290), 클래스 1(0.0280)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0963), 최소: 클래스 9 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0941), 클래스 21(0.0296), 클래스 1(0.0286)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0985), 클래스 21(0.0298), 클래스 1(0.0282)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0976), 클래스 21(0.0298), 클래스 1(0.0285)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0939), 클래스 21(0.0290), 클래스 1(0.0282)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0941), 클래스 21(0.0296), 클래스 1(0.0286)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0964), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0967), 클래스 21(0.0292), 클래스 1(0.0280)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0956), 클래스 21(0.0291), 클래스 7(0.0282)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0980), 클래스 21(0.0294), 클래스 7(0.0281)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0967), 클래스 21(0.0292), 클래스 1(0.0280)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0956), 클래스 21(0.0291), 클래스 7(0.0282)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0967), 최소: 클래스 9 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0993), 클래스 21(0.0292), 클래스 1(0.0284)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0984), 클래스 21(0.0294), 클래스 1(0.0284)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0960), 클래스 21(0.0300), 클래스 7(0.0282)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0993), 클래스 21(0.0292), 클래스 1(0.0284)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0883), 클래스 21(0.0289), 클래스 1(0.0285)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0964), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0965), 클래스 21(0.0295), 클래스 7(0.0284)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0996), 클래스 21(0.0291), 클래스 1(0.0281)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0936), 클래스 21(0.0295), 클래스 1(0.0283)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0980), 클래스 21(0.0293), 클래스 7(0.0281)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0967), 클래스 21(0.0290), 클래스 1(0.0285)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0970), 최소: 클래스 9 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0968), 클래스 21(0.0289), 클래스 7(0.0279)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0968), 클래스 21(0.0293), 클래스 1(0.0284)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0968), 클래스 21(0.0293), 클래스 1(0.0284)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0988), 클래스 21(0.0297), 클래스 1(0.0279)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0953), 클래스 21(0.0290), 클래스 1(0.0281)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0960), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0982), 클래스 21(0.0293), 클래스 1(0.0281)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0947), 클래스 21(0.0293), 클래스 7(0.0284)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0945), 클래스 21(0.0294), 클래스 7(0.0281)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0964), 클래스 21(0.0291), 클래스 7(0.0280)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0974), 클래스 21(0.0292), 클래스 1(0.0280)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0963), 최소: 클래스 9 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0993), 클래스 21(0.0299), 클래스 1(0.0278)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0987), 클래스 21(0.0290), 클래스 1(0.0283)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0939), 클래스 21(0.0299), 클래스 1(0.0281)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0973), 클래스 21(0.0288), 클래스 1(0.0282)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0953), 클래스 21(0.0291), 클래스 1(0.0285)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0957), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0981), 클래스 21(0.0293), 클래스 1(0.0282)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0969), 클래스 21(0.0293), 클래스 1(0.0284)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0935), 클래스 21(0.0288), 클래스 1(0.0285)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0969), 클래스 21(0.0293), 클래스 1(0.0284)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0973), 클래스 21(0.0294), 클래스 1(0.0282)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0956), 최소: 클래스 8 (0.0194)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0933), 클래스 21(0.0297), 클래스 1(0.0292)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0927), 클래스 21(0.0293), 클래스 1(0.0287)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0961), 클래스 21(0.0293), 클래스 7(0.0277)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0927), 클래스 21(0.0293), 클래스 1(0.0287)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0961), 클래스 21(0.0293), 클래스 7(0.0277)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0972), 최소: 클래스 9 (0.0193)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0986), 클래스 21(0.0292), 클래스 1(0.0287)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0934), 클래스 1(0.0288), 클래스 21(0.0288)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0979), 클래스 21(0.0291), 클래스 7(0.0281)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0983), 클래스 21(0.0306), 클래스 7(0.0278)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0992), 클래스 21(0.0295), 클래스 7(0.0281)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0964), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0954), 클래스 21(0.0295), 클래스 1(0.0287)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0976), 클래스 21(0.0292), 클래스 1(0.0282)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0976), 클래스 21(0.0292), 클래스 1(0.0282)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0954), 클래스 21(0.0295), 클래스 1(0.0287)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0954), 클래스 21(0.0295), 클래스 1(0.0287)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0970), 최소: 클래스 9 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0994), 클래스 21(0.0294), 클래스 1(0.0277)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0955), 클래스 21(0.0291), 클래스 1(0.0282)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0954), 클래스 21(0.0289), 클래스 1(0.0288)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0972), 클래스 21(0.0297), 클래스 1(0.0285)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0957), 클래스 21(0.0295), 클래스 1(0.0280)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0964), 최소: 클래스 9 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0995), 클래스 21(0.0291), 클래스 1(0.0280)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0952), 클래스 21(0.0295), 클래스 1(0.0285)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0982), 클래스 21(0.0294), 클래스 7(0.0279)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0950), 클래스 21(0.0300), 클래스 1(0.0285)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0991), 클래스 21(0.0292), 클래스 1(0.0279)]\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0967), 최소: 클래스 9 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0973), 클래스 21(0.0291), 클래스 1(0.0283)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0964), 클래스 21(0.0295), 클래스 7(0.0279)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0950), 클래스 21(0.0295), 클래스 1(0.0282)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0991), 클래스 21(0.0293), 클래스 1(0.0284)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0982), 클래스 21(0.0297), 클래스 7(0.0283)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daehy\\Desktop\\ai\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daehy\\Desktop\\ai\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:159: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "c:\\Users\\daehy\\Desktop\\ai\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\daehy\\Desktop\\ai\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\daehy\\Desktop\\ai\\venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\daehy\\Desktop\\ai\\venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "평가 지표 계산 오류: max() iterable argument is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "인텐트 예측 분포:\n",
      "  - search_book_title: 687개 (100.00%)\n",
      "\n",
      "상위 1개 클래스에 대한 혼동 행렬:\n",
      "  0 [search_book_title]:  687\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0948), 최소: 클래스 36 (0.0193)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0842), 클래스 1(0.0303), 클래스 10(0.0292)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.1039), 클래스 21(0.0296), 클래스 7(0.0288)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0976), 클래스 21(0.0323), 클래스 4(0.0293)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0883), 클래스 30(0.0297), 클래스 21(0.0273)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.1160), 클래스 21(0.0330), 클래스 30(0.0289)]\n",
      "Step 25 - Total: 1.8885, Intent: 2.3606, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 0 (0.0910), 최소: 클래스 8 (0.0195)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0798), 클래스 21(0.0288), 클래스 7(0.0274)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0929), 클래스 21(0.0288), 클래스 1(0.0286)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.0968), 클래스 4(0.0324), 클래스 7(0.0291)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0929), 클래스 21(0.0288), 클래스 1(0.0286)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.0968), 클래스 4(0.0324), 클래스 7(0.0291)]\n",
      "Step 25 - Total: 1.9229, Intent: 2.4036, NER: -0.0000\n",
      "클래스별 확률 - 최대: 클래스 0 (0.1002), 최소: 클래스 8 (0.0192)\n",
      "샘플 0: 예측=0, 실제=0, 상위확률=[클래스 0(0.0884), 클래스 10(0.0274), 클래스 30(0.0274)]\n",
      "샘플 1: 예측=0, 실제=0, 상위확률=[클래스 0(0.0884), 클래스 10(0.0274), 클래스 30(0.0274)]\n",
      "샘플 2: 예측=0, 실제=0, 상위확률=[클래스 0(0.1014), 클래스 1(0.0309), 클래스 7(0.0288)]\n",
      "샘플 3: 예측=0, 실제=0, 상위확률=[클래스 0(0.0982), 클래스 21(0.0291), 클래스 30(0.0269)]\n",
      "샘플 4: 예측=0, 실제=0, 상위확률=[클래스 0(0.1014), 클래스 1(0.0309), 클래스 7(0.0288)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import commentjson\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import logging  # 파이썬 기본 로깅\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    PreTrainedModel,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "# transformers의 로깅을 별도 이름으로 임포트\n",
    "from transformers import logging as transformers_logging\n",
    "from datasets import Dataset, Features, Value, Sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score as sklearn_f1_score\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "from torchcrf import CRF\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# --- 0. 기본 설정 ---\n",
    "MODEL_NAME = \"klue/roberta-base\"  # 모델 크기 증가 (base -> large)\n",
    "MAX_LEN = 256  # 시퀀스 길이 증가\n",
    "EPOCHS = 10    # 에폭 수 증가\n",
    "BATCH_SIZE = 16  # 배치 크기 증가\n",
    "LEARNING_RATE = 3e-5  # 학습률 최적화\n",
    "WARMUP_RATIO = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "INTENT_WEIGHT = 0.4  # Intent 태스크 가중치 조정\n",
    "NER_WEIGHT = 0.6     # NER 태스크 가중치 조정 (더 어려운 태스크에 가중치 부여)\n",
    "# 모델 저장 경로 설정\n",
    "INTEGRATED_MODEL_DIR = \"./models/integrated_nlu_improved\"\n",
    "INTEGRATED_LABEL_PATH = os.path.join(INTEGRATED_MODEL_DIR, \"nlu_labels.jsonc\")\n",
    "# Seed 설정 (재현성)\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "# 로깅 설정\n",
    "transformers_logging.set_verbosity_info()  # transformers 로깅 설정\n",
    "logger = logging.getLogger(__name__)  # 파이썬 기본 로깅 설정\n",
    "# --- 나머지 코드는 동일 ---\n",
    "# --- 1. 데이터 로드 함수 ---\n",
    "def load_intent_data():\n",
    "    print(\"인텐트 데이터 로드 중...\")\n",
    "    with open('intent_label_list.jsonc', 'r', encoding='utf-8') as f:\n",
    "        intent_label_list = commentjson.load(f)\n",
    "\n",
    "    # 레이블 매핑 정보 상세 출력 (디버깅용)\n",
    "    print(f\"인텐트 레이블 목록: {intent_label_list}\")\n",
    "    intent_label_to_id = {label: i for i, label in enumerate(intent_label_list)}\n",
    "    intent_id_to_label = {i: label for i, label in enumerate(intent_label_list)}\n",
    "    \n",
    "    print(\"레이블 매핑 정보:\")\n",
    "    for label, idx in intent_label_to_id.items():\n",
    "        print(f\"  '{label}' -> {idx}\")\n",
    "\n",
    "    with open('intent_data.jsonc', 'r', encoding='utf-8') as f:\n",
    "        intent_data = commentjson.load(f)\n",
    "\n",
    "    # 변환 전 원본 레이블 분포 확인\n",
    "    original_labels = {}\n",
    "    for item in intent_data:\n",
    "        # 가능한 모든 레이블 필드 확인\n",
    "        for key in [\"intent_label\", \"intent\", \"label\"]:\n",
    "            if key in item:\n",
    "                label_value = item[key]\n",
    "                if label_value not in original_labels:\n",
    "                    original_labels[label_value] = 0\n",
    "                original_labels[label_value] += 1\n",
    "                break\n",
    "    \n",
    "    print(\"\\n변환 전 원본 레이블 분포:\")\n",
    "    for label, count in sorted(original_labels.items()):\n",
    "        print(f\"  '{label}': {count}개\")\n",
    "\n",
    "    # 인텐트 데이터의 레이블 형식 확인 및 통일 (개선된 버전)\n",
    "    conversion_count = {\"success\": 0, \"default\": 0}\n",
    "    for item in intent_data:\n",
    "        # 원본 레이블 값 저장 (디버깅용)\n",
    "        original_label = None\n",
    "        converted_label = None\n",
    "        \n",
    "        # 1. intent_label 필드 처리\n",
    "        if \"intent_label\" in item:\n",
    "            original_label = item[\"intent_label\"]\n",
    "            # 이미 숫자인 경우\n",
    "            if isinstance(item[\"intent_label\"], int):\n",
    "                # 유효 범위 확인\n",
    "                if 0 <= item[\"intent_label\"] < len(intent_label_list):\n",
    "                    converted_label = item[\"intent_label\"]\n",
    "                    conversion_count[\"success\"] += 1\n",
    "                else:\n",
    "                    # 범위 벗어나면 0으로 기본 설정\n",
    "                    print(f\"경고: 범위 벗어난 레이블 값 ({item['intent_label']}) - 0으로 설정\")\n",
    "                    item[\"intent_label\"] = 0\n",
    "                    converted_label = 0\n",
    "                    conversion_count[\"default\"] += 1\n",
    "            # 문자열 레이블이면 ID로 변환\n",
    "            elif isinstance(item[\"intent_label\"], str):\n",
    "                if item[\"intent_label\"] in intent_label_to_id:\n",
    "                    item[\"intent_label\"] = intent_label_to_id[item[\"intent_label\"]]\n",
    "                    converted_label = item[\"intent_label\"]\n",
    "                    conversion_count[\"success\"] += 1\n",
    "                else:\n",
    "                    print(f\"경고: 알 수 없는 레이블 '{item['intent_label']}' - 0으로 설정\")\n",
    "                    item[\"intent_label\"] = 0\n",
    "                    converted_label = 0\n",
    "                    conversion_count[\"default\"] += 1\n",
    "        \n",
    "        # 2. intent 필드 처리\n",
    "        elif \"intent\" in item and isinstance(item[\"intent\"], str):\n",
    "            original_label = item[\"intent\"]\n",
    "            if item[\"intent\"] in intent_label_to_id:\n",
    "                item[\"intent_label\"] = intent_label_to_id[item[\"intent\"]]\n",
    "                converted_label = item[\"intent_label\"]\n",
    "                conversion_count[\"success\"] += 1\n",
    "            else:\n",
    "                print(f\"경고: 알 수 없는 intent '{item['intent']}' - 0으로 설정\")\n",
    "                item[\"intent_label\"] = 0\n",
    "                converted_label = 0\n",
    "                conversion_count[\"default\"] += 1\n",
    "        \n",
    "        # 3. label 필드 처리\n",
    "        elif \"label\" in item and isinstance(item[\"label\"], str):\n",
    "            original_label = item[\"label\"]\n",
    "            if item[\"label\"] in intent_label_to_id:\n",
    "                item[\"intent_label\"] = intent_label_to_id[item[\"label\"]]\n",
    "                converted_label = item[\"intent_label\"]\n",
    "                conversion_count[\"success\"] += 1\n",
    "            else:\n",
    "                print(f\"경고: 알 수 없는 label '{item['label']}' - 0으로 설정\")\n",
    "                item[\"intent_label\"] = 0\n",
    "                converted_label = 0\n",
    "                conversion_count[\"default\"] += 1\n",
    "        \n",
    "        # 4. 레이블이 없는 경우\n",
    "        else:\n",
    "            print(f\"경고: 레이블 필드 없음 - 0으로 설정\")\n",
    "            item[\"intent_label\"] = 0\n",
    "            original_label = \"없음\"\n",
    "            converted_label = 0\n",
    "            conversion_count[\"default\"] += 1\n",
    "            \n",
    "        # 샘플 출력 (처음 10개 항목만)\n",
    "        if conversion_count[\"success\"] + conversion_count[\"default\"] <= 10:\n",
    "            print(f\"변환: '{original_label}' -> {converted_label} (텍스트: '{item.get('text', '')[0:30]}...')\")\n",
    "\n",
    "    print(f\"\\n레이블 변환 결과: 성공={conversion_count['success']}개, 기본값 사용={conversion_count['default']}개\")\n",
    "\n",
    "    # 레이블 분포 검증 추가 (개선된 버전)\n",
    "    label_counts = {}\n",
    "    for item in intent_data:\n",
    "        label = item.get(\"intent_label\", 0)\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "    \n",
    "    print(\"\\n변환 후 인텐트 레이블 분포:\")\n",
    "    for label_id, count in sorted(label_counts.items()):\n",
    "        label_name = intent_id_to_label.get(label_id, \"알 수 없음\")\n",
    "        print(f\"  - 레이블 {label_id} ({label_name}): {count}개\")\n",
    "    \n",
    "    # 문제가 있는 경우 경고\n",
    "    if len(label_counts) == 1 and 0 in label_counts:\n",
    "        print(\"\\n경고: 모든 레이블이 0번으로 설정되었습니다! intent_label_list와 데이터의 레이블이 일치하는지 확인하세요.\")\n",
    "    elif label_counts.get(0, 0) > 0.9 * sum(label_counts.values()):\n",
    "        print(f\"\\n경고: 대부분의 레이블({label_counts.get(0, 0)}개, {label_counts.get(0, 0)/sum(label_counts.values())*100:.1f}%)이 0번으로 설정되었습니다!\")\n",
    "    \n",
    "    return intent_data, intent_label_list, intent_label_to_id, intent_id_to_label\n",
    "\n",
    "def validate_intent_labels(train_dataset, intent_id_to_label):\n",
    "    \"\"\"학습 데이터의 레이블 분포를 검증하고 불균형을 확인합니다.\"\"\"\n",
    "    label_counts = {}\n",
    "    \n",
    "    for item in train_dataset:\n",
    "        label = item[\"intent_label\"]\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "    \n",
    "    print(\"\\n훈련 데이터 인텐트 레이블 분포:\")\n",
    "    total = sum(label_counts.values())\n",
    "    for label_id, count in sorted(label_counts.items()):\n",
    "        label_name = intent_id_to_label.get(label_id, \"알 수 없음\")\n",
    "        percentage = (count / total) * 100\n",
    "        print(f\"  - 레이블 {label_id} ({label_name}): {count}개 ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 불균형 확인\n",
    "    if len(label_counts) == 1:\n",
    "        print(\"\\n심각한 경고: 단일 레이블만 존재! 모델 학습이 제대로 되지 않을 것입니다.\")\n",
    "        return False\n",
    "    \n",
    "    max_label = max(label_counts, key=label_counts.get)\n",
    "    max_count = label_counts[max_label]\n",
    "    \n",
    "    if max_count > 0.9 * total:\n",
    "        print(f\"\\n경고: 레이블 {max_label}이 전체 데이터의 {max_count/total*100:.1f}%를 차지합니다. 균형 조정이 필요합니다.\")\n",
    "        return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# --- 2. 통합 NLU 모델 정의 (Intent + NER) - 개선 ---\n",
    "class ImprovedRobertaForJointIntentAndNER(PreTrainedModel):\n",
    "    def __init__(self, config, intent_label_to_id, ner_label_to_id):\n",
    "        super().__init__(config)\n",
    "        self.num_intent_labels = len(intent_label_to_id)\n",
    "        self.num_ner_labels = len(ner_label_to_id)\n",
    "\n",
    "        # 기본 모델 로드\n",
    "        self.roberta = AutoModel.from_pretrained(MODEL_NAME, config=config)\n",
    "\n",
    "        # 인텐트 분류기 강화 \n",
    "        self.intent_dropout = nn.Dropout(0.3)  # 드롭아웃 증가\n",
    "        self.intent_hidden = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.intent_activation = nn.GELU()\n",
    "        self.intent_classifier = nn.Linear(config.hidden_size, self.num_intent_labels)\n",
    "\n",
    "        # NER을 위한 헤드\n",
    "        self.ner_dropout = nn.Dropout(0.3)\n",
    "        self.ner_lstm = nn.LSTM(\n",
    "            config.hidden_size,\n",
    "            config.hidden_size // 2,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.ner_classifier = nn.Linear(config.hidden_size, self.num_ner_labels)\n",
    "\n",
    "        # CRF 레이어 (NER용)\n",
    "        self.crf = CRF(self.num_ner_labels, batch_first=True)\n",
    "\n",
    "        # 손실 가중치 조정 (문제해결: NER 손실이 너무 커서 인텐트 비중 증가)\n",
    "        self.intent_loss_weight = 0.8\n",
    "        self.ner_loss_weight = 0.2\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        intent_labels=None,\n",
    "        ner_labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        # RoBERTa 인코더 실행\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]  # 모든 토큰의 임베딩\n",
    "        pooled_output = sequence_output[:, 0, :]  # [CLS] 토큰 임베딩 (Intent 용)\n",
    "\n",
    "        # Intent 분류 (개선된 분류기)\n",
    "        intent_output = self.intent_dropout(pooled_output)\n",
    "        intent_hidden = self.intent_hidden(intent_output)\n",
    "        intent_hidden = self.intent_activation(intent_hidden)\n",
    "        intent_logits = self.intent_classifier(intent_hidden)\n",
    "        \n",
    "        # 디버깅: 인텐트 로짓 출력\n",
    "        if intent_logits is not None and intent_labels is not None:\n",
    "            probs = F.softmax(intent_logits, dim=-1)\n",
    "            # 모든 클래스의 평균 확률 출력\n",
    "            class_probs = probs.mean(dim=0)\n",
    "            \n",
    "            # 클래스별 최대 확률과 최소 확률 출력\n",
    "            max_prob, max_idx = torch.max(class_probs, dim=0)\n",
    "            min_prob, min_idx = torch.min(class_probs, dim=0)\n",
    "            print(f\"클래스별 확률 - 최대: 클래스 {max_idx.item()} ({max_prob.item():.4f}), 최소: 클래스 {min_idx.item()} ({min_prob.item():.4f})\")\n",
    "            \n",
    "            # 무작위 샘플 5개에 대한 예측 확인 (인텐트별 확률 상위 3개 표시)\n",
    "            if intent_logits.size(0) > 5:\n",
    "                sample_indices = torch.randint(0, intent_logits.size(0), (5,))\n",
    "                for i, idx in enumerate(sample_indices):\n",
    "                    pred = torch.argmax(intent_logits[idx]).item()\n",
    "                    true_label = intent_labels[idx].item()\n",
    "                    \n",
    "                    # 상위 3개 확률 출력\n",
    "                    top_probs, top_indices = torch.topk(probs[idx], 3)\n",
    "                    top_probs_str = \", \".join([f\"클래스 {idx.item()}({prob.item():.4f})\" for idx, prob in zip(top_indices, top_probs)])\n",
    "                    \n",
    "                    print(f\"샘플 {i}: 예측={pred}, 실제={true_label}, 상위확률=[{top_probs_str}]\")\n",
    "\n",
    "        # NER 분류 (BiLSTM + CRF)\n",
    "        ner_output = self.ner_dropout(sequence_output)\n",
    "        ner_lstm_output, _ = self.ner_lstm(ner_output)\n",
    "        ner_logits = self.ner_classifier(ner_lstm_output)\n",
    "\n",
    "        # 손실 계산\n",
    "        total_loss = None\n",
    "        intent_loss = None\n",
    "        ner_loss = None\n",
    "\n",
    "        if intent_labels is not None:\n",
    "            # 클래스 가중치 계산 - 희소 클래스에 더 높은 가중치 부여\n",
    "            if hasattr(self, 'class_weights') and self.class_weights is not None:\n",
    "                # 클래스 가중치가 있으면 사용\n",
    "                intent_loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "            else:\n",
    "                # 기본 손실 함수\n",
    "                intent_loss_fct = nn.CrossEntropyLoss(label_smoothing=0.05)  # 레이블 스무딩 조정\n",
    "            \n",
    "            # 레이블 범위 검증 (오류 방지)\n",
    "            if torch.max(intent_labels) >= self.num_intent_labels:\n",
    "                print(f\"경고: 인텐트 레이블 범위 초과 - 최대값: {torch.max(intent_labels).item()}, 허용 최대: {self.num_intent_labels-1}\")\n",
    "                # 범위를 벗어난 레이블 수정\n",
    "                intent_labels = torch.clamp(intent_labels, 0, self.num_intent_labels-1)\n",
    "            \n",
    "            intent_loss = intent_loss_fct(intent_logits.view(-1, self.num_intent_labels), intent_labels.view(-1))\n",
    "\n",
    "        if ner_labels is not None:\n",
    "            # NER 손실 계산 (CRF)\n",
    "            mask = attention_mask.bool()\n",
    "\n",
    "            # -100을 유효한 레이블 인덱스로 변환 (CRF용)\n",
    "            label_mask = ner_labels != -100\n",
    "            crf_labels = ner_labels.clone()\n",
    "            crf_labels[~label_mask] = 0\n",
    "\n",
    "            # CRF 손실 계산\n",
    "            ner_loss = -self.crf(ner_logits, crf_labels, mask=mask).mean()\n",
    "\n",
    "            # NER 손실이 너무 크면 스케일링 (안정성 확보)\n",
    "            if ner_loss > 100:\n",
    "                ner_loss = ner_loss / (ner_loss.item() / 100)\n",
    "\n",
    "            if torch.isnan(ner_loss) or torch.isinf(ner_loss):\n",
    "                print(\"NER 손실이 NaN 또는 Inf입니다!\")\n",
    "                ner_loss = torch.tensor(0.1, device=ner_logits.device)\n",
    "\n",
    "        # 총 손실 계산 (두 작업의 가중치 합)\n",
    "        if intent_loss is not None and ner_loss is not None:\n",
    "            # NER 손실 스케일링 (너무 큰 경우)\n",
    "            if ner_loss.item() > 100 * intent_loss.item():\n",
    "                scale_factor = ner_loss.item() / (100 * intent_loss.item())\n",
    "                ner_loss = ner_loss / scale_factor\n",
    "                print(f\"NER 손실이 너무 커서 스케일링합니다: {scale_factor:.2f}배 감소\")\n",
    "            \n",
    "            total_loss = self.intent_loss_weight * intent_loss + self.ner_loss_weight * ner_loss\n",
    "\n",
    "        # 예측 단계\n",
    "        intent_predictions = None\n",
    "        ner_predictions = None\n",
    "\n",
    "        if intent_labels is None:\n",
    "            intent_predictions = torch.argmax(intent_logits, dim=1)\n",
    "\n",
    "        if ner_labels is None:\n",
    "            if attention_mask is not None:\n",
    "                mask = attention_mask.bool()\n",
    "                best_ner_tags_list = self.crf.decode(ner_logits, mask=mask)\n",
    "\n",
    "                # 리스트를 텐서로 변환\n",
    "                ner_predictions = torch.zeros_like(input_ids)\n",
    "                for i, tags in enumerate(best_ner_tags_list):\n",
    "                    ner_predictions[i, :len(tags)] = torch.tensor(tags, device=ner_predictions.device)\n",
    "            else:\n",
    "                best_ner_tags_list = self.crf.decode(ner_logits)\n",
    "                ner_predictions = torch.tensor(best_ner_tags_list, device=ner_logits.device)\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"intent_loss\": intent_loss,\n",
    "            \"ner_loss\": ner_loss,\n",
    "            \"intent_logits\": intent_logits,\n",
    "            \"ner_logits\": ner_logits,\n",
    "            \"intent_predictions\": intent_predictions,\n",
    "            \"ner_predictions\": ner_predictions\n",
    "        }\n",
    "    \n",
    "def calculate_class_weights(intent_data, intent_label_to_id):\n",
    "    \"\"\"클래스별 가중치 계산 - 희소 클래스에 더 높은 가중치\"\"\"\n",
    "    class_counts = {}\n",
    "    for item in intent_data:\n",
    "        # 다양한 레이블 키 시도\n",
    "        intent_label = None\n",
    "        possible_keys = [\"intent_label\", \"intent\", \"label\"]\n",
    "        \n",
    "        for key in possible_keys:\n",
    "            if key in item:\n",
    "                label_value = item[key]\n",
    "                # 정수 타입이든 문자열이든 적절히 처리\n",
    "                if isinstance(label_value, (int, float)):\n",
    "                    intent_label = int(label_value)\n",
    "                    break\n",
    "                elif isinstance(label_value, str):\n",
    "                    # 문자열이 숫자처럼 보이면 숫자로 변환 시도\n",
    "                    if label_value.isdigit():\n",
    "                        intent_label = int(label_value)\n",
    "                    else:\n",
    "                        # 문자열 레이블을 ID로 변환\n",
    "                        intent_label = intent_label_to_id.get(label_value, 0)\n",
    "                    break\n",
    "        \n",
    "        # 레이블을 찾지 못한 경우 기본값 사용\n",
    "        if intent_label is None:\n",
    "            intent_label = 0\n",
    "            \n",
    "        # 레이블 유효성 검사\n",
    "        if intent_label >= len(intent_label_to_id):\n",
    "            print(f\"경고: 유효하지 않은 인텐트 레이블({intent_label}) - 기본값 0으로 설정\")\n",
    "            intent_label = 0\n",
    "            \n",
    "        if intent_label not in class_counts:\n",
    "            class_counts[intent_label] = 0\n",
    "        class_counts[intent_label] += 1\n",
    "    \n",
    "    # 클래스 분포 로깅 (디버깅용)\n",
    "    print(\"\\n인텐트 클래스 분포:\")\n",
    "    for intent_id, count in sorted(class_counts.items()):\n",
    "        print(f\"  - 클래스 {intent_id}: {count}개\")\n",
    "    \n",
    "    # 가장 많은 클래스와 적은 클래스 찾기\n",
    "    max_count = max(class_counts.values()) if class_counts else 1\n",
    "    \n",
    "    # 클래스별 가중치 계산 (적을수록 높은 가중치)\n",
    "    class_weights = []\n",
    "    for i in range(len(intent_label_to_id)):\n",
    "        count = class_counts.get(i, 1)\n",
    "        weight = max_count / (count + 1)  # 0으로 나누는 것 방지\n",
    "        class_weights.append(weight)\n",
    "    \n",
    "    print(\"클래스별 가중치:\", class_weights)\n",
    "    return torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# --- 3. 데이터 전처리 및 통합 ---\n",
    "def preprocess_and_merge_data():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"데이터 전처리 및 통합 시작\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 3.1 토크나이저 로드\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "    # 3.2 Intent 데이터 로드 (개선된 함수 사용)\n",
    "    intent_data, intent_label_list, intent_label_to_id, intent_id_to_label = load_intent_data()\n",
    "    print(f\"Intent 레이블 ({len(intent_label_list)}개): {intent_label_list}\")\n",
    "\n",
    "    # 3.3 NER 데이터 로드\n",
    "    ner_data = load_ner_data()\n",
    "\n",
    "    # 3.4 NER 레이블 정의 (BIO 형식)\n",
    "    entity_types = set()\n",
    "    for item in ner_data:\n",
    "        for _, _, label in item[\"entities\"]:\n",
    "            entity_types.add(label)\n",
    "    entity_types = sorted(list(entity_types))\n",
    "\n",
    "    ner_labels = [\"O\"]  # Outside tag\n",
    "    for entity_type in entity_types:\n",
    "        ner_labels.extend([f\"B-{entity_type}\", f\"I-{entity_type}\"])\n",
    "\n",
    "    ner_label_to_id = {label: i for i, label in enumerate(ner_labels)}\n",
    "    ner_id_to_label = {i: label for label, i in ner_label_to_id.items()}\n",
    "    print(f\"NER 레이블 ({len(ner_labels)}개): {ner_labels}\")\n",
    "\n",
    "    # 3.5 데이터 통합 및 증강\n",
    "    integrated_data = []\n",
    "\n",
    "    # Intent 데이터 전처리 및 추가\n",
    "    print(\"\\n--- Intent 데이터 전처리 ---\")\n",
    "\n",
    "    # 각 인텐트 클래스별 데이터 수 파악 (개선: 레이블 일관성 확보)\n",
    "    intent_class_counts = {}\n",
    "    for item in intent_data:\n",
    "        intent_label = item.get(\"intent_label\", 0)  # 이미 정수로 변환됨\n",
    "        \n",
    "        if intent_label not in intent_class_counts:\n",
    "            intent_class_counts[intent_label] = 0\n",
    "        intent_class_counts[intent_label] += 1\n",
    "\n",
    "    max_count = max(intent_class_counts.values())\n",
    "    oversampling_rates = {label: max(1, min(5, int(max_count / count * 2))) \n",
    "                        for label, count in intent_class_counts.items()}\n",
    "    \n",
    "    print(\"인텐트 클래스별 데이터 수:\")\n",
    "    for label, count in intent_class_counts.items():\n",
    "        label_name = intent_id_to_label.get(label, \"알 수 없음\")\n",
    "        print(f\"  - {label} ({label_name}): {count}개\")\n",
    "\n",
    "    print(\"클래스별 오버샘플링 비율:\")\n",
    "    for label, rate in oversampling_rates.items():\n",
    "        label_name = intent_id_to_label.get(label, \"알 수 없음\")\n",
    "        print(f\"  - {label} ({label_name}): {rate}배\")\n",
    "\n",
    "    # Intent 데이터 추가 (개선: 레이블 처리 일관성)\n",
    "    for idx, item in enumerate(tqdm(intent_data, desc=\"인텐트 데이터 처리\")):\n",
    "        try:\n",
    "            # 텍스트 필드 확인\n",
    "            if \"text\" not in item:\n",
    "                continue\n",
    "\n",
    "            text = item[\"text\"]\n",
    "            \n",
    "            # 이미 정수로 변환된 레이블 사용\n",
    "            intent_label = item.get(\"intent_label\", 0)\n",
    "            \n",
    "            # 레이블 유효성 검사\n",
    "            if intent_label >= len(intent_label_list) or intent_label < 0:\n",
    "                print(f\"경고: 유효하지 않은 인텐트 레이블({intent_label}) - 기본값 0으로 설정\")\n",
    "                intent_label = 0\n",
    "\n",
    "            # 토큰화\n",
    "            tokenized = tokenizer(\n",
    "                text,\n",
    "                return_offsets_mapping=True,\n",
    "                add_special_tokens=True,\n",
    "                truncation=True,\n",
    "                max_length=MAX_LEN,\n",
    "                padding='max_length'\n",
    "            )\n",
    "            input_ids = tokenized[\"input_ids\"]\n",
    "            attention_mask = tokenized[\"attention_mask\"]\n",
    "            offset_mapping = tokenized[\"offset_mapping\"]\n",
    "\n",
    "            # NER 레이블은 모두 무시 (-100)\n",
    "            ner_token_labels = [-100] * len(input_ids)\n",
    "\n",
    "            if idx < 3:  # 샘플 출력\n",
    "                print(f\"\\n[Intent 데이터 {idx}] '{text}' -> 의도: {intent_id_to_label.get(intent_label, '알 수 없음')} ({intent_label})\")\n",
    "\n",
    "            integrated_data.append({\n",
    "                \"text\": text,\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "                \"intent_label\": intent_label,\n",
    "                \"ner_labels\": ner_token_labels\n",
    "            })\n",
    "\n",
    "            # 데이터 증강: 소량의 노이즈 추가 (랜덤 마스킹)\n",
    "            if intent_label in oversampling_rates:\n",
    "                for i in range(oversampling_rates[intent_label] - 1):  # 원본은 이미 추가했으므로 -1\n",
    "                    # 약간의 변형 추가 (토큰 마스킹)\n",
    "                    noised_input_ids = input_ids.copy()\n",
    "                    for j in range(1, len(noised_input_ids)-1):\n",
    "                        if random.random() < 0.1:  # 10% 확률로 마스킹\n",
    "                            noised_input_ids[j] = tokenizer.mask_token_id\n",
    "                    \n",
    "                    integrated_data.append({\n",
    "                        \"text\": text + f\" (augmented {i+1})\",\n",
    "                        \"input_ids\": noised_input_ids,\n",
    "                        \"attention_mask\": attention_mask,\n",
    "                        \"intent_label\": intent_label,\n",
    "                        \"ner_labels\": ner_token_labels\n",
    "                    })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Intent 데이터 처리 중 오류 발생 (항목 {idx}): {e}\")\n",
    "            continue\n",
    "\n",
    "    # NER 데이터 전처리 및 추가\n",
    "    print(\"\\n--- NER 데이터 전처리 ---\")\n",
    "\n",
    "    # 엔티티 유형별 개수 파악\n",
    "    entity_type_counts = {}\n",
    "    for item in ner_data:\n",
    "        for _, _, entity_type in item[\"entities\"]:\n",
    "            if entity_type not in entity_type_counts:\n",
    "                entity_type_counts[entity_type] = 0\n",
    "            entity_type_counts[entity_type] += 1\n",
    "\n",
    "    print(\"엔티티 유형별 개수:\")\n",
    "    for entity_type, count in entity_type_counts.items():\n",
    "        print(f\"  - {entity_type}: {count}개\")\n",
    "\n",
    "    # Intent 간 균형을 위한 인텐트 분포 생성\n",
    "    intent_counts = {i: 0 for i in range(len(intent_label_list))}\n",
    "    for item in integrated_data:\n",
    "        intent_label = item.get(\"intent_label\")\n",
    "        if intent_label is not None:\n",
    "            intent_counts[intent_label] += 1\n",
    "\n",
    "    # 가장 많은 수의 인텐트 ID 찾기\n",
    "    max_intent_count = max(intent_counts.values())\n",
    "    min_intent_count = min(intent_counts.values())\n",
    "    intent_weights = {i: max_intent_count / (count + 1) for i, count in intent_counts.items()}\n",
    "    entity_samples_weight = 3\n",
    "    # NER 데이터에 인텐트 분포 적용\n",
    "    for idx, item in enumerate(tqdm(ner_data, desc=\"NER 데이터 처리\")):\n",
    "        text = item[\"text\"]\n",
    "        entities = item[\"entities\"]\n",
    "\n",
    "        \n",
    "\n",
    "        # 적절한 인텐트 할당 (매핑 또는 무작위)\n",
    "        # 의도적으로 부족한 인텐트 클래스에 가중치 부여하여 할당\n",
    "        weighted_intent_ids = []\n",
    "        for i, weight in intent_weights.items():\n",
    "            weighted_intent_ids.extend([i] * int(weight * 10))\n",
    "\n",
    "        intent_label = random.choice(weighted_intent_ids)\n",
    "\n",
    "        # 텍스트 기반 인텐트 힌트 (텍스트에 특정 키워드가 있으면 관련 인텐트로 설정)\n",
    "        # 예: \"책, 도서, 대출\" -> 도서 관련 인텐트\n",
    "        # 이 부분은 프로젝트에 맞게 구체적으로 구현 필요\n",
    "\n",
    "        # 1. 문자 단위 BIO 태깅\n",
    "        char_labels = [\"O\"] * len(text)\n",
    "\n",
    "        # 2. 엔티티에 따라 BIO 태그 할당\n",
    "        for start_char, end_char, entity_type in entities:\n",
    "            if start_char < 0:\n",
    "                start_char = 0\n",
    "            if end_char > len(text):\n",
    "                end_char = len(text)\n",
    "\n",
    "            if start_char < end_char and start_char < len(text):\n",
    "                for i in range(start_char, end_char):\n",
    "                    if i == start_char:\n",
    "                        char_labels[i] = f\"B-{entity_type}\"\n",
    "                    else:\n",
    "                        char_labels[i] = f\"I-{entity_type}\"\n",
    "\n",
    "        # 3. 토큰화 및 토큰-문자 정렬\n",
    "        tokenized = tokenizer(\n",
    "            text,\n",
    "            return_offsets_mapping=True,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length'  # 패딩 추가\n",
    "        )\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "        offset_mapping = tokenized[\"offset_mapping\"]\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "        # 4. 토큰별 레이블 할당 (개선된 BIO 태깅)\n",
    "        ner_token_labels = []\n",
    "        prev_entity_type = None\n",
    "        prev_token_end = None\n",
    "\n",
    "        for i, (start, end) in enumerate(offset_mapping):\n",
    "            if start == end:  # 특수 토큰\n",
    "                ner_token_labels.append(-100)\n",
    "                continue\n",
    "                \n",
    "            # 현재 토큰이 어떤 엔티티에 속하는지 확인\n",
    "            entity_type = None\n",
    "            is_begin = False\n",
    "            \n",
    "            for ent_start, ent_end, ent_type in entities:\n",
    "                # 토큰이 엔티티 범위에 포함되는지 확인\n",
    "                if start >= ent_start and end <= ent_end:\n",
    "                    entity_type = ent_type\n",
    "                    # 시작 토큰인지 확인 (정확한 시작 부분 또는 처음 겹치는 부분)\n",
    "                    is_begin = (start == ent_start or \n",
    "                            (prev_token_end is not None and prev_token_end <= ent_start < start))\n",
    "                    break\n",
    "            \n",
    "            if entity_type:\n",
    "                tag = f\"B-{entity_type}\" if is_begin else f\"I-{entity_type}\"\n",
    "                ner_token_labels.append(ner_label_to_id[tag])\n",
    "            else:\n",
    "                ner_token_labels.append(ner_label_to_id[\"O\"])\n",
    "            \n",
    "            prev_token_end = end\n",
    "\n",
    "        # 레이블 길이 확인 및 조정\n",
    "        if len(ner_token_labels) < len(input_ids):\n",
    "            ner_token_labels.extend([-100] * (len(input_ids) - len(ner_token_labels)))\n",
    "        elif len(ner_token_labels) > len(input_ids):\n",
    "            ner_token_labels = ner_token_labels[:len(input_ids)]\n",
    "\n",
    "        if idx < 3:  # 샘플 출력\n",
    "            print(f\"\\n[NER 데이터 {idx}] '{text}' -> 엔티티: {entities}\")\n",
    "            print(f\"  인텐트: {intent_id_to_label.get(intent_label, '알 수 없음')}\")\n",
    "            print(f\"  토큰화: {tokens[:10]}... (총 {len(tokens)}개)\")\n",
    "            print(f\"  NER 레이블: {[ner_id_to_label.get(l, 'IGN') for l in ner_token_labels[:10]]}... (총 {len(ner_token_labels)}개)\")\n",
    "\n",
    "        integrated_data.append({\n",
    "            \"text\": text,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"intent_label\": intent_label,\n",
    "            \"ner_labels\": ner_token_labels\n",
    "        })\n",
    "\n",
    "        # 데이터 증강: 엔티티가 많은 데이터는 중복해서 추가\n",
    "        num_entities = len(entities)\n",
    "        for i in range(min(num_entities * entity_samples_weight, 5)):  # 최대 5번 반복\n",
    "            integrated_data.append({\n",
    "                \"text\": f\"{text} (duplicate {i+1})\",\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "                \"intent_label\": intent_label,\n",
    "                \"ner_labels\": ner_token_labels\n",
    "            })\n",
    "\n",
    "        print(f\"\\n통합 데이터셋 크기: {len(integrated_data)}\")\n",
    "\n",
    "    # 3.6 데이터셋 생성\n",
    "    integrated_features = Features({\n",
    "        'text': Value('string'),\n",
    "        'input_ids': Sequence(Value('int32'), length=MAX_LEN),\n",
    "        'attention_mask': Sequence(Value('int32'), length=MAX_LEN),\n",
    "        'intent_label': Value('int32'),\n",
    "        'ner_labels': Sequence(Value('int32'), length=MAX_LEN)\n",
    "    })\n",
    "\n",
    "    integrated_dataset = Dataset.from_list(integrated_data, features=integrated_features)\n",
    "\n",
    "    # 학습/검증/테스트 데이터셋 분리\n",
    "    train_val_test_datasets = integrated_dataset.train_test_split(test_size=0.3, seed=SEED)\n",
    "    train_dataset = train_val_test_datasets[\"train\"]\n",
    "\n",
    "    # 테스트 데이터를 검증과 테스트로 분리\n",
    "    test_valid_datasets = train_val_test_datasets[\"test\"].train_test_split(test_size=0.5, seed=SEED)\n",
    "    valid_dataset = test_valid_datasets[\"train\"]\n",
    "    test_dataset = test_valid_datasets[\"test\"]\n",
    "\n",
    "    print(f\"훈련 데이터 크기: {len(train_dataset)}\")\n",
    "    print(f\"검증 데이터 크기: {len(valid_dataset)}\")\n",
    "    print(f\"테스트 데이터 크기: {len(test_dataset)}\")\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset, intent_label_to_id, intent_id_to_label, ner_label_to_id, ner_id_to_label\n",
    "\n",
    "# --- 4. 데이터 콜레이터 정의 ---\n",
    "class ImprovedJointNLUDataCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # 입력 시퀀스 최대 길이 계산\n",
    "        max_length = max(len(feature[\"input_ids\"]) for feature in features)\n",
    "        max_length = min(max_length, MAX_LEN)  # 최대 길이 제한\n",
    "\n",
    "        # 배치 준비\n",
    "        batch = {\n",
    "            \"input_ids\": [],\n",
    "            \"attention_mask\": [],\n",
    "            \"intent_labels\": [],\n",
    "            \"ner_labels\": []\n",
    "        }\n",
    "\n",
    "        for feature in features:\n",
    "            # 패딩 적용\n",
    "            input_ids = feature[\"input_ids\"]\n",
    "            attention_mask = feature[\"attention_mask\"]\n",
    "            ner_labels = feature[\"ner_labels\"]\n",
    "\n",
    "            # 길이 확인 및 조정\n",
    "            if len(input_ids) > max_length:\n",
    "                input_ids = input_ids[:max_length]\n",
    "                attention_mask = attention_mask[:max_length]\n",
    "                ner_labels = ner_labels[:max_length]\n",
    "\n",
    "            padding_length = max_length - len(input_ids)\n",
    "\n",
    "            # 입력 패딩\n",
    "            if padding_length > 0:\n",
    "                input_ids = input_ids + [self.pad_token_id] * padding_length\n",
    "                attention_mask = attention_mask + [0] * padding_length\n",
    "                ner_labels = ner_labels + [-100] * padding_length  # -100은 손실 계산에서 무시됨\n",
    "\n",
    "            # 배치에 추가\n",
    "            batch[\"input_ids\"].append(input_ids)\n",
    "            batch[\"attention_mask\"].append(attention_mask)\n",
    "            batch[\"intent_labels\"].append(feature.get(\"intent_label\", 0))\n",
    "            batch[\"ner_labels\"].append(ner_labels)\n",
    "\n",
    "        # 텐서로 변환\n",
    "        batch[\"input_ids\"] = torch.tensor(batch[\"input_ids\"], dtype=torch.long)\n",
    "        batch[\"attention_mask\"] = torch.tensor(batch[\"attention_mask\"], dtype=torch.long)\n",
    "        batch[\"intent_labels\"] = torch.tensor(batch[\"intent_labels\"], dtype=torch.long)\n",
    "        batch[\"ner_labels\"] = torch.tensor(batch[\"ner_labels\"], dtype=torch.long)\n",
    "\n",
    "        return batch\n",
    "\n",
    "# --- 5. 개선된 커스텀 트레이너 정의 (통합 NLU용) ---\n",
    "class ImprovedJointNLUTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.best_metrics = {'joint_score': 0}\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # 안정적인 손실 계산을 위한 예외 처리 추가\n",
    "        try:\n",
    "            outputs = model(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                intent_labels=inputs[\"intent_labels\"],\n",
    "                ner_labels=inputs[\"ner_labels\"]\n",
    "            )\n",
    "\n",
    "            loss = outputs[\"loss\"]\n",
    "            intent_loss = outputs[\"intent_loss\"]\n",
    "            ner_loss = outputs[\"ner_loss\"]\n",
    "\n",
    "            # 손실 값 자세히 로깅\n",
    "            if self.state.global_step % 5 == 0:  # 5 스텝마다 출력\n",
    "                print(f\"Step {self.state.global_step} - Total: {loss.item():.4f}, Intent: {intent_loss.item() if intent_loss is not None else 0:.4f}, NER: {ner_loss.item() if ner_loss is not None else 0:.4f}\")\n",
    "\n",
    "            # 손실 값 검증 (NaN 방지)\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                logger.warning(\"발견된 NaN/Inf 손실값! 대체값 사용...\")\n",
    "                loss = torch.tensor(1.0, device=loss.device, requires_grad=True)\n",
    "\n",
    "            # 자세한 로깅 (정기적으로)\n",
    "            if self.state.global_step % 10 == 0:\n",
    "                self.log({\n",
    "                    \"total_loss\": loss.item(),\n",
    "                    \"intent_loss\": intent_loss.item() if intent_loss is not None else 0,\n",
    "                    \"ner_loss\": ner_loss.item() if ner_loss is not None else 0,\n",
    "                    \"lr\": self.optimizer.param_groups[0]['lr']  # 현재 학습률 로깅\n",
    "                })\n",
    "\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"손실 계산 중 오류 발생: {e}\")\n",
    "            # 오류 시 기본 손실 반환\n",
    "            loss = torch.tensor(1.0, device=inputs[\"input_ids\"].device, requires_grad=True)\n",
    "            return (loss, None) if return_outputs else loss\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        with torch.no_grad():\n",
    "            # 입력 데이터 검증\n",
    "            for k, v in inputs.items():\n",
    "                if torch.isnan(v).any() or torch.isinf(v).any():\n",
    "                    logger.warning(f\"입력 데이터 문제 발견 ({k})!\")\n",
    "                    inputs[k] = torch.nan_to_num(v)  # NaN/Inf 값 대체\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                intent_labels=inputs[\"intent_labels\"],\n",
    "                ner_labels=inputs[\"ner_labels\"]\n",
    "            )\n",
    "\n",
    "            loss = outputs[\"loss\"]\n",
    "\n",
    "            if prediction_loss_only:\n",
    "                return (loss, None, None)\n",
    "\n",
    "            # 예측 및 레이블 추출\n",
    "            intent_logits = outputs[\"intent_logits\"]\n",
    "            intent_predictions = torch.argmax(intent_logits, dim=1)\n",
    "            intent_labels = inputs[\"intent_labels\"]\n",
    "\n",
    "            # CRF 기반 NER 예측 처리\n",
    "            ner_logits = outputs[\"ner_logits\"]\n",
    "            attention_mask = inputs[\"attention_mask\"].bool()\n",
    "            ner_predictions = torch.zeros_like(inputs[\"input_ids\"])\n",
    "\n",
    "            try:\n",
    "                # CRF 디코딩 (최적의 태그 시퀀스 찾기)\n",
    "                best_ner_tags_list = model.crf.decode(ner_logits, mask=attention_mask)\n",
    "\n",
    "                for i, tags in enumerate(best_ner_tags_list):\n",
    "                    length = min(len(tags), ner_predictions.size(1))\n",
    "                    ner_predictions[i, :length] = torch.tensor(tags[:length], device=ner_predictions.device)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"NER 예측 중 오류 발생: {e}\")\n",
    "                # 오류 시 모든 토큰을 'O'(Outside) 태그로 예측\n",
    "                ner_predictions = torch.zeros_like(inputs[\"input_ids\"])\n",
    "\n",
    "            ner_labels = inputs[\"ner_labels\"]\n",
    "\n",
    "            # 반환값: (손실, 예측값 튜플, 레이블 튜플)\n",
    "            return (loss, (intent_predictions, ner_predictions), (intent_labels, ner_labels))\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        \"\"\"향상된 평가 메서드: 점진적 평가 및 상세 메트릭스\"\"\"\n",
    "        metrics = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "\n",
    "        # 개선된 결과 저장 로직 (새로운 최고 성능 달성 시)\n",
    "        current_score = metrics.get(f\"{metric_key_prefix}_joint_score\", 0)\n",
    "        if current_score > self.best_metrics['joint_score']:\n",
    "            self.best_metrics['joint_score'] = current_score\n",
    "            self.best_metrics['step'] = self.state.global_step\n",
    "            self.best_metrics['epoch'] = self.state.epoch\n",
    "\n",
    "            # 상세 로깅\n",
    "            logger.info(f\"새로운 최고 성능 달성! Joint Score: {current_score:.4f} (Step: {self.state.global_step}, Epoch: {self.state.epoch:.2f})\")\n",
    "\n",
    "        return metrics\n",
    "\n",
    "# --- 6. 개선된 평가 지표 계산 함수 ---\n",
    "def compute_improved_joint_metrics(eval_preds, ner_label_list=None):\n",
    "    (intent_preds, ner_preds), (intent_labels, ner_labels) = eval_preds\n",
    "\n",
    "    # 인텐트 예측 분포 확인 (디버깅)\n",
    "    intent_pred_counts = {}\n",
    "    for pred in intent_preds:\n",
    "        pred_id = pred.item()\n",
    "        intent_name = intent_id_to_label.get(pred_id, \"unknown\")\n",
    "        if intent_name not in intent_pred_counts:\n",
    "            intent_pred_counts[intent_name] = 0\n",
    "        intent_pred_counts[intent_name] += 1\n",
    "\n",
    "    print(\"\\n인텐트 예측 분포:\")\n",
    "    for intent_name, count in intent_pred_counts.items():\n",
    "        print(f\"  - {intent_name}: {count}개 ({count/len(intent_preds)*100:.2f}%)\")\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(intent_labels, intent_preds)\n",
    "    \n",
    "    # 혼동 행렬의 실제 크기 확인\n",
    "    cm_size = cm.shape[0]\n",
    "    # 표시할 클래스 수 결정 (지정한 값과 실제 크기 중 작은 값)\n",
    "    top_classes = min(5, cm_size)\n",
    "    \n",
    "    print(f\"\\n상위 {top_classes}개 클래스에 대한 혼동 행렬:\")\n",
    "    for i in range(top_classes):\n",
    "        row = ' '.join([f\"{cm[i][j]:4d}\" for j in range(top_classes)])\n",
    "        print(f\"  {i} [{intent_id_to_label.get(i, '?')}]: {row}\")\n",
    "\n",
    "    # Intent 평가 (F1 스코어 추가)\n",
    "    intent_accuracy = accuracy_score(intent_labels, intent_preds)\n",
    "    intent_f1_macro = sklearn_f1_score(intent_labels, intent_preds, average='macro')\n",
    "    intent_f1_weighted = sklearn_f1_score(intent_labels, intent_preds, average='weighted')\n",
    "\n",
    "    # NER 평가 준비\n",
    "    true_ner_predictions = []\n",
    "    true_ner_labels = []\n",
    "\n",
    "    # attention_mask 생성 (ner_labels가 -100이 아닌 위치)\n",
    "    attention_masks = []\n",
    "    for label in ner_labels:\n",
    "        mask = [l != -100 for l in label]\n",
    "        attention_masks.append(mask)\n",
    "\n",
    "    # attention_mask 포함하여 처리\n",
    "    for prediction, label in zip(ner_preds, ner_labels):\n",
    "        true_pred = []\n",
    "        true_label = []\n",
    "    \n",
    "        for p, l in zip(prediction, label):\n",
    "            if l != -100:  # 유효한 레이블만 평가\n",
    "                p_id = p.item()\n",
    "                l_id = l.item()\n",
    "                \n",
    "                # 레이블 ID가 유효한지 확인\n",
    "                if p_id in ner_id_to_label and l_id in ner_id_to_label:\n",
    "                    true_pred.append(ner_id_to_label[p_id])\n",
    "                    true_label.append(ner_id_to_label[l_id]) \n",
    "        \n",
    "        # 빈 시퀀스 문제 방지\n",
    "        if len(true_pred) == 0:\n",
    "            true_pred = [\"O\"]\n",
    "            true_label = [\"O\"]\n",
    "            \n",
    "        true_ner_predictions.append(true_pred)\n",
    "        true_ner_labels.append(true_label)\n",
    "\n",
    "    # seqeval의 f1_score 계산 (더 상세한 메트릭스)\n",
    "    try:\n",
    "        ner_f1 = f1_score(true_ner_labels, true_ner_predictions)\n",
    "        ner_report = classification_report(true_ner_labels, true_ner_predictions, digits=4, output_dict=True)\n",
    "\n",
    "        # 개체 유형별 F1 점수 추출\n",
    "        entity_metrics = {}\n",
    "        for label, metrics in ner_report.items():\n",
    "            if label not in ['micro avg', 'macro avg', 'weighted avg'] and isinstance(metrics, dict):\n",
    "                entity_metrics[f\"ner_f1_{label}\"] = metrics.get('f1-score', 0)\n",
    "\n",
    "        # 평가 보고서 출력 (텍스트 형식)\n",
    "        print(\"\\nNER Classification Report:\\n\", classification_report(true_ner_labels, true_ner_predictions, digits=4))\n",
    "\n",
    "        # 통합 점수 계산 (가중 평균, NER에 더 높은 가중치)\n",
    "        joint_score = INTENT_WEIGHT * intent_accuracy + NER_WEIGHT * ner_f1\n",
    "\n",
    "        # 최종 메트릭스 반환 (상세한 지표 포함)\n",
    "        metrics = {\n",
    "            \"intent_accuracy\": intent_accuracy,\n",
    "            \"intent_f1_macro\": intent_f1_macro,\n",
    "            \"intent_f1_weighted\": intent_f1_weighted,\n",
    "            \"ner_f1\": ner_f1,\n",
    "            \"joint_score\": joint_score,\n",
    "            **entity_metrics  # 개체 유형별 성능 추가\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"평가 지표 계산 오류: {e}\")\n",
    "        return {\n",
    "            \"intent_accuracy\": intent_accuracy,\n",
    "            \"intent_f1_macro\": intent_f1_macro,\n",
    "            \"intent_f1_weighted\": intent_f1_weighted,\n",
    "            \"ner_f1\": 0.0,\n",
    "            \"joint_score\": intent_accuracy * INTENT_WEIGHT\n",
    "        }\n",
    "\n",
    "# --- 7. 학습률 스케줄러 개선 ---\n",
    "def get_linear_schedule_with_warmup_and_decay(optimizer, num_warmup_steps, num_training_steps, min_lr_ratio=0.1):\n",
    "    \"\"\"학습률 워밍업 및 선형 감소 스케줄러\"\"\"\n",
    "\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            # 워밍업 구간\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "\n",
    "        # 워밍업 이후 선형 감소\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(min_lr_ratio, 1.0 - progress)\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "# --- 8. 개선된 통합 NLU 모델 훈련 함수 ---\n",
    "def train_improved_integrated_nlu_model():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"개선된 통합 NLU 모델 훈련 시작 (Intent + NER)\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 글로벌 변수 설정 (평가 지표용)\n",
    "    global intent_id_to_label, ner_id_to_label, tokenizer\n",
    "\n",
    "    # 8.1 데이터 전처리 및 통합\n",
    "    train_dataset, valid_dataset, test_dataset, intent_label_to_id, intent_id_to_label, ner_label_to_id, ner_id_to_label = preprocess_and_merge_data()\n",
    "    valid_labels = validate_intent_labels(train_dataset, intent_id_to_label)\n",
    "    if not valid_labels:\n",
    "        print(\"레이블 문제로 인해 학습을 중단합니다. 데이터와 레이블 매핑을 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    # 8.2 토크나이저 로드\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "    # 8.3 개선된 데이터 콜레이터 초기화\n",
    "    data_collator = ImprovedJointNLUDataCollator(tokenizer)\n",
    "\n",
    "    # 8.4 모델 설정\n",
    "    config = AutoModel.from_pretrained(MODEL_NAME).config\n",
    "    config.intent_label_to_id = intent_label_to_id\n",
    "    config.ner_label_to_id = ner_label_to_id\n",
    "\n",
    "    intent_data, _, _, _ = load_intent_data()\n",
    "    class_weights = calculate_class_weights(intent_data, intent_label_to_id)\n",
    "\n",
    "    # 8.5 개선된 통합 NLU 모델 초기화\n",
    "    model = ImprovedRobertaForJointIntentAndNER(\n",
    "        config,\n",
    "        intent_label_to_id,\n",
    "        ner_label_to_id\n",
    "    )\n",
    "    model.class_weights = class_weights.to(device)\n",
    "\n",
    "    model = init_intent_classifier(model)\n",
    "\n",
    "    # 8.6 개선된 훈련 설정\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results/improved_integrated_nlu\",\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        gradient_accumulation_steps=2,\n",
    "        logging_dir='./logs/improved_integrated_nlu',\n",
    "        logging_steps=1,\n",
    "        save_steps=50,\n",
    "        eval_steps=25,\n",
    "        eval_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=3,\n",
    "        fp16=True,\n",
    "        greater_is_better=True,\n",
    "        metric_for_best_model=\"intent_accuracy\",  # 인텐트 정확도를 기준으로 모델 선택\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=5e-5,  # 학습률 증가\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"linear\",  # 단순한 스케줄러 사용\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    # 8.7 개선된 훈련 시작\n",
    "    trainer = ImprovedJointNLUTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_improved_joint_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    # 메모리 최적화\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "    # 훈련 실행\n",
    "    print(\"모델 훈련 시작...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # 8.8 최종 평가\n",
    "    print(\"\\n--- 검증 세트 최종 평가 ---\")\n",
    "    eval_result = trainer.evaluate(valid_dataset)\n",
    "    print(f\"검증 세트 평가 결과: {eval_result}\")\n",
    "\n",
    "    print(\"\\n--- 테스트 세트 최종 평가 ---\")\n",
    "    test_result = trainer.evaluate(test_dataset, metric_key_prefix=\"test\")\n",
    "    print(f\"테스트 세트 평가 결과: {test_result}\")\n",
    "\n",
    "    # 8.9 모델 및 레이블 정보 저장\n",
    "    print(\"\\n모델 및 레이블 정보 저장 중...\")\n",
    "    os.makedirs(INTEGRATED_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "    # 메모리 최적화\n",
    "    gc.collect()\n",
    "    model.cpu()\n",
    "\n",
    "    # 모델 저장\n",
    "    torch.save(model.state_dict(), os.path.join(INTEGRATED_MODEL_DIR, \"pytorch_model.bin\"))\n",
    "\n",
    "    # Config 정보 저장\n",
    "    config_dict = config.to_dict()\n",
    "    config_dict[\"model_type\"] = \"improved_roberta_joint_nlu\"  # 개선된 모델 타입 표시\n",
    "    with open(os.path.join(INTEGRATED_MODEL_DIR, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(config_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # 토크나이저 저장\n",
    "    tokenizer.save_pretrained(INTEGRATED_MODEL_DIR)\n",
    "\n",
    "    # 레이블 매핑 저장\n",
    "    with open(INTEGRATED_LABEL_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            \"intent_id2label\": intent_id_to_label,\n",
    "            \"intent_label2id\": intent_label_to_id,\n",
    "            \"ner_id2label\": ner_id_to_label,\n",
    "            \"ner_label2id\": ner_label_to_id,\n",
    "            \"training_metrics\": {\n",
    "                \"validation\": eval_result,\n",
    "                \"test\": test_result,\n",
    "                \"best_metrics\": trainer.best_metrics\n",
    "            }\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "\n",
    "    print(f\"개선된 통합 NLU 모델 및 레이블 정보 저장 완료: {INTEGRATED_MODEL_DIR}\")\n",
    "    print(\"개선된 통합 NLU 모델 훈련 완료!\")\n",
    "\n",
    "def init_intent_classifier(model):\n",
    "    \"\"\"인텐트 분류기 가중치 특별 초기화 - 더 균형있게\"\"\"\n",
    "    if hasattr(model, 'intent_classifier'):\n",
    "        # Xavier 초기화 대신 작은 표준편차로 정규분포 초기화\n",
    "        nn.init.normal_(model.intent_classifier.weight, mean=0.0, std=0.02)\n",
    "        # 바이어스를 0으로 초기화하는 것이 아니라 작은 난수로 초기화\n",
    "        nn.init.constant_(model.intent_classifier.bias, 0.1)\n",
    "        print(\"인텐트 분류기 가중치 균형있게 초기화 완료\")\n",
    "    return model\n",
    "\n",
    "# --- 9. 메인 실행 코드 ---\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 시작 시간 기록\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 개선된 훈련 함수 실행\n",
    "        train_improved_integrated_nlu_model()\n",
    "\n",
    "        # 총 실행 시간 출력\n",
    "        total_time = time.time() - start_time\n",
    "        hours, remainder = divmod(total_time, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        print(f\"\\n총 실행 시간: {int(hours)}시간 {int(minutes)}분 {seconds:.2f}초\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"모델 훈련 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f29df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인텐트 레이블 목록: ['search_book_title', 'search_book_author', 'search_book_location', 'check_book_availability', 'get_bestseller', 'get_new_releases', 'request_recommendation_genre', 'request_recommendation_mood', 'request_recommendation_topic', 'request_recommendation_similar', 'request_recommendation_reader', 'search_space_availability', 'reserve_space', 'get_space_info', 'check_space_reservation', 'cancel_space_reservation', 'search_program', 'apply_program', 'get_program_info', 'check_program_application', 'cancel_program_application', 'get_library_hours', 'inquire_service', 'manage_membership', 'check_loan_status', 'extend_loan', 'reserve_book', 'check_reservation_status', 'cancel_book_reservation', 'check_overdue_status', 'report_lost_item', 'greeting', 'gratitude', 'closing', 'affirmative', 'negative', 'abuse', 'clarification', 'out_of_scope', 'repeat']\n",
      "총 데이터 수: 1371\n",
      "\n",
      "레이블 분포:\n",
      "레이블 0: 194개\n",
      "레이블 1: 116개\n",
      "레이블 2: 213개\n",
      "레이블 3: 183개\n",
      "레이블 4: 75개\n",
      "레이블 5: 89개\n",
      "레이블 6: 295개\n",
      "레이블 7: 45개\n",
      "레이블 8: 5개\n",
      "레이블 9: 5개\n",
      "레이블 10: 5개\n",
      "레이블 11: 5개\n",
      "레이블 12: 5개\n",
      "레이블 13: 5개\n",
      "레이블 14: 5개\n",
      "레이블 15: 5개\n",
      "레이블 16: 5개\n",
      "레이블 17: 5개\n",
      "레이블 18: 5개\n",
      "레이블 19: 5개\n",
      "레이블 20: 5개\n",
      "레이블 21: 5개\n",
      "레이블 22: 5개\n",
      "레이블 23: 5개\n",
      "레이블 24: 5개\n",
      "레이블 25: 5개\n",
      "레이블 26: 5개\n",
      "레이블 27: 5개\n",
      "레이블 28: 5개\n",
      "레이블 29: 5개\n",
      "레이블 30: 5개\n",
      "레이블 31: 5개\n",
      "레이블 32: 5개\n",
      "레이블 33: 5개\n",
      "레이블 34: 5개\n",
      "레이블 35: 5개\n",
      "레이블 36: 6개\n",
      "레이블 37: 5개\n",
      "레이블 38: 5개\n",
      "레이블 39: 5개\n"
     ]
    }
   ],
   "source": [
    "import commentjson\n",
    "\n",
    "# 파일 로드\n",
    "with open('intent_label_list.jsonc', 'r', encoding='utf-8') as f:\n",
    "    intent_label_list = commentjson.load(f)\n",
    "\n",
    "with open('intent_data.jsonc', 'r', encoding='utf-8') as f:\n",
    "    intent_data = commentjson.load(f)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"인텐트 레이블 목록: {intent_label_list}\")\n",
    "print(f\"총 데이터 수: {len(intent_data)}\")\n",
    "\n",
    "# 레이블 분포 확인\n",
    "label_counts = {}\n",
    "for item in intent_data:\n",
    "    # 레이블 값 가져오기\n",
    "    label = item.get(\"intent_label\", 0)  # 기본값 0\n",
    "    \n",
    "    if label not in label_counts:\n",
    "        label_counts[label] = 0\n",
    "    label_counts[label] += 1\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n레이블 분포:\")\n",
    "for label, count in sorted(label_counts.items()):\n",
    "    print(f\"레이블 {label}: {count}개\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
