{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2512783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "==================================================\n",
      "도서 검색 NLU 모델 훈련 시작\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Intent 분류 모델 훈련 시작\n",
      "==================================================\n",
      "Intent 레이블 (40개) 사용: {'search_book_title': 0, 'search_book_author': 1, 'search_book_location': 2, 'check_book_availability': 3, 'get_bestseller': 4, 'get_new_releases': 5, 'request_recommendation_genre': 6, 'request_recommendation_mood': 7, 'request_recommendation_topic': 8, 'request_recommendation_similar': 9, 'request_recommendation_reader': 10, 'search_space_availability': 11, 'reserve_space': 12, 'get_space_info': 13, 'check_space_reservation': 14, 'cancel_space_reservation': 15, 'search_program': 16, 'apply_program': 17, 'get_program_info': 18, 'check_program_application': 19, 'cancel_program_application': 20, 'get_library_info': 21, 'inquire_service': 22, 'manage_membership': 23, 'check_loan_status': 24, 'extend_loan': 25, 'reserve_book': 26, 'check_reservation_status': 27, 'cancel_book_reservation': 28, 'check_overdue_status': 29, 'report_lost_item': 30, 'greeting': 31, 'gratitude': 32, 'closing': 33, 'affirmative': 34, 'negative': 35, 'abuse': 36, 'clarification': 37, 'out_of_scope': 38, 'repeat': 39}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debfe1c63cf04a589011cc59ed5de5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/708 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6442aa7a91d946819b0677df5a26c09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/177 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent 데이터 샘플: {'label': 2, 'input_ids': [0, 15382, 1459, 8075, 4318, 1556, 3915, 5527, 2343, 2388, 7187, 18, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='445' max='445' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [445/445 11:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.561400</td>\n",
       "      <td>1.288270</td>\n",
       "      <td>0.734463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.822600</td>\n",
       "      <td>1.009654</td>\n",
       "      <td>0.790960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.599900</td>\n",
       "      <td>0.941475</td>\n",
       "      <td>0.790960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.455800</td>\n",
       "      <td>0.915936</td>\n",
       "      <td>0.785311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23/23 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent 모델 평가 결과: {'eval_loss': 0.9143379330635071, 'eval_accuracy': 0.7909604519774012, 'eval_runtime': 4.2416, 'eval_samples_per_second': 41.73, 'eval_steps_per_second': 5.423, 'epoch': 5.0}\n",
      "Intent 모델 훈련 완료\n",
      "Intent 모델 및 레이블 정보 저장 완료: ./models/intent\n",
      "\n",
      "==================================================\n",
      "NER 모델 훈련 시작\n",
      "==================================================\n",
      "토크나이저 테스트 '인문학' -> ['인문학']\n",
      "찾은 엔터티 타입: ['account_action', 'author', 'call_number', 'category', 'date', 'difficulty', 'duration', 'equipment', 'event_type', 'fee', 'format', 'isbn', 'library_info_type', 'location', 'lost_item', 'mood', 'num_people', 'publisher', 'service_type', 'target_audience', 'time', 'timeOfDay', 'title', 'topic']\n",
      "NER 레이블 (49개): ['O', 'B-account_action', 'I-account_action', 'B-author', 'I-author', 'B-call_number', 'I-call_number', 'B-category', 'I-category', 'B-date', 'I-date', 'B-difficulty', 'I-difficulty', 'B-duration', 'I-duration', 'B-equipment', 'I-equipment', 'B-event_type', 'I-event_type', 'B-fee', 'I-fee', 'B-format', 'I-format', 'B-isbn', 'I-isbn', 'B-library_info_type', 'I-library_info_type', 'B-location', 'I-location', 'B-lost_item', 'I-lost_item', 'B-mood', 'I-mood', 'B-num_people', 'I-num_people', 'B-publisher', 'I-publisher', 'B-service_type', 'I-service_type', 'B-target_audience', 'I-target_audience', 'B-time', 'I-time', 'B-timeOfDay', 'I-timeOfDay', 'B-title', 'I-title', 'B-topic', 'I-topic']\n",
      "\n",
      "--- NER 데이터 전처리 시작 ---\n",
      "\n",
      "[데이터 0] 텍스트: \"예수는 역사다라는 책 있나요?\"\n",
      "  정의된 엔티티: [(0, 7, 'title'), (10, 11, 'format')]\n",
      "  문제가 있는 엔티티: (10, 11, format)\n",
      "  텍스트 길이: 16\n",
      "  문자별 BIO 태그:\n",
      "    '예': B-title\n",
      "    '수': I-title\n",
      "    '는': I-title\n",
      "    ' ': I-title\n",
      "    '역': I-title\n",
      "    '사': I-title\n",
      "    '다': I-title\n",
      "    '라': O\n",
      "    '는': O\n",
      "    ' ': O\n",
      "    '책': B-format\n",
      "    ' ': O\n",
      "    '있': O\n",
      "    '나': O\n",
      "    '요': O\n",
      "    '?': O\n",
      "  토큰화 결과: ['[CLS]', '예수', '##는', '역사', '##다', '##라는', '책', '있', '##나', '##요', '?', '[SEP]']\n",
      "  오프셋 매핑: [(0, 0), (0, 2), (2, 3), (4, 6), (6, 7), (7, 9), (10, 11), (12, 13), (13, 14), (14, 15), (15, 16), (0, 0)]\n",
      "  최종 토큰 레이블: ['IGN', 'B-title', 'I-title', 'I-title', 'I-title', 'O', 'B-format', 'O', 'O', 'O', 'O', 'IGN']\n",
      "\n",
      "[데이터 1] 텍스트: \"어머니 나무를 찾아서 책 찾아주세요.\"\n",
      "  정의된 엔티티: [(0, 11, 'title'), (12, 13, 'format')]\n",
      "  문제가 있는 엔티티: (12, 13, format)\n",
      "  텍스트 길이: 20\n",
      "  문자별 BIO 태그:\n",
      "    '어': B-title\n",
      "    '머': I-title\n",
      "    '니': I-title\n",
      "    ' ': I-title\n",
      "    '나': I-title\n",
      "    '무': I-title\n",
      "    '를': I-title\n",
      "    ' ': I-title\n",
      "    '찾': I-title\n",
      "    '아': I-title\n",
      "    '서': I-title\n",
      "    ' ': O\n",
      "    '책': B-format\n",
      "    ' ': O\n",
      "    '찾': O\n",
      "    '아': O\n",
      "    '주': O\n",
      "    '세': O\n",
      "    '요': O\n",
      "    '.': O\n",
      "  토큰화 결과: ['[CLS]', '어머니', '나무', '##를', '찾아', '##서', '책', '찾아', '##주', '##세요', '.', '[SEP]']\n",
      "  오프셋 매핑: [(0, 0), (0, 3), (4, 6), (6, 7), (8, 10), (10, 11), (12, 13), (14, 16), (16, 17), (17, 19), (19, 20), (0, 0)]\n",
      "  최종 토큰 레이블: ['IGN', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'O', 'O', 'O', 'O', 'IGN']\n",
      "\n",
      "[데이터 2] 텍스트: \"이처럼 사소한 것들 소장하고 있는지 궁금합니다.\"\n",
      "  정의된 엔티티: [(0, 10, 'title')]\n",
      "  문제가 있는 엔티티: (0, 10, title)\n",
      "  텍스트 길이: 26\n",
      "  문자별 BIO 태그:\n",
      "    '이': B-title\n",
      "    '처': I-title\n",
      "    '럼': I-title\n",
      "    ' ': I-title\n",
      "    '사': I-title\n",
      "    '소': I-title\n",
      "    '한': I-title\n",
      "    ' ': I-title\n",
      "    '것': I-title\n",
      "    '들': I-title\n",
      "    ' ': O\n",
      "    '소': O\n",
      "    '장': O\n",
      "    '하': O\n",
      "    '고': O\n",
      "    ' ': O\n",
      "    '있': O\n",
      "    '는': O\n",
      "    '지': O\n",
      "    ' ': O\n",
      "    '궁': O\n",
      "    '금': O\n",
      "    '합': O\n",
      "    '니': O\n",
      "    '다': O\n",
      "    '.': O\n",
      "  토큰화 결과: ['[CLS]', '이', '##처럼', '사소', '##한', '것', '##들', '소장', '##하고', '있', '##는지', '궁금', '##합니다', '.', '[SEP]']\n",
      "  오프셋 매핑: [(0, 0), (0, 1), (1, 3), (4, 6), (6, 7), (8, 9), (9, 10), (11, 13), (13, 15), (16, 17), (17, 19), (20, 22), (22, 25), (25, 26), (0, 0)]\n",
      "  최종 토큰 레이블: ['IGN', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'IGN']\n",
      "NER 훈련 데이터 크기: 1066\n",
      "NER 평가 데이터 크기: 267\n",
      "NER 데이터 샘플: {'text': '어느 코너 가면 스즈미야 하루히의 음모 찾을 수 있을까?', 'input_ids': [0, 3875, 7849, 18140, 23965, 2044, 2275, 4051, 2468, 2079, 10796, 1642, 2069, 1295, 1513, 16809, 35, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 45, 46, 46, 46, 46, 46, 46, 0, 0, 0, 0, 0, 0, -100]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='670' max='670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [670/670 19:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1 Account Action</th>\n",
       "      <th>F1 Author</th>\n",
       "      <th>F1 Call Number</th>\n",
       "      <th>F1 Category</th>\n",
       "      <th>F1 Date</th>\n",
       "      <th>F1 Difficulty</th>\n",
       "      <th>F1 Duration</th>\n",
       "      <th>F1 Equipment</th>\n",
       "      <th>F1 Event Type</th>\n",
       "      <th>F1 Fee</th>\n",
       "      <th>F1 Format</th>\n",
       "      <th>F1 Isbn</th>\n",
       "      <th>F1 Library Info Type</th>\n",
       "      <th>F1 Location</th>\n",
       "      <th>F1 Lost Item</th>\n",
       "      <th>F1 Mood</th>\n",
       "      <th>F1 Num People</th>\n",
       "      <th>F1 Publisher</th>\n",
       "      <th>F1 Service Type</th>\n",
       "      <th>F1 Target Audience</th>\n",
       "      <th>F1 Time</th>\n",
       "      <th>F1 Timeofday</th>\n",
       "      <th>F1 Title</th>\n",
       "      <th>F1 Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.160108</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.133555</td>\n",
       "      <td>0.928279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.122716</td>\n",
       "      <td>0.927329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.117323</td>\n",
       "      <td>0.920245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.102803</td>\n",
       "      <td>0.937692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.087699</td>\n",
       "      <td>0.954035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.8899    0.8899    0.8899       109\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.0000    0.0000    0.0000         3\n",
      "           format     0.9242    0.9385    0.9313       130\n",
      "             isbn     0.0000    0.0000    0.0000         1\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.0000    0.0000    0.0000         1\n",
      "        lost_item     0.0000    0.0000    0.0000         1\n",
      "             mood     0.0000    0.0000    0.0000         2\n",
      "            title     0.8367    0.8898    0.8624       236\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.8720    0.8809    0.8764       487\n",
      "        macro avg     0.2209    0.2265    0.2236       487\n",
      "     weighted avg     0.8513    0.8809    0.8657       487\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'O', 'O', 'B-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9464    0.9725    0.9593       109\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.0000    0.0000    0.0000         3\n",
      "           format     0.9697    0.9846    0.9771       130\n",
      "             isbn     0.0000    0.0000    0.0000         1\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.0000    0.0000    0.0000         1\n",
      "        lost_item     0.0000    0.0000    0.0000         1\n",
      "             mood     0.0000    0.0000    0.0000         2\n",
      "            title     0.8939    0.9280    0.9106       236\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.9264    0.9302    0.9283       487\n",
      "        macro avg     0.2342    0.2404    0.2372       487\n",
      "     weighted avg     0.9039    0.9302    0.9168       487\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9712    0.9266    0.9484       109\n",
      "      call_number     0.0000    0.0000    0.0000         0\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.0000    0.0000    0.0000         3\n",
      "           format     0.9697    0.9846    0.9771       130\n",
      "             isbn     0.0000    0.0000    0.0000         1\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.2000    1.0000    0.3333         1\n",
      "        lost_item     0.0000    0.0000    0.0000         1\n",
      "             mood     0.0000    0.0000    0.0000         2\n",
      "            title     0.8992    0.9449    0.9215       236\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.9245    0.9302    0.9273       487\n",
      "        macro avg     0.2338    0.2966    0.2446       487\n",
      "     weighted avg     0.9124    0.9302    0.9203       487\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'O', 'O', 'B-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9615    0.9174    0.9390       109\n",
      "      call_number     0.0000    0.0000    0.0000         0\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.0000    0.0000    0.0000         3\n",
      "           format     0.9697    0.9846    0.9771       130\n",
      "             isbn     0.0000    0.0000    0.0000         1\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.1429    1.0000    0.2500         1\n",
      "        lost_item     0.0000    0.0000    0.0000         1\n",
      "             mood     0.0000    0.0000    0.0000         2\n",
      "            title     0.8947    0.9364    0.9151       236\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.9165    0.9240    0.9202       487\n",
      "        macro avg     0.2284    0.2953    0.2370       487\n",
      "     weighted avg     0.9079    0.9240    0.9150       487\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9626    0.9450    0.9537       109\n",
      "      call_number     0.0000    0.0000    0.0000         0\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.3333    0.3333    0.3333         3\n",
      "           format     0.9697    0.9846    0.9771       130\n",
      "             isbn     0.0000    0.0000    0.0000         1\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.2500    1.0000    0.4000         1\n",
      "        lost_item     0.0000    0.0000    0.0000         1\n",
      "             mood     0.0000    0.0000    0.0000         2\n",
      "            title     0.9224    0.9576    0.9397       236\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.9329    0.9425    0.9377       487\n",
      "        macro avg     0.2645    0.3247    0.2772       487\n",
      "     weighted avg     0.9239    0.9425    0.9325       487\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9730    0.9908    0.9818       109\n",
      "      call_number     0.0000    0.0000    0.0000         0\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.5000    0.3333    0.4000         3\n",
      "           format     0.9697    0.9846    0.9771       130\n",
      "             isbn     0.0000    0.0000    0.0000         1\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.1667    1.0000    0.2857         1\n",
      "        lost_item     0.0000    0.0000    0.0000         1\n",
      "             mood     0.0000    0.0000    0.0000         2\n",
      "       num_people     0.0000    0.0000    0.0000         0\n",
      "            title     0.9582    0.9703    0.9642       236\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.9492    0.9589    0.9540       487\n",
      "        macro avg     0.2548    0.3057    0.2578       487\n",
      "     weighted avg     0.9444    0.9589    0.9509       487\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9730    0.9908    0.9818       109\n",
      "      call_number     0.0000    0.0000    0.0000         0\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.5000    0.3333    0.4000         3\n",
      "           format     0.9697    0.9846    0.9771       130\n",
      "             isbn     0.0000    0.0000    0.0000         1\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.1667    1.0000    0.2857         1\n",
      "        lost_item     0.0000    0.0000    0.0000         1\n",
      "             mood     0.0000    0.0000    0.0000         2\n",
      "       num_people     0.0000    0.0000    0.0000         0\n",
      "            title     0.9582    0.9703    0.9642       236\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.9492    0.9589    0.9540       487\n",
      "        macro avg     0.2548    0.3057    0.2578       487\n",
      "     weighted avg     0.9444    0.9589    0.9509       487\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'I-author', 'O', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "NER 모델 평가 결과: {'eval_loss': 0.08769945800304413, 'eval_f1': 0.9540347293156282, 'eval_f1_account_action': 1.0, 'eval_f1_author': 1.0, 'eval_f1_call_number': 1.0, 'eval_f1_category': 1.0, 'eval_f1_date': 1.0, 'eval_f1_difficulty': 1.0, 'eval_f1_duration': 1.0, 'eval_f1_equipment': 1.0, 'eval_f1_event_type': 1.0, 'eval_f1_fee': 1.0, 'eval_f1_format': 1.0, 'eval_f1_isbn': 1.0, 'eval_f1_library_info_type': 1.0, 'eval_f1_location': 1.0, 'eval_f1_lost_item': 1.0, 'eval_f1_mood': 1.0, 'eval_f1_num_people': 1.0, 'eval_f1_publisher': 1.0, 'eval_f1_service_type': 1.0, 'eval_f1_target_audience': 1.0, 'eval_f1_time': 1.0, 'eval_f1_timeOfDay': 1.0, 'eval_f1_title': 1.0, 'eval_f1_topic': 1.0, 'eval_runtime': 7.075, 'eval_samples_per_second': 37.739, 'eval_steps_per_second': 4.806, 'epoch': 5.0}\n",
      "NER 모델 훈련 완료\n",
      "NER 모델 및 레이블 정보 저장 완료: ./models/ner\n",
      "\n",
      "==================================================\n",
      "도서 검색 NLU 모델 훈련 완료\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import commentjson\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from datasets import Dataset, Features, Value, ClassLabel, Sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 0. 기본 설정 ---\n",
    "MODEL_NAME = \"klue/roberta-base\"\n",
    "MAX_LEN = 128\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# 모델 저장 경로 설정\n",
    "INTENT_MODEL_DIR = \"./models/intent\"\n",
    "NER_MODEL_DIR = \"./models/ner\"\n",
    "INTENT_LABEL_PATH = os.path.join(INTENT_MODEL_DIR, \"intent_labels.jsonc\")\n",
    "NER_LABEL_PATH = os.path.join(NER_MODEL_DIR, \"ner_labels.jsonc\")\n",
    "\n",
    "# --- 1. 데이터 로드 ---\n",
    "# 1.1 Intent 분류를 위한 데이터\n",
    "def load_intent_data():\n",
    "    with open('intent_label_list.jsonc', 'r', encoding='utf-8') as f:\n",
    "        intent_label_list = commentjson.load(f)\n",
    "\n",
    "    intent_label_to_id = {label: i for i, label in enumerate(intent_label_list)}\n",
    "    intent_id_to_label = {i: label for label, i in intent_label_to_id.items()}\n",
    "\n",
    "    with open('intent_data.jsonc', 'r', encoding='utf-8') as f:\n",
    "        intent_data = commentjson.load(f)\n",
    "\n",
    "    return intent_data, intent_label_list, intent_label_to_id, intent_id_to_label\n",
    "\n",
    "# 1.2 NER을 위한 데이터\n",
    "def load_ner_data():\n",
    "    with open('ner_data.jsonc', 'r', encoding='utf-8') as f:\n",
    "        loaded_ner_data = commentjson.load(f)\n",
    "\n",
    "    ner_data = []\n",
    "    for item in loaded_ner_data:\n",
    "        entities_as_tuples = [tuple(entity_list) for entity_list in item.get(\"entities\", [])]\n",
    "        ner_data.append({\"text\": item.get(\"text\", \"\"), \"entities\": entities_as_tuples})\n",
    "\n",
    "    return ner_data\n",
    "\n",
    "# --- 2. Intent 분류 모델 훈련 ---\n",
    "def train_intent_model():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Intent 분류 모델 훈련 시작\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    intent_data, intent_label_list, intent_label_to_id, intent_id_to_label = load_intent_data()\n",
    "\n",
    "    num_intent_labels = len(intent_label_list)\n",
    "    print(f\"Intent 레이블 ({num_intent_labels}개) 사용: {intent_label_to_id}\")\n",
    "\n",
    "    intent_features = Features({\n",
    "        'text': Value('string'),\n",
    "        'label': ClassLabel(num_classes=num_intent_labels, names=intent_label_list)\n",
    "    })\n",
    "\n",
    "    intent_dataset = Dataset.from_list(intent_data, features=intent_features)\n",
    "\n",
    "    # 학습/평가 데이터 분리\n",
    "    train_test_datasets = intent_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "    train_dataset = train_test_datasets[\"train\"]\n",
    "    eval_dataset = train_test_datasets[\"test\"]\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "    def preprocess_intent_data(examples):\n",
    "        tokenized = tokenizer(\n",
    "            examples['text'],\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": tokenized[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"]\n",
    "        }\n",
    "\n",
    "    tokenized_train_dataset = train_dataset.map(\n",
    "        preprocess_intent_data,\n",
    "        batched=True,\n",
    "        remove_columns=['text']\n",
    "    )\n",
    "\n",
    "    tokenized_eval_dataset = eval_dataset.map(\n",
    "        preprocess_intent_data,\n",
    "        batched=True,\n",
    "        remove_columns=['text']\n",
    "    )\n",
    "\n",
    "    print(f\"Intent 데이터 샘플: {tokenized_train_dataset[0]}\")\n",
    "\n",
    "    intent_data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    intent_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=num_intent_labels,\n",
    "        id2label=intent_id_to_label,\n",
    "        label2id=intent_label_to_id\n",
    "    )\n",
    "\n",
    "    def compute_intent_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results/intent\",\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        logging_dir='./logs/intent',\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        eval_steps=100,\n",
    "        eval_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        save_total_limit=2,\n",
    "        report_to=\"none\",\n",
    "        learning_rate=5e-5,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "    )\n",
    "\n",
    "    intent_trainer = Trainer(\n",
    "        model=intent_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_eval_dataset,\n",
    "        data_collator=intent_data_collator,\n",
    "        compute_metrics=compute_intent_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    intent_trainer.train()\n",
    "    eval_result = intent_trainer.evaluate()\n",
    "    print(f\"Intent 모델 평가 결과: {eval_result}\")\n",
    "    print(\"Intent 모델 훈련 완료\")\n",
    "\n",
    "    # 모델 및 토크나이저 저장\n",
    "    os.makedirs(INTENT_MODEL_DIR, exist_ok=True)\n",
    "    intent_model.save_pretrained(INTENT_MODEL_DIR, safe_serialization=False)\n",
    "    tokenizer.save_pretrained(INTENT_MODEL_DIR)\n",
    "\n",
    "    # 레이블 정보 저장\n",
    "    with open(INTENT_LABEL_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            \"id2label\": intent_id_to_label,\n",
    "            \"label2id\": intent_label_to_id\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Intent 모델 및 레이블 정보 저장 완료: {INTENT_MODEL_DIR}\")\n",
    "\n",
    "# --- 3. NER 모델 훈련 ---\n",
    "def train_ner_model():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"NER 모델 훈련 시작\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    ner_data = load_ner_data()\n",
    "\n",
    "    # 3.1 토크나이저 로드\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "    # 디버깅: 토크나이저 테스트\n",
    "    test_text = \"인문학\"\n",
    "    test_tokens = tokenizer.tokenize(test_text)\n",
    "    print(f\"토크나이저 테스트 '{test_text}' -> {test_tokens}\")\n",
    "\n",
    "    # 3.2 NER 레이블 정의 (BIO 형식)\n",
    "    # 먼저 모든 엔터티 타입 추출\n",
    "    entity_types = sorted(list(set(label for item in ner_data for _, _, label in item[\"entities\"])))\n",
    "    print(f\"찾은 엔터티 타입: {entity_types}\")\n",
    "\n",
    "    ner_labels = [\"O\"]  # Outside tag\n",
    "    for entity_type in entity_types:\n",
    "        ner_labels.extend([f\"B-{entity_type}\", f\"I-{entity_type}\"])\n",
    "\n",
    "    ner_label2id = {label: i for i, label in enumerate(ner_labels)}\n",
    "    ner_id2label = {i: label for label, i in ner_label2id.items()}\n",
    "\n",
    "    print(f\"NER 레이블 ({len(ner_labels)}개): {ner_labels}\")\n",
    "\n",
    "    # 3.3 NER 데이터 전처리 - 문자 단위 접근\n",
    "    preprocessed_ner_data = []\n",
    "\n",
    "    print(\"\\n--- NER 데이터 전처리 시작 ---\")\n",
    "\n",
    "    for example_idx, example in enumerate(ner_data):\n",
    "        text = example[\"text\"]\n",
    "        entities = example[\"entities\"]\n",
    "\n",
    "        if example_idx < 3:  # 처음 몇 개 예시만 상세 출력\n",
    "            print(f\"\\n[데이터 {example_idx}] 텍스트: \\\"{text}\\\"\")\n",
    "            print(f\"  정의된 엔티티: {entities}\")\n",
    "\n",
    "        # 1. 문자 단위 BIO 태깅 초기화\n",
    "        char_labels = [\"O\"] * len(text)\n",
    "\n",
    "        # 2. 엔티티에 따라 BIO 태그 할당\n",
    "        for start_char, end_char, entity_type in entities:\n",
    "            # 범위 체크 및 수정\n",
    "            if start_char < 0:\n",
    "                start_char = 0\n",
    "            if end_char > len(text):\n",
    "                end_char = len(text)\n",
    "\n",
    "            if start_char < end_char and start_char < len(text):\n",
    "                for i in range(start_char, end_char):\n",
    "                    if i == start_char:\n",
    "                        char_labels[i] = f\"B-{entity_type}\"\n",
    "                    else:\n",
    "                        char_labels[i] = f\"I-{entity_type}\"\n",
    "\n",
    "        if example_idx < 3 or start_char >= len(text) or end_char > len(text) or start_char < 0:\n",
    "            print(f\"  문제가 있는 엔티티: ({start_char}, {end_char}, {entity_type})\")\n",
    "            print(f\"  텍스트 길이: {len(text)}\")\n",
    "\n",
    "        if example_idx < 3:  # 상세 디버깅 출력\n",
    "            print(f\"  문자별 BIO 태그:\")\n",
    "            for i, (char, label) in enumerate(zip(text, char_labels)):\n",
    "                print(f\"    '{char}': {label}\")\n",
    "\n",
    "        # 3. 토큰화 및 토큰-문자 정렬\n",
    "        tokenized = tokenizer(text, return_offsets_mapping=True, add_special_tokens=True)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(tokenized['input_ids'])\n",
    "        offset_mapping = tokenized['offset_mapping']\n",
    "\n",
    "        if example_idx < 3:  # 상세 디버깅 출력\n",
    "            print(f\"  토큰화 결과: {tokens}\")\n",
    "            print(f\"  오프셋 매핑: {offset_mapping}\")\n",
    "\n",
    "        # 4. 토큰별 레이블 할당\n",
    "        token_labels = []\n",
    "        for i, (start, end) in enumerate(offset_mapping):\n",
    "            # 특수 토큰 처리\n",
    "            if start == end:\n",
    "                token_label = -100  # ignore_index\n",
    "            else:\n",
    "                # 토큰 시작 위치의 문자 레이블 사용\n",
    "                char_label = char_labels[start]\n",
    "                token_label = ner_label2id[char_label]\n",
    "\n",
    "                # 서브워드 토큰은 I- 태그로 변환 (WordPiece ##로 시작하는 경우)\n",
    "                if i > 0 and tokens[i].startswith(\"##\"):\n",
    "                    prev_label = token_labels[-1]\n",
    "                    if prev_label != -100 and ner_id2label[prev_label].startswith(\"B-\"):\n",
    "                        # B- -> I- 변환\n",
    "                        entity_type = ner_id2label[prev_label][2:]  # \"B-genre\" -> \"genre\"\n",
    "                        token_label = ner_label2id[f\"I-{entity_type}\"]\n",
    "\n",
    "            token_labels.append(token_label)\n",
    "\n",
    "        if example_idx < 3:  # 상세 디버깅 출력\n",
    "            print(f\"  최종 토큰 레이블: {[ner_id2label.get(l, 'IGN') for l in token_labels]}\")\n",
    "\n",
    "        # 5. 레이블 ID로 변환\n",
    "        preprocessed_ner_data.append({\n",
    "            \"text\": text,\n",
    "            \"input_ids\": tokenized[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "            \"labels\": token_labels\n",
    "        })\n",
    "\n",
    "    # 3.4 데이터셋 생성\n",
    "    ner_features = Features({\n",
    "        'text': Value('string'),\n",
    "        'input_ids': Sequence(Value('int32')),\n",
    "        'attention_mask': Sequence(Value('int32')),\n",
    "        'labels': Sequence(Value('int32'))\n",
    "    })\n",
    "\n",
    "    ner_dataset = Dataset.from_list(preprocessed_ner_data, features=ner_features)\n",
    "\n",
    "    # 학습/평가 데이터셋 분리\n",
    "    train_test_datasets = ner_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "    train_dataset = train_test_datasets[\"train\"]\n",
    "    eval_dataset = train_test_datasets[\"test\"]\n",
    "\n",
    "    print(f\"NER 훈련 데이터 크기: {len(train_dataset)}\")\n",
    "    print(f\"NER 평가 데이터 크기: {len(eval_dataset)}\")\n",
    "    print(f\"NER 데이터 샘플: {train_dataset[0]}\")\n",
    "\n",
    "    # 3.5 데이터 콜레이터 설정\n",
    "    ner_data_collator = DataCollatorForTokenClassification(\n",
    "        tokenizer=tokenizer,\n",
    "        padding=True,\n",
    "        max_length=MAX_LEN,\n",
    "        pad_to_multiple_of=8\n",
    "    )\n",
    "\n",
    "    # 3.6 모델 로드\n",
    "    ner_model = AutoModelForTokenClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=len(ner_labels),\n",
    "        id2label=ner_id2label,\n",
    "        label2id=ner_label2id\n",
    "    )\n",
    "\n",
    "    # 3.7 평가 지표 계산 함수\n",
    "    def compute_ner_metrics(p):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # 실제 토큰의 예측값과 레이블만 추출\n",
    "        true_predictions = []\n",
    "        true_labels = []\n",
    "\n",
    "        for prediction, label in zip(predictions, labels):\n",
    "            true_pred = []\n",
    "            true_label = []\n",
    "\n",
    "            for p, l in zip(prediction, label):\n",
    "                if l != -100:  # -100은 무시\n",
    "                    true_pred.append(ner_id2label[p])\n",
    "                    true_label.append(ner_id2label[l])\n",
    "\n",
    "            true_predictions.append(true_pred)\n",
    "            true_labels.append(true_label)\n",
    "\n",
    "        # seqeval의 f1_score 계산\n",
    "        try:\n",
    "            f1 = f1_score(true_labels, true_predictions)\n",
    "            report = classification_report(true_labels, true_predictions, digits=4)\n",
    "            print(\"\\nNER Classification Report:\\n\", report)\n",
    "\n",
    "            # 세부 클래스별 결과 분석\n",
    "            class_results = {}\n",
    "            for label in ner_labels:\n",
    "                if label != \"O\" and label.startswith(\"B-\"):\n",
    "                    entity_type = label[2:]  # \"B-genre\" -> \"genre\"\n",
    "                    label_f1 = f1_score([[label]], [[label]], average='macro')\n",
    "                    class_results[entity_type] = label_f1\n",
    "\n",
    "            # 상세 예측 예시 출력\n",
    "            print(\"\\n예측 예시:\")\n",
    "            for i in range(min(5, len(true_labels))):\n",
    "                print(f\"실제: {true_labels[i]}\")\n",
    "                print(f\"예측: {true_predictions[i]}\")\n",
    "                print(\"---\")\n",
    "\n",
    "            return {\n",
    "                \"f1\": f1,\n",
    "                **{f\"f1_{key}\": val for key, val in class_results.items()}\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating NER metrics: {e}\")\n",
    "            return {\"f1\": 0.0}\n",
    "\n",
    "    # 3.8 훈련 설정\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results/ner\",\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        logging_dir='./logs/ner',\n",
    "        logging_steps=10,\n",
    "        save_steps=100,\n",
    "        eval_steps=100,\n",
    "        eval_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=2,\n",
    "        greater_is_better=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        weight_decay=0.01,\n",
    "        report_to=\"none\",\n",
    "        learning_rate=5e-5,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "\n",
    "    )\n",
    "\n",
    "    # 3.9 Trainer 정의\n",
    "    ner_trainer = Trainer(\n",
    "        model=ner_model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=ner_data_collator,\n",
    "        compute_metrics=compute_ner_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    # 3.10 모델 훈련\n",
    "    ner_trainer.train()\n",
    "    eval_result = ner_trainer.evaluate()\n",
    "    print(f\"NER 모델 평가 결과: {eval_result}\")\n",
    "    print(\"NER 모델 훈련 완료\")\n",
    "\n",
    "    # 3.11 모델 및 레이블 정보 저장\n",
    "    os.makedirs(NER_MODEL_DIR, exist_ok=True)\n",
    "    gc.collect()\n",
    "    ner_model.cpu()\n",
    "    ner_model.save_pretrained(NER_MODEL_DIR, safe_serialization=False)\n",
    "    tokenizer.save_pretrained(NER_MODEL_DIR)\n",
    "\n",
    "    # 레이블 매핑 저장\n",
    "    with open(NER_LABEL_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            \"id2label\": ner_id2label,\n",
    "            \"label2id\": ner_label2id\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"NER 모델 및 레이블 정보 저장 완료: {NER_MODEL_DIR}\")\n",
    "\n",
    "\n",
    "# --- 메인 함수 ---\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"도서 검색 NLU 모델 훈련 시작\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Intent 모델 훈련\n",
    "    train_intent_model()\n",
    "\n",
    "    # NER 모델 훈련\n",
    "    train_ner_model()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"도서 검색 NLU 모델 훈련 완료\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
