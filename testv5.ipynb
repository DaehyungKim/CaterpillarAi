{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 중인 디바이스: cuda\n",
      "인텐트 레이블 수: 40\n",
      "NER 레이블 수: 51\n",
      "모델 로드 완료!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bfd04eea5e456fb6db5e2b2772d943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>통합 NLU 모델 테스트</h2>'), HTML(value='<p>아래에 테스트할 텍스트를 입력하거나 예시 버튼을 클릭하세요.</p>'), H…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NLU 모델 테스트 노트북\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import commentjson  # 주석이 포함된 JSON 파일을 위해 필요\n",
    "from torch.nn import functional as F\n",
    "from torchcrf import CRF\n",
    "import torch.nn as nn\n",
    "from transformers import PreTrainedModel\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "# --- 모델 정의 (원본 코드에서 가져옴) ---\n",
    "class ImprovedRobertaForJointIntentAndNER(PreTrainedModel):\n",
    "    def __init__(self, config, intent_label_to_id, ner_label_to_id):\n",
    "        super().__init__(config)\n",
    "        self.num_intent_labels = len(intent_label_to_id)\n",
    "        self.num_ner_labels = len(ner_label_to_id)\n",
    "\n",
    "        # 기본 모델 로드\n",
    "        from transformers import RobertaModel\n",
    "        self.roberta = RobertaModel(config)  # 직접 RobertaModel을 사용\n",
    "\n",
    "        # Intent 분류를 위한 헤드 (개선: 더 복잡한 분류기)\n",
    "        self.intent_dropout = nn.Dropout(0.2)  # dropout 비율 조정\n",
    "        self.intent_classifier = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.GELU(),  # ReLU 대신 GELU 사용\n",
    "            nn.LayerNorm(config.hidden_size // 2),  # Layer Normalization 추가\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(config.hidden_size // 2, self.num_intent_labels)\n",
    "        )\n",
    "\n",
    "        # NER을 위한 헤드 (개선: BiLSTM + CRF)\n",
    "        self.ner_dropout = nn.Dropout(0.3)  # NER dropout 증가\n",
    "        self.ner_lstm = nn.LSTM(\n",
    "            config.hidden_size,\n",
    "            config.hidden_size // 2,\n",
    "            num_layers=2,  # LSTM 레이어 추가\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.ner_classifier = nn.Linear(config.hidden_size, self.num_ner_labels)\n",
    "\n",
    "        # CRF 레이어 (NER용)\n",
    "        self.crf = CRF(self.num_ner_labels, batch_first=True)\n",
    "\n",
    "        # 초기 가중치 설정 (훈련된 모델을 로드하므로 여기서는 필요 없음)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        intent_labels=None,\n",
    "        ner_labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        # RoBERTa 인코더 실행\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]  # 모든 토큰의 임베딩\n",
    "        pooled_output = sequence_output[:, 0, :]  # [CLS] 토큰 임베딩 (Intent 용)\n",
    "\n",
    "        # Intent 분류 (개선된 분류기)\n",
    "        intent_output = self.intent_dropout(pooled_output)\n",
    "        intent_logits = self.intent_classifier(intent_output)\n",
    "\n",
    "        # NER 분류 (BiLSTM + CRF)\n",
    "        ner_output = self.ner_dropout(sequence_output)\n",
    "        ner_lstm_output, _ = self.ner_lstm(ner_output)\n",
    "        ner_logits = self.ner_classifier(ner_lstm_output)\n",
    "\n",
    "        # 예측 단계\n",
    "        intent_predictions = None\n",
    "        ner_predictions = None\n",
    "\n",
    "        if intent_labels is None:\n",
    "            intent_predictions = torch.argmax(intent_logits, dim=1)\n",
    "\n",
    "        if ner_labels is None:\n",
    "            if attention_mask is not None:\n",
    "                mask = attention_mask.bool()\n",
    "                best_ner_tags_list = self.crf.decode(ner_logits, mask=mask)\n",
    "\n",
    "                # 리스트를 텐서로 변환\n",
    "                ner_predictions = torch.zeros_like(input_ids)\n",
    "                for i, tags in enumerate(best_ner_tags_list):\n",
    "                    ner_predictions[i, :len(tags)] = torch.tensor(tags, device=ner_predictions.device)\n",
    "            else:\n",
    "                best_ner_tags_list = self.crf.decode(ner_logits)\n",
    "                ner_predictions = torch.tensor(best_ner_tags_list, device=ner_logits.device)\n",
    "\n",
    "        return {\n",
    "            \"intent_logits\": intent_logits,\n",
    "            \"ner_logits\": ner_logits,\n",
    "            \"intent_predictions\": intent_predictions,\n",
    "            \"ner_predictions\": ner_predictions\n",
    "        }\n",
    "\n",
    "# --- 모델 로드 및 테스트를 위한 클래스 ---\n",
    "class NLUTester:\n",
    "    def __init__(self, model_dir=\"./models/integrated_nlu_improved\"):\n",
    "        self.model_dir = model_dir\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"사용 중인 디바이스: {self.device}\")\n",
    "        \n",
    "        # 레이블 정보 로드\n",
    "        with open(os.path.join(model_dir, \"nlu_labels.jsonc\"), 'r', encoding='utf-8') as f:\n",
    "            self.label_info = commentjson.load(f)\n",
    "        \n",
    "        self.intent_id2label = self.label_info[\"intent_id2label\"]\n",
    "        self.intent_label2id = self.label_info[\"intent_label2id\"]\n",
    "        self.ner_id2label = self.label_info[\"ner_id2label\"]\n",
    "        self.ner_label2id = self.label_info[\"ner_label2id\"]\n",
    "        \n",
    "        # ID를 문자열에서 정수로 변환 (JSON에서는 키가 문자열로 저장됨)\n",
    "        self.intent_id2label = {int(k): v for k, v in self.intent_id2label.items()}\n",
    "        self.ner_id2label = {int(k): v for k, v in self.ner_id2label.items()}\n",
    "        \n",
    "        print(f\"인텐트 레이블 수: {len(self.intent_id2label)}\")\n",
    "        print(f\"NER 레이블 수: {len(self.ner_id2label)}\")\n",
    "        \n",
    "        # 토크나이저 로드\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "        \n",
    "        # 설정 파일 직접 열고 RoBERTa 설정으로 변환\n",
    "        try:\n",
    "            config_file = os.path.join(model_dir, \"config.json\")\n",
    "            with open(config_file, 'r', encoding='utf-8') as f:\n",
    "                config_dict = json.load(f)\n",
    "            \n",
    "            # 모델 타입을 roberta로 변경\n",
    "            config_dict[\"model_type\"] = \"roberta\"\n",
    "            \n",
    "            # 변경된 설정으로 AutoConfig 생성\n",
    "            from transformers import RobertaConfig\n",
    "            self.config = RobertaConfig.from_dict(config_dict)\n",
    "        except Exception as e:\n",
    "            print(f\"설정 파일 변경 중 오류: {str(e)}\")\n",
    "            # 폴백: 기본 RoBERTa 설정 사용\n",
    "            from transformers import RobertaConfig\n",
    "            self.config = RobertaConfig.from_pretrained(\"klue/roberta-base\")\n",
    "            # 레이블 수 설정\n",
    "            self.config.num_labels = len(self.intent_label2id)\n",
    "        \n",
    "        # 직접 모델 생성\n",
    "        self.model = ImprovedRobertaForJointIntentAndNER(\n",
    "            self.config, \n",
    "            self.intent_label2id, \n",
    "            self.ner_label2id\n",
    "        )\n",
    "        \n",
    "        # 모델 가중치 로드\n",
    "        state_dict = torch.load(os.path.join(model_dir, \"pytorch_model.bin\"), map_location=self.device)\n",
    "        \n",
    "        # 가중치 로드 시 오류 처리 (키 이름 불일치 문제 해결)\n",
    "        try:\n",
    "            self.model.load_state_dict(state_dict)\n",
    "        except Exception as e:\n",
    "            print(f\"가중치 로드 중 오류 발생: {str(e)}\")\n",
    "            print(\"가중치 로드 방식을 변경하여 다시 시도합니다...\")\n",
    "            \n",
    "            # 불일치하는 키 수정하여 로드\n",
    "            from collections import OrderedDict\n",
    "            new_state_dict = OrderedDict()\n",
    "            \n",
    "            for k, v in state_dict.items():\n",
    "                # 키 이름 변환이 필요한 경우 여기서 처리\n",
    "                if k.startswith('roberta.'):\n",
    "                    new_state_dict[k] = v\n",
    "                else:\n",
    "                    new_state_dict[k] = v\n",
    "            \n",
    "            # 엄격하지 않은 로드 시도\n",
    "            self.model.load_state_dict(new_state_dict, strict=False)\n",
    "            print(\"유연한 방식으로 가중치 로드 완료!\")\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        print(\"모델 로드 완료!\")\n",
    "    \n",
    "    def predict(self, text):\n",
    "        # 입력 텍스트 토큰화\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        \n",
    "        input_ids = inputs[\"input_ids\"].to(self.device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(self.device)\n",
    "        offset_mapping = inputs[\"offset_mapping\"][0].numpy()  # 토큰-문자 매핑 정보\n",
    "        \n",
    "        # 예측 실행\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "        \n",
    "        # 인텐트 예측 결과 처리\n",
    "        intent_logits = outputs[\"intent_logits\"][0]\n",
    "        intent_probs = F.softmax(intent_logits, dim=0).cpu().numpy()\n",
    "        intent_pred_id = outputs[\"intent_predictions\"][0].item()\n",
    "        intent_pred = self.intent_id2label[intent_pred_id]\n",
    "        \n",
    "        # 인텐트 상위 5개 확률 추출\n",
    "        top_intent_indices = np.argsort(intent_probs)[::-1][:5]  # 상위 5개\n",
    "        top_intents = [(self.intent_id2label[idx], intent_probs[idx]) for idx in top_intent_indices]\n",
    "        \n",
    "        # NER 예측 결과 처리\n",
    "        ner_predictions = outputs[\"ner_predictions\"][0].cpu().numpy()\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        \n",
    "        # 토큰별 NER 태그 추출\n",
    "        ner_tags = []\n",
    "        entity_spans = []\n",
    "        current_entity = None\n",
    "        \n",
    "        for i, (token_id, pred_id, (start, end)) in enumerate(zip(input_ids[0].cpu().numpy(), \n",
    "                                                               ner_predictions, \n",
    "                                                               offset_mapping)):\n",
    "            # 특수 토큰 또는 패딩 건너뛰기\n",
    "            if start == 0 and end == 0:\n",
    "                continue\n",
    "                \n",
    "            # 예측된 태그 가져오기\n",
    "            tag = self.ner_id2label.get(pred_id, \"O\")\n",
    "            token = self.tokenizer.convert_ids_to_tokens([token_id])[0]\n",
    "            \n",
    "            # NER 태그-토큰 쌍 저장\n",
    "            if tag != \"O\" and token.startswith(\"##\"):\n",
    "                # 서브워드 토큰인 경우 이전 토큰에 병합\n",
    "                if ner_tags:\n",
    "                    ner_tags[-1] = (ner_tags[-1][0], ner_tags[-1][1] + token[2:], ner_tags[-1][2])\n",
    "            else:\n",
    "                ner_tags.append((tag, token, (start, end)))\n",
    "            \n",
    "            # 엔티티 추출 (B-tag로 시작하는 경우)\n",
    "            if tag.startswith(\"B-\"):\n",
    "                if current_entity:\n",
    "                    entity_spans.append(current_entity)\n",
    "                entity_type = tag[2:]\n",
    "                current_entity = {\n",
    "                    \"entity_type\": entity_type,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"text\": text[start:end]\n",
    "                }\n",
    "            # I-tag인 경우 현재 엔티티에 추가\n",
    "            elif tag.startswith(\"I-\") and current_entity:\n",
    "                if tag[2:] == current_entity[\"entity_type\"]:\n",
    "                    current_entity[\"end\"] = end\n",
    "                    current_entity[\"text\"] = text[current_entity[\"start\"]:end]\n",
    "            # O-tag인 경우 현재 엔티티 저장\n",
    "            elif tag == \"O\" and current_entity:\n",
    "                entity_spans.append(current_entity)\n",
    "                current_entity = None\n",
    "        \n",
    "        # 마지막 엔티티 저장\n",
    "        if current_entity:\n",
    "            entity_spans.append(current_entity)\n",
    "        \n",
    "        # 결과 반환\n",
    "        result = {\n",
    "            \"text\": text,\n",
    "            \"intent\": {\n",
    "                \"predicted\": intent_pred,\n",
    "                \"confidence\": float(intent_probs[intent_pred_id]),\n",
    "                \"top_k\": top_intents\n",
    "            },\n",
    "            \"ner\": {\n",
    "                \"token_tags\": ner_tags,\n",
    "                \"entities\": entity_spans\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def visualize_text_with_entities(self, text, entities):\n",
    "        \"\"\"엔티티를 하이라이트하여 HTML로 보여주는 시각화 함수\"\"\"\n",
    "        # 엔티티 색상 맵 정의\n",
    "        color_map = {\n",
    "            \"PERSON\": \"#FFADAD\",  # 연한 빨강\n",
    "            \"LOCATION\": \"#FFD6A5\",  # 연한 주황\n",
    "            \"ORGANIZATION\": \"#FDFFB6\",  # 연한 노랑\n",
    "            \"DATE\": \"#CAFFBF\", # 연한 초록\n",
    "            \"TIME\": \"#98F6FF\", # 연한 청록\n",
    "            \"MONEY\": \"#A0C4FF\", # 연한 파랑\n",
    "            \"PERCENT\": \"#BDB2FF\", # 연한 남색\n",
    "            \"PHONE\": \"#FFC6FF\", # 연한 자주\n",
    "            \"EMAIL\": \"#D1D1D1\",  # 연한 회색\n",
    "            \"NUMBER\": \"#99FFFF\",  # 연한 하늘색\n",
    "            \"EVENT\": \"#EBFF99\", # 연한 라임\n",
    "            \"PRODUCT\": \"#FF9CEE\",  # 연한 분홍\n",
    "            \"DURATION\": \"#FFD700\",  # 골드\n",
    "            \"FACILITY\": \"#B4F4A8\", # 연한 민트\n",
    "            \"QUANTITY\": \"#C8A2C8\", # 연한 보라\n",
    "            \"CARDINAL\": \"#F0EAD6\"  # 크림색\n",
    "        }\n",
    "        \n",
    "        # 기본 색상\n",
    "        default_color = \"#FFE4E1\"  # 연한 붉은색\n",
    "        \n",
    "        # 텍스트를 HTML로 변환\n",
    "        html_text = text\n",
    "        \n",
    "        # 엔티티 위치 기준으로 정렬 (뒤에서부터 처리하여 인덱스 문제 방지)\n",
    "        sorted_entities = sorted(entities, key=lambda x: x[\"start\"], reverse=True)\n",
    "        \n",
    "        for entity in sorted_entities:\n",
    "            entity_type = entity[\"entity_type\"]\n",
    "            start = entity[\"start\"]\n",
    "            end = entity[\"end\"]\n",
    "            entity_text = entity[\"text\"]\n",
    "            \n",
    "            # 엔티티 색상 설정\n",
    "            color = color_map.get(entity_type, default_color)\n",
    "            \n",
    "            # HTML 태그로 감싸기\n",
    "            html_tag = f'<span style=\"background-color: {color}; padding: 2px; border-radius: 3px;\" title=\"{entity_type}\">{entity_text}</span>'\n",
    "            html_text = html_text[:start] + html_tag + html_text[end:]\n",
    "        \n",
    "        return html_text\n",
    "\n",
    "# --- 인터랙티브 테스트 위젯 생성 ---\n",
    "def create_test_widgets(tester):\n",
    "    # 입력 텍스트 위젯\n",
    "    text_input = widgets.Textarea(\n",
    "        value='안녕하세요, 내일 서울에서 오후 2시에 김영희 씨와 약속이 있어요.',\n",
    "        placeholder='테스트할 텍스트를 입력하세요',\n",
    "        description='입력 텍스트:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='90%', height='100px')\n",
    "    )\n",
    "    \n",
    "    # 예측 버튼\n",
    "    predict_button = widgets.Button(\n",
    "        description='예측하기',\n",
    "        button_style='primary',\n",
    "        tooltip='모델로 예측 실행',\n",
    "        icon='check'\n",
    "    )\n",
    "    \n",
    "    # 출력 영역\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # 예시 텍스트 버튼\n",
    "    example_texts = [\n",
    "        '내일 오후 3시에 홍길동 씨에게 전화해야 해요.',\n",
    "        '서울에서 부산까지 KTX 표를 예약하고 싶어요.',\n",
    "        '주문한 상품이 언제 배송될지 알려주세요.',\n",
    "        '오늘 날씨가 어때요?',\n",
    "        '내 계좌에서 50만원을 이체해줘.',\n",
    "        'ABC123 상품의 재고가 있나요?'\n",
    "    ]\n",
    "    \n",
    "    example_buttons = [widgets.Button(description=f'예시 {i+1}', \n",
    "                                     layout=widgets.Layout(width='100px')) \n",
    "                      for i in range(len(example_texts))]\n",
    "    \n",
    "    # 예시 버튼 클릭 이벤트 처리\n",
    "    def on_example_click(b):\n",
    "        index = example_buttons.index(b)\n",
    "        text_input.value = example_texts[index]\n",
    "    \n",
    "    for button in example_buttons:\n",
    "        button.on_click(on_example_click)\n",
    "    \n",
    "    # 버튼 클릭 이벤트 처리\n",
    "    def on_predict_button_clicked(b):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not text_input.value.strip():\n",
    "                print(\"입력 텍스트를 입력해주세요!\")\n",
    "                return\n",
    "            \n",
    "            try:\n",
    "                # 모델 예측 실행\n",
    "                result = tester.predict(text_input.value)\n",
    "                \n",
    "                # 결과 시각화\n",
    "                # 1. 인텐트 결과\n",
    "                print(\"📋 분석 결과:\")\n",
    "                print(f\"원문: {result['text']}\")\n",
    "                print(\"\\n🎯 인텐트 분석:\")\n",
    "                print(f\"예측된 인텐트: {result['intent']['predicted']} (확률: {result['intent']['confidence']:.4f})\")\n",
    "                \n",
    "                # 2. 인텐트 확률 시각화 (상위 5개)\n",
    "                plt.figure(figsize=(10, 3))\n",
    "                intent_names = [intent[0] for intent in result['intent']['top_k']]\n",
    "                intent_probs = [intent[1] for intent in result['intent']['top_k']]\n",
    "                \n",
    "                # 가로 막대 그래프로 표시\n",
    "                sns.barplot(x=intent_probs, y=intent_names, palette=\"Blues_r\")\n",
    "                plt.xlim(0, 1)\n",
    "                plt.title(\"인텐트 예측 확률 (상위 5개)\")\n",
    "                plt.xlabel(\"확률\")\n",
    "                plt.ylabel(\"인텐트\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # 3. NER 결과\n",
    "                print(\"\\n🔍 개체명(NER) 분석:\")\n",
    "                \n",
    "                if result['ner']['entities']:\n",
    "                    # 엔티티 시각화\n",
    "                    html_text = tester.visualize_text_with_entities(result['text'], result['ner']['entities'])\n",
    "                    display(HTML(f\"<div style='font-size: 16px; padding: 10px; border: 1px solid #ddd; border-radius: 5px;'>{html_text}</div>\"))\n",
    "                    \n",
    "                    # 인식된 엔티티 표로 출력\n",
    "                    print(\"\\n인식된 개체명:\")\n",
    "                    for i, entity in enumerate(result['ner']['entities']):\n",
    "                        print(f\"  {i+1}. {entity['text']} ({entity['entity_type']}, 위치: {entity['start']}~{entity['end']})\")\n",
    "                else:\n",
    "                    print(\"인식된 개체명이 없습니다.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"오류 발생: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    # 버튼 클릭 이벤트 연결\n",
    "    predict_button.on_click(on_predict_button_clicked)\n",
    "    \n",
    "    # 위젯 배치\n",
    "    example_box = widgets.HBox(example_buttons)\n",
    "    \n",
    "    # 전체 UI 구성\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HTML(value=\"<h2>통합 NLU 모델 테스트</h2>\"),\n",
    "        widgets.HTML(value=\"<p>아래에 테스트할 텍스트를 입력하거나 예시 버튼을 클릭하세요.</p>\"),\n",
    "        example_box,\n",
    "        text_input,\n",
    "        predict_button,\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# --- 메인 실행 코드 ---\n",
    "def run_tester():\n",
    "    try:\n",
    "        # 기본 모델 디렉토리 설정\n",
    "        model_dir = \"./models/integrated_nlu_improved\"\n",
    "        \n",
    "        # 모델 디렉토리가 존재하는지 확인\n",
    "        if not os.path.exists(model_dir):\n",
    "            print(f\"경고: 모델 디렉토리 {model_dir}가 존재하지 않습니다.\")\n",
    "            model_dir = input(\"모델 디렉토리 경로를 입력해주세요: \")\n",
    "            if not os.path.exists(model_dir):\n",
    "                print(f\"오류: 모델 디렉토리 {model_dir}가 존재하지 않습니다. 정확한 경로를 확인해주세요.\")\n",
    "                return\n",
    "        \n",
    "        # NLU 테스터 초기화\n",
    "        tester = NLUTester(model_dir)\n",
    "        \n",
    "        # 인터랙티브 위젯 생성 및 표시\n",
    "        ui = create_test_widgets(tester)\n",
    "        display(ui)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# 노트북에서 실행\n",
    "if __name__ == \"__main__\":\n",
    "    run_tester()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
