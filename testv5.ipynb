{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: cuda\n",
      "ì¸í…íŠ¸ ë ˆì´ë¸” ìˆ˜: 40\n",
      "NER ë ˆì´ë¸” ìˆ˜: 51\n",
      "ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bfd04eea5e456fb6db5e2b2772d943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>í†µí•© NLU ëª¨ë¸ í…ŒìŠ¤íŠ¸</h2>'), HTML(value='<p>ì•„ë˜ì— í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì˜ˆì‹œ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.</p>'), Hâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NLU ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë…¸íŠ¸ë¶\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import commentjson  # ì£¼ì„ì´ í¬í•¨ëœ JSON íŒŒì¼ì„ ìœ„í•´ í•„ìš”\n",
    "from torch.nn import functional as F\n",
    "from torchcrf import CRF\n",
    "import torch.nn as nn\n",
    "from transformers import PreTrainedModel\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "# --- ëª¨ë¸ ì •ì˜ (ì›ë³¸ ì½”ë“œì—ì„œ ê°€ì ¸ì˜´) ---\n",
    "class ImprovedRobertaForJointIntentAndNER(PreTrainedModel):\n",
    "    def __init__(self, config, intent_label_to_id, ner_label_to_id):\n",
    "        super().__init__(config)\n",
    "        self.num_intent_labels = len(intent_label_to_id)\n",
    "        self.num_ner_labels = len(ner_label_to_id)\n",
    "\n",
    "        # ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ\n",
    "        from transformers import RobertaModel\n",
    "        self.roberta = RobertaModel(config)  # ì§ì ‘ RobertaModelì„ ì‚¬ìš©\n",
    "\n",
    "        # Intent ë¶„ë¥˜ë¥¼ ìœ„í•œ í—¤ë“œ (ê°œì„ : ë” ë³µì¡í•œ ë¶„ë¥˜ê¸°)\n",
    "        self.intent_dropout = nn.Dropout(0.2)  # dropout ë¹„ìœ¨ ì¡°ì •\n",
    "        self.intent_classifier = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size // 2),\n",
    "            nn.GELU(),  # ReLU ëŒ€ì‹  GELU ì‚¬ìš©\n",
    "            nn.LayerNorm(config.hidden_size // 2),  # Layer Normalization ì¶”ê°€\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(config.hidden_size // 2, self.num_intent_labels)\n",
    "        )\n",
    "\n",
    "        # NERì„ ìœ„í•œ í—¤ë“œ (ê°œì„ : BiLSTM + CRF)\n",
    "        self.ner_dropout = nn.Dropout(0.3)  # NER dropout ì¦ê°€\n",
    "        self.ner_lstm = nn.LSTM(\n",
    "            config.hidden_size,\n",
    "            config.hidden_size // 2,\n",
    "            num_layers=2,  # LSTM ë ˆì´ì–´ ì¶”ê°€\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.ner_classifier = nn.Linear(config.hidden_size, self.num_ner_labels)\n",
    "\n",
    "        # CRF ë ˆì´ì–´ (NERìš©)\n",
    "        self.crf = CRF(self.num_ner_labels, batch_first=True)\n",
    "\n",
    "        # ì´ˆê¸° ê°€ì¤‘ì¹˜ ì„¤ì • (í›ˆë ¨ëœ ëª¨ë¸ì„ ë¡œë“œí•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” í•„ìš” ì—†ìŒ)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        intent_labels=None,\n",
    "        ner_labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        # RoBERTa ì¸ì½”ë” ì‹¤í–‰\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]  # ëª¨ë“  í† í°ì˜ ì„ë² ë”©\n",
    "        pooled_output = sequence_output[:, 0, :]  # [CLS] í† í° ì„ë² ë”© (Intent ìš©)\n",
    "\n",
    "        # Intent ë¶„ë¥˜ (ê°œì„ ëœ ë¶„ë¥˜ê¸°)\n",
    "        intent_output = self.intent_dropout(pooled_output)\n",
    "        intent_logits = self.intent_classifier(intent_output)\n",
    "\n",
    "        # NER ë¶„ë¥˜ (BiLSTM + CRF)\n",
    "        ner_output = self.ner_dropout(sequence_output)\n",
    "        ner_lstm_output, _ = self.ner_lstm(ner_output)\n",
    "        ner_logits = self.ner_classifier(ner_lstm_output)\n",
    "\n",
    "        # ì˜ˆì¸¡ ë‹¨ê³„\n",
    "        intent_predictions = None\n",
    "        ner_predictions = None\n",
    "\n",
    "        if intent_labels is None:\n",
    "            intent_predictions = torch.argmax(intent_logits, dim=1)\n",
    "\n",
    "        if ner_labels is None:\n",
    "            if attention_mask is not None:\n",
    "                mask = attention_mask.bool()\n",
    "                best_ner_tags_list = self.crf.decode(ner_logits, mask=mask)\n",
    "\n",
    "                # ë¦¬ìŠ¤íŠ¸ë¥¼ í…ì„œë¡œ ë³€í™˜\n",
    "                ner_predictions = torch.zeros_like(input_ids)\n",
    "                for i, tags in enumerate(best_ner_tags_list):\n",
    "                    ner_predictions[i, :len(tags)] = torch.tensor(tags, device=ner_predictions.device)\n",
    "            else:\n",
    "                best_ner_tags_list = self.crf.decode(ner_logits)\n",
    "                ner_predictions = torch.tensor(best_ner_tags_list, device=ner_logits.device)\n",
    "\n",
    "        return {\n",
    "            \"intent_logits\": intent_logits,\n",
    "            \"ner_logits\": ner_logits,\n",
    "            \"intent_predictions\": intent_predictions,\n",
    "            \"ner_predictions\": ner_predictions\n",
    "        }\n",
    "\n",
    "# --- ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ ---\n",
    "class NLUTester:\n",
    "    def __init__(self, model_dir=\"./models/integrated_nlu_improved\"):\n",
    "        self.model_dir = model_dir\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {self.device}\")\n",
    "        \n",
    "        # ë ˆì´ë¸” ì •ë³´ ë¡œë“œ\n",
    "        with open(os.path.join(model_dir, \"nlu_labels.jsonc\"), 'r', encoding='utf-8') as f:\n",
    "            self.label_info = commentjson.load(f)\n",
    "        \n",
    "        self.intent_id2label = self.label_info[\"intent_id2label\"]\n",
    "        self.intent_label2id = self.label_info[\"intent_label2id\"]\n",
    "        self.ner_id2label = self.label_info[\"ner_id2label\"]\n",
    "        self.ner_label2id = self.label_info[\"ner_label2id\"]\n",
    "        \n",
    "        # IDë¥¼ ë¬¸ìì—´ì—ì„œ ì •ìˆ˜ë¡œ ë³€í™˜ (JSONì—ì„œëŠ” í‚¤ê°€ ë¬¸ìì—´ë¡œ ì €ì¥ë¨)\n",
    "        self.intent_id2label = {int(k): v for k, v in self.intent_id2label.items()}\n",
    "        self.ner_id2label = {int(k): v for k, v in self.ner_id2label.items()}\n",
    "        \n",
    "        print(f\"ì¸í…íŠ¸ ë ˆì´ë¸” ìˆ˜: {len(self.intent_id2label)}\")\n",
    "        print(f\"NER ë ˆì´ë¸” ìˆ˜: {len(self.ner_id2label)}\")\n",
    "        \n",
    "        # í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "        \n",
    "        # ì„¤ì • íŒŒì¼ ì§ì ‘ ì—´ê³  RoBERTa ì„¤ì •ìœ¼ë¡œ ë³€í™˜\n",
    "        try:\n",
    "            config_file = os.path.join(model_dir, \"config.json\")\n",
    "            with open(config_file, 'r', encoding='utf-8') as f:\n",
    "                config_dict = json.load(f)\n",
    "            \n",
    "            # ëª¨ë¸ íƒ€ì…ì„ robertaë¡œ ë³€ê²½\n",
    "            config_dict[\"model_type\"] = \"roberta\"\n",
    "            \n",
    "            # ë³€ê²½ëœ ì„¤ì •ìœ¼ë¡œ AutoConfig ìƒì„±\n",
    "            from transformers import RobertaConfig\n",
    "            self.config = RobertaConfig.from_dict(config_dict)\n",
    "        except Exception as e:\n",
    "            print(f\"ì„¤ì • íŒŒì¼ ë³€ê²½ ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
    "            # í´ë°±: ê¸°ë³¸ RoBERTa ì„¤ì • ì‚¬ìš©\n",
    "            from transformers import RobertaConfig\n",
    "            self.config = RobertaConfig.from_pretrained(\"klue/roberta-base\")\n",
    "            # ë ˆì´ë¸” ìˆ˜ ì„¤ì •\n",
    "            self.config.num_labels = len(self.intent_label2id)\n",
    "        \n",
    "        # ì§ì ‘ ëª¨ë¸ ìƒì„±\n",
    "        self.model = ImprovedRobertaForJointIntentAndNER(\n",
    "            self.config, \n",
    "            self.intent_label2id, \n",
    "            self.ner_label2id\n",
    "        )\n",
    "        \n",
    "        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "        state_dict = torch.load(os.path.join(model_dir, \"pytorch_model.bin\"), map_location=self.device)\n",
    "        \n",
    "        # ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œ ì˜¤ë¥˜ ì²˜ë¦¬ (í‚¤ ì´ë¦„ ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²°)\n",
    "        try:\n",
    "            self.model.load_state_dict(state_dict)\n",
    "        except Exception as e:\n",
    "            print(f\"ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "            print(\"ê°€ì¤‘ì¹˜ ë¡œë“œ ë°©ì‹ì„ ë³€ê²½í•˜ì—¬ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤...\")\n",
    "            \n",
    "            # ë¶ˆì¼ì¹˜í•˜ëŠ” í‚¤ ìˆ˜ì •í•˜ì—¬ ë¡œë“œ\n",
    "            from collections import OrderedDict\n",
    "            new_state_dict = OrderedDict()\n",
    "            \n",
    "            for k, v in state_dict.items():\n",
    "                # í‚¤ ì´ë¦„ ë³€í™˜ì´ í•„ìš”í•œ ê²½ìš° ì—¬ê¸°ì„œ ì²˜ë¦¬\n",
    "                if k.startswith('roberta.'):\n",
    "                    new_state_dict[k] = v\n",
    "                else:\n",
    "                    new_state_dict[k] = v\n",
    "            \n",
    "            # ì—„ê²©í•˜ì§€ ì•Šì€ ë¡œë“œ ì‹œë„\n",
    "            self.model.load_state_dict(new_state_dict, strict=False)\n",
    "            print(\"ìœ ì—°í•œ ë°©ì‹ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ!\")\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        print(\"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "    \n",
    "    def predict(self, text):\n",
    "        # ì…ë ¥ í…ìŠ¤íŠ¸ í† í°í™”\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        \n",
    "        input_ids = inputs[\"input_ids\"].to(self.device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(self.device)\n",
    "        offset_mapping = inputs[\"offset_mapping\"][0].numpy()  # í† í°-ë¬¸ì ë§¤í•‘ ì •ë³´\n",
    "        \n",
    "        # ì˜ˆì¸¡ ì‹¤í–‰\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "        \n",
    "        # ì¸í…íŠ¸ ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬\n",
    "        intent_logits = outputs[\"intent_logits\"][0]\n",
    "        intent_probs = F.softmax(intent_logits, dim=0).cpu().numpy()\n",
    "        intent_pred_id = outputs[\"intent_predictions\"][0].item()\n",
    "        intent_pred = self.intent_id2label[intent_pred_id]\n",
    "        \n",
    "        # ì¸í…íŠ¸ ìƒìœ„ 5ê°œ í™•ë¥  ì¶”ì¶œ\n",
    "        top_intent_indices = np.argsort(intent_probs)[::-1][:5]  # ìƒìœ„ 5ê°œ\n",
    "        top_intents = [(self.intent_id2label[idx], intent_probs[idx]) for idx in top_intent_indices]\n",
    "        \n",
    "        # NER ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬\n",
    "        ner_predictions = outputs[\"ner_predictions\"][0].cpu().numpy()\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        \n",
    "        # í† í°ë³„ NER íƒœê·¸ ì¶”ì¶œ\n",
    "        ner_tags = []\n",
    "        entity_spans = []\n",
    "        current_entity = None\n",
    "        \n",
    "        for i, (token_id, pred_id, (start, end)) in enumerate(zip(input_ids[0].cpu().numpy(), \n",
    "                                                               ner_predictions, \n",
    "                                                               offset_mapping)):\n",
    "            # íŠ¹ìˆ˜ í† í° ë˜ëŠ” íŒ¨ë”© ê±´ë„ˆë›°ê¸°\n",
    "            if start == 0 and end == 0:\n",
    "                continue\n",
    "                \n",
    "            # ì˜ˆì¸¡ëœ íƒœê·¸ ê°€ì ¸ì˜¤ê¸°\n",
    "            tag = self.ner_id2label.get(pred_id, \"O\")\n",
    "            token = self.tokenizer.convert_ids_to_tokens([token_id])[0]\n",
    "            \n",
    "            # NER íƒœê·¸-í† í° ìŒ ì €ì¥\n",
    "            if tag != \"O\" and token.startswith(\"##\"):\n",
    "                # ì„œë¸Œì›Œë“œ í† í°ì¸ ê²½ìš° ì´ì „ í† í°ì— ë³‘í•©\n",
    "                if ner_tags:\n",
    "                    ner_tags[-1] = (ner_tags[-1][0], ner_tags[-1][1] + token[2:], ner_tags[-1][2])\n",
    "            else:\n",
    "                ner_tags.append((tag, token, (start, end)))\n",
    "            \n",
    "            # ì—”í‹°í‹° ì¶”ì¶œ (B-tagë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°)\n",
    "            if tag.startswith(\"B-\"):\n",
    "                if current_entity:\n",
    "                    entity_spans.append(current_entity)\n",
    "                entity_type = tag[2:]\n",
    "                current_entity = {\n",
    "                    \"entity_type\": entity_type,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"text\": text[start:end]\n",
    "                }\n",
    "            # I-tagì¸ ê²½ìš° í˜„ì¬ ì—”í‹°í‹°ì— ì¶”ê°€\n",
    "            elif tag.startswith(\"I-\") and current_entity:\n",
    "                if tag[2:] == current_entity[\"entity_type\"]:\n",
    "                    current_entity[\"end\"] = end\n",
    "                    current_entity[\"text\"] = text[current_entity[\"start\"]:end]\n",
    "            # O-tagì¸ ê²½ìš° í˜„ì¬ ì—”í‹°í‹° ì €ì¥\n",
    "            elif tag == \"O\" and current_entity:\n",
    "                entity_spans.append(current_entity)\n",
    "                current_entity = None\n",
    "        \n",
    "        # ë§ˆì§€ë§‰ ì—”í‹°í‹° ì €ì¥\n",
    "        if current_entity:\n",
    "            entity_spans.append(current_entity)\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜\n",
    "        result = {\n",
    "            \"text\": text,\n",
    "            \"intent\": {\n",
    "                \"predicted\": intent_pred,\n",
    "                \"confidence\": float(intent_probs[intent_pred_id]),\n",
    "                \"top_k\": top_intents\n",
    "            },\n",
    "            \"ner\": {\n",
    "                \"token_tags\": ner_tags,\n",
    "                \"entities\": entity_spans\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def visualize_text_with_entities(self, text, entities):\n",
    "        \"\"\"ì—”í‹°í‹°ë¥¼ í•˜ì´ë¼ì´íŠ¸í•˜ì—¬ HTMLë¡œ ë³´ì—¬ì£¼ëŠ” ì‹œê°í™” í•¨ìˆ˜\"\"\"\n",
    "        # ì—”í‹°í‹° ìƒ‰ìƒ ë§µ ì •ì˜\n",
    "        color_map = {\n",
    "            \"PERSON\": \"#FFADAD\",  # ì—°í•œ ë¹¨ê°•\n",
    "            \"LOCATION\": \"#FFD6A5\",  # ì—°í•œ ì£¼í™©\n",
    "            \"ORGANIZATION\": \"#FDFFB6\",  # ì—°í•œ ë…¸ë‘\n",
    "            \"DATE\": \"#CAFFBF\", # ì—°í•œ ì´ˆë¡\n",
    "            \"TIME\": \"#98F6FF\", # ì—°í•œ ì²­ë¡\n",
    "            \"MONEY\": \"#A0C4FF\", # ì—°í•œ íŒŒë‘\n",
    "            \"PERCENT\": \"#BDB2FF\", # ì—°í•œ ë‚¨ìƒ‰\n",
    "            \"PHONE\": \"#FFC6FF\", # ì—°í•œ ìì£¼\n",
    "            \"EMAIL\": \"#D1D1D1\",  # ì—°í•œ íšŒìƒ‰\n",
    "            \"NUMBER\": \"#99FFFF\",  # ì—°í•œ í•˜ëŠ˜ìƒ‰\n",
    "            \"EVENT\": \"#EBFF99\", # ì—°í•œ ë¼ì„\n",
    "            \"PRODUCT\": \"#FF9CEE\",  # ì—°í•œ ë¶„í™\n",
    "            \"DURATION\": \"#FFD700\",  # ê³¨ë“œ\n",
    "            \"FACILITY\": \"#B4F4A8\", # ì—°í•œ ë¯¼íŠ¸\n",
    "            \"QUANTITY\": \"#C8A2C8\", # ì—°í•œ ë³´ë¼\n",
    "            \"CARDINAL\": \"#F0EAD6\"  # í¬ë¦¼ìƒ‰\n",
    "        }\n",
    "        \n",
    "        # ê¸°ë³¸ ìƒ‰ìƒ\n",
    "        default_color = \"#FFE4E1\"  # ì—°í•œ ë¶‰ì€ìƒ‰\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ë¥¼ HTMLë¡œ ë³€í™˜\n",
    "        html_text = text\n",
    "        \n",
    "        # ì—”í‹°í‹° ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë’¤ì—ì„œë¶€í„° ì²˜ë¦¬í•˜ì—¬ ì¸ë±ìŠ¤ ë¬¸ì œ ë°©ì§€)\n",
    "        sorted_entities = sorted(entities, key=lambda x: x[\"start\"], reverse=True)\n",
    "        \n",
    "        for entity in sorted_entities:\n",
    "            entity_type = entity[\"entity_type\"]\n",
    "            start = entity[\"start\"]\n",
    "            end = entity[\"end\"]\n",
    "            entity_text = entity[\"text\"]\n",
    "            \n",
    "            # ì—”í‹°í‹° ìƒ‰ìƒ ì„¤ì •\n",
    "            color = color_map.get(entity_type, default_color)\n",
    "            \n",
    "            # HTML íƒœê·¸ë¡œ ê°ì‹¸ê¸°\n",
    "            html_tag = f'<span style=\"background-color: {color}; padding: 2px; border-radius: 3px;\" title=\"{entity_type}\">{entity_text}</span>'\n",
    "            html_text = html_text[:start] + html_tag + html_text[end:]\n",
    "        \n",
    "        return html_text\n",
    "\n",
    "# --- ì¸í„°ë™í‹°ë¸Œ í…ŒìŠ¤íŠ¸ ìœ„ì ¯ ìƒì„± ---\n",
    "def create_test_widgets(tester):\n",
    "    # ì…ë ¥ í…ìŠ¤íŠ¸ ìœ„ì ¯\n",
    "    text_input = widgets.Textarea(\n",
    "        value='ì•ˆë…•í•˜ì„¸ìš”, ë‚´ì¼ ì„œìš¸ì—ì„œ ì˜¤í›„ 2ì‹œì— ê¹€ì˜í¬ ì”¨ì™€ ì•½ì†ì´ ìˆì–´ìš”.',\n",
    "        placeholder='í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”',\n",
    "        description='ì…ë ¥ í…ìŠ¤íŠ¸:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='90%', height='100px')\n",
    "    )\n",
    "    \n",
    "    # ì˜ˆì¸¡ ë²„íŠ¼\n",
    "    predict_button = widgets.Button(\n",
    "        description='ì˜ˆì¸¡í•˜ê¸°',\n",
    "        button_style='primary',\n",
    "        tooltip='ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì‹¤í–‰',\n",
    "        icon='check'\n",
    "    )\n",
    "    \n",
    "    # ì¶œë ¥ ì˜ì—­\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # ì˜ˆì‹œ í…ìŠ¤íŠ¸ ë²„íŠ¼\n",
    "    example_texts = [\n",
    "        'ë‚´ì¼ ì˜¤í›„ 3ì‹œì— í™ê¸¸ë™ ì”¨ì—ê²Œ ì „í™”í•´ì•¼ í•´ìš”.',\n",
    "        'ì„œìš¸ì—ì„œ ë¶€ì‚°ê¹Œì§€ KTX í‘œë¥¼ ì˜ˆì•½í•˜ê³  ì‹¶ì–´ìš”.',\n",
    "        'ì£¼ë¬¸í•œ ìƒí’ˆì´ ì–¸ì œ ë°°ì†¡ë ì§€ ì•Œë ¤ì£¼ì„¸ìš”.',\n",
    "        'ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?',\n",
    "        'ë‚´ ê³„ì¢Œì—ì„œ 50ë§Œì›ì„ ì´ì²´í•´ì¤˜.',\n",
    "        'ABC123 ìƒí’ˆì˜ ì¬ê³ ê°€ ìˆë‚˜ìš”?'\n",
    "    ]\n",
    "    \n",
    "    example_buttons = [widgets.Button(description=f'ì˜ˆì‹œ {i+1}', \n",
    "                                     layout=widgets.Layout(width='100px')) \n",
    "                      for i in range(len(example_texts))]\n",
    "    \n",
    "    # ì˜ˆì‹œ ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ ì²˜ë¦¬\n",
    "    def on_example_click(b):\n",
    "        index = example_buttons.index(b)\n",
    "        text_input.value = example_texts[index]\n",
    "    \n",
    "    for button in example_buttons:\n",
    "        button.on_click(on_example_click)\n",
    "    \n",
    "    # ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ ì²˜ë¦¬\n",
    "    def on_predict_button_clicked(b):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not text_input.value.strip():\n",
    "                print(\"ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!\")\n",
    "                return\n",
    "            \n",
    "            try:\n",
    "                # ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰\n",
    "                result = tester.predict(text_input.value)\n",
    "                \n",
    "                # ê²°ê³¼ ì‹œê°í™”\n",
    "                # 1. ì¸í…íŠ¸ ê²°ê³¼\n",
    "                print(\"ğŸ“‹ ë¶„ì„ ê²°ê³¼:\")\n",
    "                print(f\"ì›ë¬¸: {result['text']}\")\n",
    "                print(\"\\nğŸ¯ ì¸í…íŠ¸ ë¶„ì„:\")\n",
    "                print(f\"ì˜ˆì¸¡ëœ ì¸í…íŠ¸: {result['intent']['predicted']} (í™•ë¥ : {result['intent']['confidence']:.4f})\")\n",
    "                \n",
    "                # 2. ì¸í…íŠ¸ í™•ë¥  ì‹œê°í™” (ìƒìœ„ 5ê°œ)\n",
    "                plt.figure(figsize=(10, 3))\n",
    "                intent_names = [intent[0] for intent in result['intent']['top_k']]\n",
    "                intent_probs = [intent[1] for intent in result['intent']['top_k']]\n",
    "                \n",
    "                # ê°€ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ í‘œì‹œ\n",
    "                sns.barplot(x=intent_probs, y=intent_names, palette=\"Blues_r\")\n",
    "                plt.xlim(0, 1)\n",
    "                plt.title(\"ì¸í…íŠ¸ ì˜ˆì¸¡ í™•ë¥  (ìƒìœ„ 5ê°œ)\")\n",
    "                plt.xlabel(\"í™•ë¥ \")\n",
    "                plt.ylabel(\"ì¸í…íŠ¸\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # 3. NER ê²°ê³¼\n",
    "                print(\"\\nğŸ” ê°œì²´ëª…(NER) ë¶„ì„:\")\n",
    "                \n",
    "                if result['ner']['entities']:\n",
    "                    # ì—”í‹°í‹° ì‹œê°í™”\n",
    "                    html_text = tester.visualize_text_with_entities(result['text'], result['ner']['entities'])\n",
    "                    display(HTML(f\"<div style='font-size: 16px; padding: 10px; border: 1px solid #ddd; border-radius: 5px;'>{html_text}</div>\"))\n",
    "                    \n",
    "                    # ì¸ì‹ëœ ì—”í‹°í‹° í‘œë¡œ ì¶œë ¥\n",
    "                    print(\"\\nì¸ì‹ëœ ê°œì²´ëª…:\")\n",
    "                    for i, entity in enumerate(result['ner']['entities']):\n",
    "                        print(f\"  {i+1}. {entity['text']} ({entity['entity_type']}, ìœ„ì¹˜: {entity['start']}~{entity['end']})\")\n",
    "                else:\n",
    "                    print(\"ì¸ì‹ëœ ê°œì²´ëª…ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "    \n",
    "    # ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ ì—°ê²°\n",
    "    predict_button.on_click(on_predict_button_clicked)\n",
    "    \n",
    "    # ìœ„ì ¯ ë°°ì¹˜\n",
    "    example_box = widgets.HBox(example_buttons)\n",
    "    \n",
    "    # ì „ì²´ UI êµ¬ì„±\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HTML(value=\"<h2>í†µí•© NLU ëª¨ë¸ í…ŒìŠ¤íŠ¸</h2>\"),\n",
    "        widgets.HTML(value=\"<p>ì•„ë˜ì— í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì˜ˆì‹œ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.</p>\"),\n",
    "        example_box,\n",
    "        text_input,\n",
    "        predict_button,\n",
    "        output\n",
    "    ])\n",
    "    \n",
    "    return ui\n",
    "\n",
    "# --- ë©”ì¸ ì‹¤í–‰ ì½”ë“œ ---\n",
    "def run_tester():\n",
    "    try:\n",
    "        # ê¸°ë³¸ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "        model_dir = \"./models/integrated_nlu_improved\"\n",
    "        \n",
    "        # ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "        if not os.path.exists(model_dir):\n",
    "            print(f\"ê²½ê³ : ëª¨ë¸ ë””ë ‰í† ë¦¬ {model_dir}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "            model_dir = input(\"ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: \")\n",
    "            if not os.path.exists(model_dir):\n",
    "                print(f\"ì˜¤ë¥˜: ëª¨ë¸ ë””ë ‰í† ë¦¬ {model_dir}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì •í™•í•œ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "                return\n",
    "        \n",
    "        # NLU í…ŒìŠ¤í„° ì´ˆê¸°í™”\n",
    "        tester = NLUTester(model_dir)\n",
    "        \n",
    "        # ì¸í„°ë™í‹°ë¸Œ ìœ„ì ¯ ìƒì„± ë° í‘œì‹œ\n",
    "        ui = create_test_widgets(tester)\n",
    "        display(ui)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ë…¸íŠ¸ë¶ì—ì„œ ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    run_tester()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
