{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84145061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import commentjson\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from datasets import Dataset, Features, Value, ClassLabel, Sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 0. 기본 설정 ---\n",
    "MODEL_NAME = \"klue/bert-base\"\n",
    "MAX_LEN = 64\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# 모델 저장 경로 설정\n",
    "INTENT_MODEL_DIR = \"./models/intent\"\n",
    "NER_MODEL_DIR = \"./models/ner\"\n",
    "INTENT_LABEL_PATH = os.path.join(INTENT_MODEL_DIR, \"intent_labels.jsonc\")\n",
    "NER_LABEL_PATH = os.path.join(NER_MODEL_DIR, \"ner_labels.jsonc\")\n",
    "\n",
    "# --- 1. 데이터 로드 ---\n",
    "# 1.1 Intent 분류를 위한 데이터\n",
    "with open('intent_label_list.jsonc', 'r', encoding='utf-8') as f:\n",
    "    intent_label_list = commentjson.load(f)\n",
    "\n",
    "intent_label_to_id = {label: i for i, label in enumerate(intent_label_list)}\n",
    "intent_id_to_label = {i: label for label, i in intent_label_to_id.items()}\n",
    "\n",
    "with open('intent_data.jsonc', 'r', encoding='utf-8') as f:\n",
    "    intent_data = commentjson.load(f)\n",
    "\n",
    "# 1.2 NER을 위한 데이터\n",
    "with open('ner_data.jsonc', 'r', encoding='utf-8') as f:\n",
    "    loaded_ner_data = commentjson.load(f)\n",
    "\n",
    "ner_data = []\n",
    "for item in loaded_ner_data:\n",
    "    entities_as_tuples = [tuple(entity_list) for entity_list in item.get(\"entities\", [])]\n",
    "    ner_data.append({\"text\": item.get(\"text\", \"\"), \"entities\": entities_as_tuples})\n",
    "\n",
    "# --- 2. Intent 분류 모델 훈련 ---\n",
    "def train_intent_model():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Intent 분류 모델 훈련 시작\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    global intent_label_list, intent_label_to_id, intent_id_to_label\n",
    "\n",
    "    num_intent_labels = len(intent_label_list)\n",
    "    print(f\"Intent 레이블 ({num_intent_labels}개) 사용: {intent_label_to_id}\")\n",
    "\n",
    "    intent_features = Features({\n",
    "        'text': Value('string'),\n",
    "        'label': ClassLabel(num_classes=num_intent_labels, names=intent_label_list)\n",
    "    })\n",
    "\n",
    "    intent_dataset = Dataset.from_list(intent_data, features=intent_features)\n",
    "\n",
    "    # 학습/평가 데이터 분리\n",
    "    train_test_datasets = intent_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "    train_dataset = train_test_datasets[\"train\"]\n",
    "    eval_dataset = train_test_datasets[\"test\"]\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "    def preprocess_intent_data(examples):\n",
    "        tokenized = tokenizer(\n",
    "            examples['text'],\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": tokenized[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"]\n",
    "        }\n",
    "\n",
    "    tokenized_train_dataset = train_dataset.map(\n",
    "        preprocess_intent_data,\n",
    "        batched=True,\n",
    "        remove_columns=['text']\n",
    "    )\n",
    "\n",
    "    tokenized_eval_dataset = eval_dataset.map(\n",
    "        preprocess_intent_data,\n",
    "        batched=True,\n",
    "        remove_columns=['text']\n",
    "    )\n",
    "\n",
    "    print(f\"Intent 데이터 샘플: {tokenized_train_dataset[0]}\")\n",
    "\n",
    "    intent_data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    intent_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=num_intent_labels,\n",
    "        id2label=intent_id_to_label,\n",
    "        label2id=intent_label_to_id\n",
    "    )\n",
    "\n",
    "    def compute_intent_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results/intent\",\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        logging_dir='./logs/intent',\n",
    "        logging_steps=10,\n",
    "        eval_steps=100,\n",
    "        eval_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        save_total_limit=2,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    intent_trainer = Trainer(\n",
    "        model=intent_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_eval_dataset,\n",
    "        data_collator=intent_data_collator,\n",
    "        compute_metrics=compute_intent_metrics,\n",
    "    )\n",
    "    intent_trainer.train()\n",
    "    eval_result = intent_trainer.evaluate()\n",
    "    print(f\"Intent 모델 평가 결과: {eval_result}\")\n",
    "    print(\"Intent 모델 훈련 완료\")\n",
    "\n",
    "    os.makedirs(INTENT_MODEL_DIR, exist_ok=True)\n",
    "    intent_model.save_pretrained(INTENT_MODEL_DIR, safe_serialization=False)\n",
    "    tokenizer.save_pretrained(INTENT_MODEL_DIR)\n",
    "\n",
    "    with open(INTENT_LABEL_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            \"id2label\": intent_id_to_label,\n",
    "            \"label2id\": intent_label_to_id\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Intent 모델 및 레이블 정보 저장 완료: {INTENT_MODEL_DIR}\")\n",
    "\n",
    "    return intent_model, tokenizer, intent_id_to_label\n",
    "\n",
    "# --- 3. NER 모델 훈련 (개선된 버전) ---\n",
    "def train_ner_model():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"NER 모델 훈련 시작 (개선된 버전)\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 3.1 토크나이저 로드\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "    # 디버깅: 토크나이저 테스트\n",
    "    test_text = \"인문학\"\n",
    "    test_tokens = tokenizer.tokenize(test_text)\n",
    "    print(f\"토크나이저 테스트 '{test_text}' -> {test_tokens}\")\n",
    "\n",
    "    # 3.2 NER 레이블 정의 (BIO 형식)\n",
    "    # 먼저 모든 엔터티 타입 추출\n",
    "    entity_types = sorted(list(set(label for item in ner_data for _, _, label in item[\"entities\"])))\n",
    "    print(f\"찾은 엔터티 타입: {entity_types}\")\n",
    "\n",
    "    ner_labels = [\"O\"]  # Outside tag\n",
    "    for entity_type in entity_types:\n",
    "        ner_labels.extend([f\"B-{entity_type}\", f\"I-{entity_type}\"])\n",
    "\n",
    "    ner_label2id = {label: i for i, label in enumerate(ner_labels)}\n",
    "    ner_id2label = {i: label for label, i in ner_label2id.items()}\n",
    "\n",
    "    print(f\"NER 레이블 ({len(ner_labels)}개): {ner_labels}\")\n",
    "\n",
    "    # 3.3 개선된 NER 데이터 전처리 - 문자 단위 접근\n",
    "    preprocessed_ner_data = []\n",
    "\n",
    "    print(\"\\n--- 개선된 NER 데이터 전처리 시작 ---\")\n",
    "\n",
    "    for example_idx, example in enumerate(ner_data):\n",
    "        text = example[\"text\"]\n",
    "        entities = example[\"entities\"]\n",
    "\n",
    "        if example_idx < 3:  # 처음 몇 개 예시만 상세 출력\n",
    "            print(f\"\\n[데이터 {example_idx}] 텍스트: \\\"{text}\\\"\")\n",
    "            print(f\"  정의된 엔티티: {entities}\")\n",
    "\n",
    "        # 1. 문자 단위 BIO 태깅 초기화\n",
    "        char_labels = [\"O\"] * len(text)\n",
    "\n",
    "        # 2. 엔티티에 따라 BIO 태그 할당\n",
    "        for start_char, end_char, entity_type in entities:\n",
    "            for i in range(start_char, end_char):\n",
    "                if start_char < 0:\n",
    "                    start_char = 0\n",
    "                if end_char > len(text):\n",
    "                    end_char = len(text)\n",
    "\n",
    "                if start_char < end_char and start_char < len(text):\n",
    "                    for i in range(start_char, end_char):\n",
    "                        if i == start_char:\n",
    "                            char_labels[i] = f\"B-{entity_type}\"\n",
    "                        else:\n",
    "                            char_labels[i] = f\"I-{entity_type}\"\n",
    "\n",
    "        if example_idx < 3 or start_char >= len(text) or end_char > len(text) or start_char < 0:\n",
    "            print(f\"  문제가 있는 엔티티: ({start_char}, {end_char}, {entity_type})\")\n",
    "            print(f\"  텍스트 길이: {len(text)}\")\n",
    "\n",
    "        if example_idx < 3:  # 상세 디버깅 출력\n",
    "            print(f\"  문자별 BIO 태그:\")\n",
    "            for i, (char, label) in enumerate(zip(text, char_labels)):\n",
    "                print(f\"    '{char}': {label}\")\n",
    "\n",
    "        # 3. 토큰화 및 토큰-문자 정렬\n",
    "        tokenized = tokenizer(text, return_offsets_mapping=True, add_special_tokens=True)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(tokenized['input_ids'])\n",
    "        offset_mapping = tokenized['offset_mapping']\n",
    "\n",
    "        if example_idx < 3:  # 상세 디버깅 출력\n",
    "            print(f\"  토큰화 결과: {tokens}\")\n",
    "            print(f\"  오프셋 매핑: {offset_mapping}\")\n",
    "\n",
    "        # 4. 토큰별 레이블 할당\n",
    "        token_labels = []\n",
    "        for i, (start, end) in enumerate(offset_mapping):\n",
    "            # 특수 토큰 처리\n",
    "            if start == end:\n",
    "                token_label = -100  # ignore_index\n",
    "            else:\n",
    "                # 토큰 시작 위치의 문자 레이블 사용\n",
    "                char_label = char_labels[start]\n",
    "                token_label = ner_label2id[char_label]\n",
    "\n",
    "                # 서브워드 토큰은 I- 태그로 변환 (WordPiece ##로 시작하는 경우)\n",
    "                if i > 0 and tokens[i].startswith(\"##\"):\n",
    "                    prev_label = token_labels[-1]\n",
    "                    if prev_label != -100 and ner_id2label[prev_label].startswith(\"B-\"):\n",
    "                        # B- -> I- 변환\n",
    "                        entity_type = ner_id2label[prev_label][2:]  # \"B-genre\" -> \"genre\"\n",
    "                        token_label = ner_label2id[f\"I-{entity_type}\"]\n",
    "\n",
    "            token_labels.append(token_label)\n",
    "\n",
    "        if example_idx < 3:  # 상세 디버깅 출력\n",
    "            print(f\"  최종 토큰 레이블: {[ner_id2label.get(l, 'IGN') for l in token_labels]}\")\n",
    "\n",
    "        # 5. 레이블 ID로 변환\n",
    "        preprocessed_ner_data.append({\n",
    "            \"text\": text,\n",
    "            \"input_ids\": tokenized[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "            \"labels\": token_labels\n",
    "        })\n",
    "\n",
    "    # 3.4 데이터셋 생성\n",
    "    ner_features = Features({\n",
    "        'text': Value('string'),\n",
    "        'input_ids': Sequence(Value('int32')),\n",
    "        'attention_mask': Sequence(Value('int32')),\n",
    "        'labels': Sequence(Value('int32'))\n",
    "    })\n",
    "\n",
    "    ner_dataset = Dataset.from_list(preprocessed_ner_data, features=ner_features)\n",
    "\n",
    "    # 학습/평가 데이터셋 분리\n",
    "    train_test_datasets = ner_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "    train_dataset = train_test_datasets[\"train\"]\n",
    "    eval_dataset = train_test_datasets[\"test\"]\n",
    "\n",
    "    print(f\"NER 훈련 데이터 크기: {len(train_dataset)}\")\n",
    "    print(f\"NER 평가 데이터 크기: {len(eval_dataset)}\")\n",
    "    print(f\"NER 데이터 샘플: {train_dataset[0]}\")\n",
    "\n",
    "    # 3.5 데이터 콜레이터 설정\n",
    "    ner_data_collator = DataCollatorForTokenClassification(\n",
    "        tokenizer=tokenizer,\n",
    "        padding=True,\n",
    "        max_length=MAX_LEN,\n",
    "        pad_to_multiple_of=8\n",
    "    )\n",
    "\n",
    "    # 3.6 모델 로드\n",
    "    ner_model = AutoModelForTokenClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=len(ner_labels),\n",
    "        id2label=ner_id2label,\n",
    "        label2id=ner_label2id\n",
    "    )\n",
    "\n",
    "    # 3.7 평가 지표 계산 함수\n",
    "    def compute_ner_metrics(p):\n",
    "        predictions, labels = p\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # 실제 토큰의 예측값과 레이블만 추출\n",
    "        true_predictions = []\n",
    "        true_labels = []\n",
    "\n",
    "        for prediction, label in zip(predictions, labels):\n",
    "            true_pred = []\n",
    "            true_label = []\n",
    "\n",
    "            for p, l in zip(prediction, label):\n",
    "                if l != -100:  # -100은 무시\n",
    "                    true_pred.append(ner_id2label[p])\n",
    "                    true_label.append(ner_id2label[l])\n",
    "\n",
    "            true_predictions.append(true_pred)\n",
    "            true_labels.append(true_label)\n",
    "\n",
    "        # seqeval의 f1_score 계산\n",
    "        try:\n",
    "            f1 = f1_score(true_labels, true_predictions)\n",
    "            report = classification_report(true_labels, true_predictions, digits=4)\n",
    "            print(\"\\nNER Classification Report:\\n\", report)\n",
    "\n",
    "            # 세부 클래스별 결과 분석\n",
    "            class_results = {}\n",
    "            for label in ner_labels:\n",
    "                if label != \"O\" and label.startswith(\"B-\"):\n",
    "                    entity_type = label[2:]  # \"B-genre\" -> \"genre\"\n",
    "                    label_f1 = f1_score([[label]], [[label]], average='macro')\n",
    "                    class_results[entity_type] = label_f1\n",
    "\n",
    "            # 상세 예측 예시 출력\n",
    "            print(\"\\n예측 예시:\")\n",
    "            for i in range(min(5, len(true_labels))):\n",
    "                print(f\"실제: {true_labels[i]}\")\n",
    "                print(f\"예측: {true_predictions[i]}\")\n",
    "                print(\"---\")\n",
    "\n",
    "            return {\n",
    "                \"f1\": f1,\n",
    "                **{f\"f1_{key}\": val for key, val in class_results.items()}\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating NER metrics: {e}\")\n",
    "            return {\"f1\": 0.0}\n",
    "\n",
    "    # 3.8 훈련 설정\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results/ner\",\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        logging_dir='./logs/ner',\n",
    "        logging_steps=10,\n",
    "        save_steps=100,\n",
    "        eval_steps=100,\n",
    "        eval_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=2,\n",
    "        greater_is_better=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        weight_decay=0.01,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    # 3.9 Trainer 정의\n",
    "    ner_trainer = Trainer(\n",
    "        model=ner_model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=ner_data_collator,\n",
    "        compute_metrics=compute_ner_metrics,\n",
    "    )\n",
    "\n",
    "    # 3.10 모델 훈련\n",
    "    ner_trainer.train()\n",
    "    eval_result = ner_trainer.evaluate()\n",
    "    print(f\"NER 모델 평가 결과: {eval_result}\")\n",
    "    print(\"NER 모델 훈련 완료\")\n",
    "\n",
    "    # 3.11 모델 및 레이블 정보 저장\n",
    "    os.makedirs(NER_MODEL_DIR, exist_ok=True)\n",
    "    gc.collect()\n",
    "    ner_model.cpu()\n",
    "    ner_model.save_pretrained(NER_MODEL_DIR, safe_serialization=False)\n",
    "    tokenizer.save_pretrained(NER_MODEL_DIR)\n",
    "\n",
    "    # 레이블 매핑 저장\n",
    "    with open(NER_LABEL_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            \"id2label\": ner_id2label,\n",
    "            \"label2id\": ner_label2id\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"NER 모델 및 레이블 정보 저장 완료: {NER_MODEL_DIR}\")\n",
    "\n",
    "    return ner_model, tokenizer, ner_id2label\n",
    "\n",
    "\n",
    "# --- 4. 저장된 모델 로드 ---\n",
    "def load_intent_model():\n",
    "    # 토크나이저 로드\n",
    "    tokenizer = AutoTokenizer.from_pretrained(INTENT_MODEL_DIR)\n",
    "\n",
    "    # 레이블 정보 로드\n",
    "    with open(INTENT_LABEL_PATH, 'r', encoding='utf-8') as f:\n",
    "        label_info = json.load(f)\n",
    "\n",
    "    id2label = {int(k): v for k, v in label_info[\"id2label\"].items()}\n",
    "    label2id = label_info[\"label2id\"]\n",
    "\n",
    "    # 모델 로드\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        INTENT_MODEL_DIR,\n",
    "        num_labels=len(id2label),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    return model, tokenizer, id2label\n",
    "\n",
    "\n",
    "def load_ner_model():\n",
    "    # 토크나이저 로드 - 저장된 위치에서 직접 로드\n",
    "    tokenizer = AutoTokenizer.from_pretrained(NER_MODEL_DIR, use_fast=True)\n",
    "    print(f\"NER용 토크나이저 로드 완료 (타입: {type(tokenizer)})\")\n",
    "\n",
    "    # 레이블 정보 로드\n",
    "    with open(NER_LABEL_PATH, 'r', encoding='utf-8') as f:\n",
    "        label_info = json.load(f)\n",
    "\n",
    "    id2label = {int(k): v for k, v in label_info[\"id2label\"].items()}\n",
    "    label2id = label_info[\"label2id\"]\n",
    "\n",
    "    # 모델 로드\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        NER_MODEL_DIR,\n",
    "        num_labels=len(id2label),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    return model, tokenizer, id2label\n",
    "\n",
    "\n",
    "# --- 5. 예측 함수 ---\n",
    "def predict_intent(model, tokenizer, id2label, text):\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "    if 'token_type_ids' in inputs:\n",
    "        del inputs['token_type_ids']\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(\"cuda\")\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "        predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
    "        predicted_intent = id2label[predicted_class_id]\n",
    "\n",
    "    return {\n",
    "        \"intent\": predicted_intent,\n",
    "        \"confidence\": probabilities.cpu().numpy().flatten().tolist()\n",
    "    }\n",
    "\n",
    "\n",
    "def predict_entities(model, tokenizer, id2label, text):\n",
    "    if not model or not tokenizer or not id2label:\n",
    "        return {\"tokens\": [], \"tags\": [], \"entities\": [], \"token_probabilities\": []}\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # 토큰화 시 오프셋 매핑 반환\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True,\n",
    "                      max_length=MAX_LEN, return_offsets_mapping=True)\n",
    "\n",
    "    # 오프셋 매핑 별도 저장 및 제거 (모델에 전달하지 않음)\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\").cpu().numpy()[0]\n",
    "\n",
    "    if 'token_type_ids' in inputs:\n",
    "        del inputs['token_type_ids']\n",
    "\n",
    "    # GPU 사용 가능 시 이동\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(\"cuda\")\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=2)\n",
    "        predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "    # 결과 추출\n",
    "    input_ids = inputs[\"input_ids\"][0].cpu().numpy()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    predicted_tag_ids = predictions[0].cpu().numpy()\n",
    "    all_probabilities = probabilities[0].cpu().numpy()\n",
    "\n",
    "    # 디버깅을 위한 출력\n",
    "    print(\"-\" * 30)\n",
    "    print(\"predict_entities 내부 디버깅:\")\n",
    "    print(f\"입력 텍스트: {text}\")\n",
    "    print(f\"토큰화 결과: {tokens}\")\n",
    "    print(f\"예측된 태그 ID: {predicted_tag_ids}\")\n",
    "\n",
    "    # 특수 토큰 제외 및 결과 처리\n",
    "    content_tokens = []\n",
    "    content_tags = []\n",
    "    token_probabilities_list = []\n",
    "    content_offsets = []\n",
    "\n",
    "    for i, (token, tag_id, input_id, (start, end)) in enumerate(zip(tokens, predicted_tag_ids, input_ids, offset_mapping)):\n",
    "        if input_id == tokenizer.pad_token_id:\n",
    "            break\n",
    "\n",
    "        if token not in tokenizer.all_special_tokens:\n",
    "            content_tokens.append(token)\n",
    "            tag = id2label.get(tag_id, \"O\")\n",
    "            content_tags.append(tag)\n",
    "            content_offsets.append((start, end))\n",
    "            token_probabilities_list.append(all_probabilities[i].tolist())\n",
    "\n",
    "    # 디버깅 출력 (일부)\n",
    "    print(f\"특수 토큰 제외 토큰: {content_tokens}\")\n",
    "    print(f\"해당 토큰의 태그: {content_tags}\")\n",
    "    print(f\"해당 토큰의 오프셋: {content_offsets}\")\n",
    "\n",
    "    # 엔티티 추출\n",
    "    entities_found = []\n",
    "    current_entity_tokens = []\n",
    "    current_entity_starts = []\n",
    "    current_entity_ends = []\n",
    "    current_entity_label = None\n",
    "\n",
    "    for i, (token, tag, (start, end)) in enumerate(zip(content_tokens, content_tags, content_offsets)):\n",
    "        if tag.startswith(\"B-\"):\n",
    "            # 이전 엔티티 처리\n",
    "            if current_entity_tokens:\n",
    "                entity_text = text[current_entity_starts[0]:current_entity_ends[-1]]\n",
    "                entities_found.append({\n",
    "                    \"entity\": entity_text,\n",
    "                    \"label\": current_entity_label\n",
    "                })\n",
    "\n",
    "            # 새 엔티티 시작\n",
    "            current_entity_tokens = [token]\n",
    "            current_entity_starts = [start]\n",
    "            current_entity_ends = [end]\n",
    "            current_entity_label = tag[2:]  # \"B-genre\" -> \"genre\"\n",
    "\n",
    "        elif tag.startswith(\"I-\") and current_entity_label == tag[2:]:\n",
    "            # 기존 엔티티 계속\n",
    "            current_entity_tokens.append(token)\n",
    "            current_entity_starts.append(start)\n",
    "            current_entity_ends.append(end)\n",
    "\n",
    "        else:\n",
    "            # 엔티티 종료\n",
    "            if current_entity_tokens:\n",
    "                entity_text = text[current_entity_starts[0]:current_entity_ends[-1]]\n",
    "                entities_found.append({\n",
    "                    \"entity\": entity_text,\n",
    "                    \"label\": current_entity_label\n",
    "                })\n",
    "            current_entity_tokens = []\n",
    "            current_entity_starts = []\n",
    "            current_entity_ends = []\n",
    "            current_entity_label = None\n",
    "\n",
    "    # 마지막 엔티티 처리\n",
    "    if current_entity_tokens:\n",
    "        entity_text = text[current_entity_starts[0]:current_entity_ends[-1]]\n",
    "        entities_found.append({\n",
    "            \"entity\": entity_text,\n",
    "            \"label\": current_entity_label\n",
    "        })\n",
    "\n",
    "    # 문자 단위 시각화를 위한 태그 매핑\n",
    "    char_tags = [\"_\"] * len(text)\n",
    "\n",
    "    for entity in entities_found:\n",
    "        entity_text = entity[\"entity\"]\n",
    "        entity_type = entity[\"label\"]\n",
    "\n",
    "        # 원본 텍스트에서 엔티티 위치 찾기\n",
    "        start_pos = text.find(entity_text)\n",
    "        if start_pos != -1:\n",
    "            end_pos = start_pos + len(entity_text)\n",
    "\n",
    "            # 위치에 태그 표시 (첫 글자는 B-, 나머지는 I-)\n",
    "            char_tags[start_pos] = \"B\"\n",
    "            for i in range(start_pos + 1, end_pos):\n",
    "                char_tags[i] = \"I\"\n",
    "\n",
    "    print(f\"추출된 엔티티: {entities_found}\")\n",
    "    print(f\"문자별 태그 매핑: {''.join(char_tags)}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    return {\n",
    "        \"tokens\": content_tokens,\n",
    "        \"tags\": content_tags,\n",
    "        \"entities\": entities_found,\n",
    "        \"token_probabilities\": token_probabilities_list,\n",
    "        \"char_tags\": char_tags  # 시각화를 위한 문자 단위 태그\n",
    "    }\n",
    "\n",
    "\n",
    "# --- 6. 통합 예측 함수 ---\n",
    "def predict(text):\n",
    "    global intent_model, intent_tokenizer, intent_id2label, ner_model, ner_tokenizer, ner_id2label\n",
    "\n",
    "    if not intent_model or not ner_model:\n",
    "        return {\"text\": text, \"intent\": \"오류: 모델 로드 실패\", \"confidence\": 0.0, \"entities\": [], \"error\": \"모델 로드 실패\"}\n",
    "    try:\n",
    "        intent_result = predict_intent(intent_model, intent_tokenizer, intent_id2label, text)\n",
    "        ner_result = predict_entities(ner_model, ner_tokenizer, ner_id2label, text)\n",
    "\n",
    "        # 문자별 태그 시각화 추가\n",
    "        char_tags = ner_result.get(\"char_tags\", [\"_\"] * len(text))\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"intent\": intent_result[\"intent\"],\n",
    "            \"confidence\": max(intent_result[\"confidence\"]) if intent_result.get(\"confidence\") else 0.0,\n",
    "            \"entities\": ner_result[\"entities\"],\n",
    "            \"ner_tokens\": ner_result.get(\"tokens\", []),\n",
    "            \"ner_token_probabilities\": ner_result.get(\"token_probabilities\", []),\n",
    "            \"char_tags\": \"\".join(char_tags)  # 문자 단위 시각화\n",
    "        }\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"예측 중 오류 발생: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return {\"text\": text, \"intent\": \"예측 오류\", \"confidence\": 0.0, \"entities\": [],\n",
    "                \"ner_tokens\": [], \"ner_token_probabilities\": [], \"error\": str(e)}\n",
    "\n",
    "\n",
    "# --- 7. 모델 훈련 함수 ---\n",
    "def train_models():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"도서 검색 NLU 모델 훈련 시작\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 모델 훈련 및 저장\n",
    "    train_intent_model()\n",
    "    train_ner_model()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"도서 검색 NLU 모델 훈련 완료\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcab041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "도서 검색 NLU 모델 훈련 시작\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Intent 분류 모델 훈련 시작\n",
      "==================================================\n",
      "Intent 레이블 (40개) 사용: {'search_book_title': 0, 'search_book_author': 1, 'search_book_location': 2, 'check_book_availability': 3, 'get_bestseller': 4, 'get_new_releases': 5, 'request_recommendation_genre': 6, 'request_recommendation_mood': 7, 'request_recommendation_topic': 8, 'request_recommendation_similar': 9, 'request_recommendation_reader': 10, 'search_space_availability': 11, 'reserve_space': 12, 'get_space_info': 13, 'check_space_reservation': 14, 'cancel_space_reservation': 15, 'search_program': 16, 'apply_program': 17, 'get_program_info': 18, 'check_program_application': 19, 'cancel_program_application': 20, 'get_library_info': 21, 'inquire_service': 22, 'manage_membership': 23, 'check_loan_status': 24, 'extend_loan': 25, 'reserve_book': 26, 'check_reservation_status': 27, 'cancel_book_reservation': 28, 'check_overdue_status': 29, 'report_lost_item': 30, 'greeting': 31, 'gratitude': 32, 'closing': 33, 'affirmative': 34, 'negative': 35, 'abuse': 36, 'clarification': 37, 'out_of_scope': 38, 'repeat': 39}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778dd00311c74c509f93e344c948aa03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/549 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcc29cc441d4ae39d0e0ada1e02abec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent 데이터 샘플: {'label': 0, 'input_ids': [2, 10571, 2024, 1052, 3630, 636, 1644, 1513, 6076, 1560, 2918, 13964, 16, 3915, 1556, 1897, 2223, 2477, 1295, 1513, 2075, 2182, 35, 3], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [690/690 15:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.263400</td>\n",
       "      <td>1.239202</td>\n",
       "      <td>0.717391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.766700</td>\n",
       "      <td>0.904835</td>\n",
       "      <td>0.760870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.855200</td>\n",
       "      <td>0.905479</td>\n",
       "      <td>0.768116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.385300</td>\n",
       "      <td>0.705974</td>\n",
       "      <td>0.789855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.331400</td>\n",
       "      <td>0.664301</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.353300</td>\n",
       "      <td>0.622599</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35/35 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent 모델 평가 결과: {'eval_loss': 0.6143625974655151, 'eval_accuracy': 0.8260869565217391, 'eval_runtime': 4.2446, 'eval_samples_per_second': 32.512, 'eval_steps_per_second': 8.246, 'epoch': 5.0}\n",
      "Intent 모델 훈련 완료\n",
      "Intent 모델 및 레이블 정보 저장 완료: ./models/intent\n",
      "\n",
      "==================================================\n",
      "NER 모델 훈련 시작 (개선된 버전)\n",
      "==================================================\n",
      "토크나이저 테스트 '인문학' -> ['인문학']\n",
      "찾은 엔터티 타입: ['account_action', 'author', 'call_number', 'category', 'date', 'difficulty', 'duration', 'equipment', 'event_type', 'fee', 'format', 'isbn', 'library_info_type', 'location', 'lost_item', 'mood', 'num_people', 'publisher', 'service_type', 'target_audience', 'time', 'timeOfDay', 'title', 'topic']\n",
      "NER 레이블 (49개): ['O', 'B-account_action', 'I-account_action', 'B-author', 'I-author', 'B-call_number', 'I-call_number', 'B-category', 'I-category', 'B-date', 'I-date', 'B-difficulty', 'I-difficulty', 'B-duration', 'I-duration', 'B-equipment', 'I-equipment', 'B-event_type', 'I-event_type', 'B-fee', 'I-fee', 'B-format', 'I-format', 'B-isbn', 'I-isbn', 'B-library_info_type', 'I-library_info_type', 'B-location', 'I-location', 'B-lost_item', 'I-lost_item', 'B-mood', 'I-mood', 'B-num_people', 'I-num_people', 'B-publisher', 'I-publisher', 'B-service_type', 'I-service_type', 'B-target_audience', 'I-target_audience', 'B-time', 'I-time', 'B-timeOfDay', 'I-timeOfDay', 'B-title', 'I-title', 'B-topic', 'I-topic']\n",
      "\n",
      "--- 개선된 NER 데이터 전처리 시작 ---\n",
      "\n",
      "[데이터 0] 텍스트: \"예수는 역사다라는 책 있나요?\"\n",
      "  정의된 엔티티: [(0, 7, 'title'), (10, 11, 'format')]\n",
      "  문제가 있는 엔티티: (10, 11, format)\n",
      "  텍스트 길이: 16\n",
      "  문자별 BIO 태그:\n",
      "    '예': B-title\n",
      "    '수': I-title\n",
      "    '는': I-title\n",
      "    ' ': I-title\n",
      "    '역': I-title\n",
      "    '사': I-title\n",
      "    '다': I-title\n",
      "    '라': O\n",
      "    '는': O\n",
      "    ' ': O\n",
      "    '책': B-format\n",
      "    ' ': O\n",
      "    '있': O\n",
      "    '나': O\n",
      "    '요': O\n",
      "    '?': O\n",
      "  토큰화 결과: ['[CLS]', '예수', '##는', '역사', '##다', '##라는', '책', '있', '##나', '##요', '?', '[SEP]']\n",
      "  오프셋 매핑: [(0, 0), (0, 2), (2, 3), (4, 6), (6, 7), (7, 9), (10, 11), (12, 13), (13, 14), (14, 15), (15, 16), (0, 0)]\n",
      "  최종 토큰 레이블: ['IGN', 'B-title', 'I-title', 'I-title', 'I-title', 'O', 'B-format', 'O', 'O', 'O', 'O', 'IGN']\n",
      "\n",
      "[데이터 1] 텍스트: \"어머니 나무를 찾아서 책 찾아주세요.\"\n",
      "  정의된 엔티티: [(0, 11, 'title'), (12, 13, 'format')]\n",
      "  문제가 있는 엔티티: (12, 13, format)\n",
      "  텍스트 길이: 20\n",
      "  문자별 BIO 태그:\n",
      "    '어': B-title\n",
      "    '머': I-title\n",
      "    '니': I-title\n",
      "    ' ': I-title\n",
      "    '나': I-title\n",
      "    '무': I-title\n",
      "    '를': I-title\n",
      "    ' ': I-title\n",
      "    '찾': I-title\n",
      "    '아': I-title\n",
      "    '서': I-title\n",
      "    ' ': O\n",
      "    '책': B-format\n",
      "    ' ': O\n",
      "    '찾': O\n",
      "    '아': O\n",
      "    '주': O\n",
      "    '세': O\n",
      "    '요': O\n",
      "    '.': O\n",
      "  토큰화 결과: ['[CLS]', '어머니', '나무', '##를', '찾아', '##서', '책', '찾아', '##주', '##세요', '.', '[SEP]']\n",
      "  오프셋 매핑: [(0, 0), (0, 3), (4, 6), (6, 7), (8, 10), (10, 11), (12, 13), (14, 16), (16, 17), (17, 19), (19, 20), (0, 0)]\n",
      "  최종 토큰 레이블: ['IGN', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'B-format', 'O', 'O', 'O', 'O', 'IGN']\n",
      "\n",
      "[데이터 2] 텍스트: \"이처럼 사소한 것들 소장하고 있는지 궁금합니다.\"\n",
      "  정의된 엔티티: [(0, 10, 'title')]\n",
      "  문제가 있는 엔티티: (0, 10, title)\n",
      "  텍스트 길이: 26\n",
      "  문자별 BIO 태그:\n",
      "    '이': B-title\n",
      "    '처': I-title\n",
      "    '럼': I-title\n",
      "    ' ': I-title\n",
      "    '사': I-title\n",
      "    '소': I-title\n",
      "    '한': I-title\n",
      "    ' ': I-title\n",
      "    '것': I-title\n",
      "    '들': I-title\n",
      "    ' ': O\n",
      "    '소': O\n",
      "    '장': O\n",
      "    '하': O\n",
      "    '고': O\n",
      "    ' ': O\n",
      "    '있': O\n",
      "    '는': O\n",
      "    '지': O\n",
      "    ' ': O\n",
      "    '궁': O\n",
      "    '금': O\n",
      "    '합': O\n",
      "    '니': O\n",
      "    '다': O\n",
      "    '.': O\n",
      "  토큰화 결과: ['[CLS]', '이', '##처럼', '사소', '##한', '것', '##들', '소장', '##하고', '있', '##는지', '궁금', '##합니다', '.', '[SEP]']\n",
      "  오프셋 매핑: [(0, 0), (0, 1), (1, 3), (4, 6), (6, 7), (8, 9), (9, 10), (11, 13), (13, 15), (16, 17), (17, 19), (20, 22), (22, 25), (25, 26), (0, 0)]\n",
      "  최종 토큰 레이블: ['IGN', 'B-title', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'IGN']\n",
      "NER 훈련 데이터 크기: 590\n",
      "NER 평가 데이터 크기: 148\n",
      "NER 데이터 샘플: {'text': '루이스 캐럴이라는 사람이 쓴 책을 찾고 싶은데, 도서관에 있을까?', 'input_ids': [2, 12236, 25950, 2052, 23548, 3611, 2052, 1365, 1644, 2069, 1642, 2088, 1335, 2073, 2147, 16, 5714, 2170, 1513, 16809, 35, 3], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 3, 4, 0, 0, 0, 0, 0, 21, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='740' max='740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [740/740 19:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1 Account Action</th>\n",
       "      <th>F1 Author</th>\n",
       "      <th>F1 Call Number</th>\n",
       "      <th>F1 Category</th>\n",
       "      <th>F1 Date</th>\n",
       "      <th>F1 Difficulty</th>\n",
       "      <th>F1 Duration</th>\n",
       "      <th>F1 Equipment</th>\n",
       "      <th>F1 Event Type</th>\n",
       "      <th>F1 Fee</th>\n",
       "      <th>F1 Format</th>\n",
       "      <th>F1 Isbn</th>\n",
       "      <th>F1 Library Info Type</th>\n",
       "      <th>F1 Location</th>\n",
       "      <th>F1 Lost Item</th>\n",
       "      <th>F1 Mood</th>\n",
       "      <th>F1 Num People</th>\n",
       "      <th>F1 Publisher</th>\n",
       "      <th>F1 Service Type</th>\n",
       "      <th>F1 Target Audience</th>\n",
       "      <th>F1 Time</th>\n",
       "      <th>F1 Timeofday</th>\n",
       "      <th>F1 Title</th>\n",
       "      <th>F1 Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.211283</td>\n",
       "      <td>0.769510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.172159</td>\n",
       "      <td>0.872865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.116273</td>\n",
       "      <td>0.906367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.148557</td>\n",
       "      <td>0.876364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.132774</td>\n",
       "      <td>0.911820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.120930</td>\n",
       "      <td>0.919926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.121026</td>\n",
       "      <td>0.908752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.8514    0.9545    0.9000        66\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "             date     0.0000    0.0000    0.0000         2\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.0000    0.0000    0.0000         2\n",
      "           format     0.7209    0.8986    0.8000        69\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.0000    0.0000    0.0000         4\n",
      "        publisher     0.0000    0.0000    0.0000         1\n",
      "  target_audience     0.0000    0.0000    0.0000         1\n",
      "        timeOfDay     0.0000    0.0000    0.0000         1\n",
      "            title     0.6905    0.7565    0.7220       115\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.7413    0.8000    0.7695       265\n",
      "        macro avg     0.1741    0.2007    0.1863       265\n",
      "     weighted avg     0.6994    0.8000    0.7458       265\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9118    0.9394    0.9254        66\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "             date     0.0000    0.0000    0.0000         2\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.0000    0.0000    0.0000         2\n",
      "           format     0.9531    0.8841    0.9173        69\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.5000    1.0000    0.6667         4\n",
      "        publisher     0.0000    0.0000    0.0000         1\n",
      "  target_audience     1.0000    1.0000    1.0000         1\n",
      "        timeOfDay     0.0000    0.0000    0.0000         1\n",
      "            title     0.8430    0.8870    0.8644       115\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.8779    0.8679    0.8729       265\n",
      "        macro avg     0.3237    0.3623    0.3364       265\n",
      "     weighted avg     0.8524    0.8679    0.8583       265\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'I-title', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9552    0.9697    0.9624        66\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "             date     0.0000    0.0000    0.0000         2\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.5000    0.5000    0.5000         2\n",
      "           format     0.9178    0.9710    0.9437        69\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     1.0000    1.0000    1.0000         4\n",
      "        publisher     0.0000    0.0000    0.0000         1\n",
      "  target_audience     1.0000    1.0000    1.0000         1\n",
      "        timeOfDay     0.0000    0.0000    0.0000         1\n",
      "            title     0.8607    0.9130    0.8861       115\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.8996    0.9132    0.9064       265\n",
      "        macro avg     0.4026    0.4118    0.4071       265\n",
      "     weighted avg     0.8730    0.9132    0.8926       265\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'I-title', 'I-title', 'I-title', 'I-title', 'I-title', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.8784    0.9848    0.9286        66\n",
      "         category     1.0000    1.0000    1.0000         1\n",
      "             date     0.3333    0.5000    0.4000         2\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     1.0000    1.0000    1.0000         2\n",
      "           format     0.9067    0.9855    0.9444        69\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.5000    1.0000    0.6667         4\n",
      "       num_people     0.0000    0.0000    0.0000         0\n",
      "        publisher     0.0000    0.0000    0.0000         1\n",
      "  target_audience     0.0000    0.0000    0.0000         1\n",
      "        timeOfDay     0.0000    0.0000    0.0000         1\n",
      "            title     0.8333    0.8696    0.8511       115\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.8456    0.9094    0.8764       265\n",
      "        macro avg     0.3894    0.4529    0.4136       265\n",
      "     weighted avg     0.8379    0.9094    0.8709       265\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'I-title', 'I-title', 'I-title', 'O', 'I-title', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9420    0.9848    0.9630        66\n",
      "         category     0.0000    0.0000    0.0000         1\n",
      "             date     0.0000    0.0000    0.0000         2\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     0.5000    0.5000    0.5000         2\n",
      "           format     0.9577    0.9855    0.9714        69\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.8000    1.0000    0.8889         4\n",
      "        publisher     0.0000    0.0000    0.0000         1\n",
      "  target_audience     1.0000    1.0000    1.0000         1\n",
      "        timeOfDay     0.0000    0.0000    0.0000         1\n",
      "            title     0.8739    0.9043    0.8889       115\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.9067    0.9170    0.9118       265\n",
      "        macro avg     0.3903    0.4134    0.4009       265\n",
      "     weighted avg     0.8829    0.9170    0.8995       265\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9552    0.9697    0.9624        66\n",
      "         category     1.0000    1.0000    1.0000         1\n",
      "             date     0.5000    0.5000    0.5000         2\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     1.0000    1.0000    1.0000         2\n",
      "           format     0.9577    0.9855    0.9714        69\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.8000    1.0000    0.8889         4\n",
      "        publisher     0.0000    0.0000    0.0000         1\n",
      "  target_audience     1.0000    1.0000    1.0000         1\n",
      "             time     0.0000    0.0000    0.0000         0\n",
      "        timeOfDay     0.0000    0.0000    0.0000         1\n",
      "            title     0.8689    0.9217    0.8945       115\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.9081    0.9321    0.9199       265\n",
      "        macro avg     0.5058    0.5269    0.5155       265\n",
      "     weighted avg     0.8953    0.9321    0.9131       265\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'I-title', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9265    0.9545    0.9403        66\n",
      "         category     1.0000    1.0000    1.0000         1\n",
      "             date     0.5000    0.5000    0.5000         2\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     1.0000    0.5000    0.6667         2\n",
      "           format     0.9577    0.9855    0.9714        69\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.8000    1.0000    0.8889         4\n",
      "        publisher     0.0000    0.0000    0.0000         1\n",
      "  target_audience     1.0000    1.0000    1.0000         1\n",
      "             time     0.0000    0.0000    0.0000         0\n",
      "        timeOfDay     0.0000    0.0000    0.0000         1\n",
      "            title     0.8607    0.9130    0.8861       115\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.8971    0.9208    0.9088       265\n",
      "        macro avg     0.5032    0.4895    0.4895       265\n",
      "     weighted avg     0.8846    0.9208    0.9014       265\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'I-title', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2718: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\spring\\CaterpillarAi\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NER Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           author     0.9552    0.9697    0.9624        66\n",
      "         category     1.0000    1.0000    1.0000         1\n",
      "             date     0.5000    0.5000    0.5000         2\n",
      "         duration     0.0000    0.0000    0.0000         1\n",
      "       event_type     1.0000    1.0000    1.0000         2\n",
      "           format     0.9577    0.9855    0.9714        69\n",
      "library_info_type     0.0000    0.0000    0.0000         1\n",
      "         location     0.8000    1.0000    0.8889         4\n",
      "        publisher     0.0000    0.0000    0.0000         1\n",
      "  target_audience     1.0000    1.0000    1.0000         1\n",
      "             time     0.0000    0.0000    0.0000         0\n",
      "        timeOfDay     0.0000    0.0000    0.0000         1\n",
      "            title     0.8689    0.9217    0.8945       115\n",
      "            topic     0.0000    0.0000    0.0000         1\n",
      "\n",
      "        micro avg     0.9081    0.9321    0.9199       265\n",
      "        macro avg     0.5058    0.5269    0.5155       265\n",
      "     weighted avg     0.8953    0.9321    0.9131       265\n",
      "\n",
      "\n",
      "예측 예시:\n",
      "실제: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'I-title', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-title', 'I-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['O', 'O', 'B-author', 'I-author', 'I-author', 'O', 'O', 'O', 'B-title', 'I-title', 'I-title', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "실제: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "예측: ['B-author', 'I-author', 'O', 'B-format', 'I-format', 'I-format', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "---\n",
      "NER 모델 평가 결과: {'eval_loss': 0.12093033641576767, 'eval_f1': 0.919925512104283, 'eval_f1_account_action': 1.0, 'eval_f1_author': 1.0, 'eval_f1_call_number': 1.0, 'eval_f1_category': 1.0, 'eval_f1_date': 1.0, 'eval_f1_difficulty': 1.0, 'eval_f1_duration': 1.0, 'eval_f1_equipment': 1.0, 'eval_f1_event_type': 1.0, 'eval_f1_fee': 1.0, 'eval_f1_format': 1.0, 'eval_f1_isbn': 1.0, 'eval_f1_library_info_type': 1.0, 'eval_f1_location': 1.0, 'eval_f1_lost_item': 1.0, 'eval_f1_mood': 1.0, 'eval_f1_num_people': 1.0, 'eval_f1_publisher': 1.0, 'eval_f1_service_type': 1.0, 'eval_f1_target_audience': 1.0, 'eval_f1_time': 1.0, 'eval_f1_timeOfDay': 1.0, 'eval_f1_title': 1.0, 'eval_f1_topic': 1.0, 'eval_runtime': 5.3939, 'eval_samples_per_second': 27.438, 'eval_steps_per_second': 6.86, 'epoch': 5.0}\n",
      "NER 모델 훈련 완료\n",
      "NER 모델 및 레이블 정보 저장 완료: ./models/ner\n",
      "\n",
      "==================================================\n",
      "도서 검색 NLU 모델 훈련 완료\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d79ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER용 토크나이저 로드 완료 (타입: <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n"
     ]
    }
   ],
   "source": [
    "intent_model, intent_tokenizer, intent_id2label = load_intent_model()\n",
    "ner_model, ner_tokenizer, ner_id2label = load_ner_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a52d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079e7e190b414404abdeb214c39578d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='질문:', placeholder='질문을 입력하세요')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646d2758a683406b8e60ecad2edbe77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='예측', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68cd29d09f1b44f8ac59444543913eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "text_widget = widgets.Text(description='질문:', placeholder='질문을 입력하세요')\n",
    "button = widgets.Button(description='예측')\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    global ner_id2label\n",
    "\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        user_input = text_widget.value\n",
    "        if not user_input:\n",
    "            print(\"질문을 입력해주세요.\")\n",
    "            return\n",
    "\n",
    "        print(f\"입력: \\\"{user_input}\\\"\")\n",
    "        print(\"예측 수행 중...\")\n",
    "        result = predict(user_input)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        if \"error\" in result:\n",
    "            print(f\"🚨 예측 오류: {result['error']}\")\n",
    "        else:\n",
    "            print(f\"📄 입력 텍스트: \\\"{result['text']}\\\"\")\n",
    "            print(f\"🎯 의도 분석 결과: {result['intent']} (확률: {result.get('confidence', 0.0):.4f})\")\n",
    "\n",
    "            print(\"\\n🔍 개체명 인식 결과:\")\n",
    "            if result.get('entities'):\n",
    "                for i, entity in enumerate(result['entities'], 1):\n",
    "                    print(f\"  {i}. \\\"{entity['entity']}\\\" → {entity['label']}\")\n",
    "            else:\n",
    "                print(\"  인식된 개체명 없음\")\n",
    "\n",
    "            print(\"\\n📊 토큰별 NER 확률:\")\n",
    "            if result.get('ner_tokens') and result.get('ner_token_probabilities'):\n",
    "                if 'ner_id2label' in globals() and ner_id2label:\n",
    "                    for token, probs in zip(result['ner_tokens'], result['ner_token_probabilities']):\n",
    "                        print(f\"  - 토큰: '{token}'\")\n",
    "                        sorted_probs = sorted(enumerate(probs), key=lambda item: item[1], reverse=True)\n",
    "                        for tag_id, prob in sorted_probs:\n",
    "                            print(f\"      {ner_id2label.get(tag_id, f'ID_{tag_id}')}: {prob:.4f}\")\n",
    "                else:\n",
    "                    print(\"  (오류: NER 레이블 매핑 정보(ner_id2label)를 찾을 수 없습니다.)\")\n",
    "            else:\n",
    "                print(\"  토큰별 확률 정보 없음.\")\n",
    "\n",
    "            print(\"\\n📝 문자별 NER 태그 시각화:\")\n",
    "            print(f\"  원문: {result['text']}\")\n",
    "\n",
    "            text = result['text']\n",
    "            tag_markers = ['_'] * len(text)\n",
    "            processed_indices = set()\n",
    "            for entity in sorted(result.get('entities', []), key=lambda x: len(x['entity']), reverse=True):\n",
    "                entity_text = entity['entity']\n",
    "                entity_type = entity['label']\n",
    "                start_pos = -1\n",
    "                search_start = 0\n",
    "                while True:\n",
    "                    temp_pos = text.find(entity_text, search_start)\n",
    "                    if temp_pos == -1: break\n",
    "                    is_overlapping = False\n",
    "                    for i in range(temp_pos, temp_pos + len(entity_text)):\n",
    "                        if i in processed_indices:\n",
    "                            is_overlapping = True\n",
    "                            break\n",
    "                    if not is_overlapping:\n",
    "                        start_pos = temp_pos\n",
    "                        break\n",
    "                    search_start = temp_pos + 1\n",
    "\n",
    "                if start_pos != -1:\n",
    "                    end_pos = start_pos + len(entity_text)\n",
    "                    for i in range(start_pos, end_pos):\n",
    "                        if i not in processed_indices:\n",
    "                            tag_markers[i] = '^'\n",
    "                            processed_indices.add(i)\n",
    "                    tag_label = f\"[{entity_type}]\"\n",
    "                    for i, char in enumerate(tag_label):\n",
    "                        pos = start_pos + i\n",
    "                        if pos < len(tag_markers) and tag_markers[pos] == '^':\n",
    "                            tag_markers[pos] = char\n",
    "\n",
    "            print(f\"  태그: {''.join(tag_markers)}\")\n",
    "\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "display(text_widget, button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
